{"messages": [{"role": "user", "content": "Create an Azure Resource Group using Terraform with the specified name and location. Set up a trigger using the subscription ID, resource group name, and domain variable. Execute a local command to create a B2C directory in Azure Active Directory. Implement a second command to delete the B2C directory when the resource is destroyed. Ensure the resource group is created before executing the B2C commands by specifying a dependency."}, {"role": "assistant", "content": "\n#File: main.tf\ndata \"azurerm_client_config\" \"current\" {\n}\nvariable \"domain\" {}\nvariable \"rg\" {}\nvariable \"location\" {}\n\nresource \"azurerm_resource_group\" \"rg\" {\n  name     = var.rg\n  location = var.location\n}\n\nresource \"null_resource\" \"b2c\" {\n  triggers = {\n    subs   = data.azurerm_client_config.current.subscription_id\n    rg     = var.rg\n    domain = var.domain\n  }\n  provisioner \"local-exec\" {\n    command = <<EOF\n      export SUBS=${self.triggers.subs}\n      export RG=${self.triggers.rg}\n      export DOMAIN=${self.triggers.domain}\n      az rest --method put --url https://management.azure.com/subscriptions/$SUBS/resourceGroups/$RG/providers/Microsoft.AzureActiveDirectory/b2cDirectories/$DOMAIN.onmicrosoft.com?api-version=2019-01-01-preview --body @b2c.json --verbose\n    EOF\n  }\n  provisioner \"local-exec\" {\n    when    = destroy\n    command = <<EOF\n      export SUBS=${self.triggers.subs}\n      export RG=${self.triggers.rg}\n      export DOMAIN=${self.triggers.domain}\n      az rest --method delete --url https://management.azure.com/subscriptions/$SUBS/resourceGroups/$RG/providers/Microsoft.AzureActiveDirectory/b2cDirectories/$DOMAIN.onmicrosoft.com?api-version=2019-01-01-preview --verbose\n    EOF\n  }\n  depends_on = [\n    azurerm_resource_group.rg\n  ]\n}\n#File: providers.tf\nprovider \"azurerm\" {\n  features {}\n}\n\nterraform {\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"~>2.0\"\n    }\n  }\n  required_version = \">= 0.13\"\n}"}]}
{"messages": [{"role": "user", "content": "Create a Google Cloud service account named \"dataproc-service-account\" with a display name of \"Dataproc Default Service Account\". Set up two Google Cloud Storage buckets for staging and configuration of a Dataproc cluster. Configure IAM bindings to grant the service account the Dataproc worker role. Initialize a Dataproc cluster with custom machine types and disk configurations, including preemptible workers and specific software settings. Finally, establish firewall rules to allow SSH access and internal communication within the network."}, {"role": "assistant", "content": "\n#File: cluster.tf\n\nresource \"google_service_account\" \"dataproc-service-account\" {\n  account_id   = \"dataproc-service-account\"\n  display_name = \"Dataproc Default Service Account\"\n}\n\nresource \"google_storage_bucket\" \"dataproc_staging_bucket\" {\n  name          = \"dataproc-cluster-0\"\n  location      = \"eu\"\n  uniform_bucket_level_access = true\n}\n\nresource \"google_project_iam_binding\" \"dataproc_worker\" {\n  role    = \"roles/dataproc.worker\"\n  members = [\n    \"serviceAccount:${google_service_account.dataproc-service-account.email}\"\n  ]\n}\n\nresource \"google_storage_bucket\" \"dataproc_config\" {\n  name          = \"dataproc-cluster-0-config\"\n  location      = \"eu\"\n  uniform_bucket_level_access = true\n}\n\nresource \"google_storage_bucket_object\" \"init_script\" {\n  name     = var.init_script\n  source   = \"${path.module}/${var.init_script}\"\n  bucket   = google_storage_bucket.dataproc_config.name\n}\n\nresource \"google_dataproc_cluster\" \"dataproc-cluster\" {\n  count = 1\n  name     = \"dataproc-cluster-${count.index}-${random_id.instance_id.hex}\"\n  region   = var.region\n  labels = {\n    environment = \"prod\"\n  }\n\n  cluster_config {\n    staging_bucket = google_storage_bucket.dataproc_staging_bucket.name\n\n    master_config {\n      num_instances = var.count_server[\"master\"]\n      machine_type  = var.machine_types[\"master\"]\n      disk_config {\n        boot_disk_type    = var.disk_type[\"master\"]\n        boot_disk_size_gb = var.disk_size[\"master\"]\n      }\n      image_uri = \"projects/${var.project}/global/images/custom-debian10-java11\"\n    }\n\n    worker_config {\n      num_instances    = var.count_server[\"worker\"]\n      machine_type     = var.machine_types[\"worker\"]\n      disk_config {\n        boot_disk_type    = var.disk_type[\"worker\"]\n        boot_disk_size_gb = var.disk_size[\"worker\"]\n      }\n      image_uri = \"projects/${var.project}/global/images/custom-debian10-java11\"\n    }\n\n    preemptible_worker_config {\n      num_instances = var.count_server[\"preemptible\"]\n    }\n\n    software_config {\n      image_version = var.image_version\n      override_properties = {\n        \"dataproc:dataproc.allow.zero.workers\" = \"true\"\n        \"spark-env:JAVA_HOME\" = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n        \"spark:spark.executorEnv.JAVA_HOME\" = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n      }\n    }\n\n    gce_cluster_config {\n      tags = [\"prod\", \"spark\"]\n      service_account_scopes = [\n        \"monitoring\",\n        \"useraccounts-ro\",\n        \"storage-rw\",\n        \"logging-write\"\n      ]\n      service_account = google_service_account.dataproc-service-account.email\n      subnetwork = google_compute_subnetwork.dataproc_subnetwork.name\n      internal_ip_only = true\n    }\n\n    initialization_action {\n      script = \"gs://${google_storage_bucket_object.init_script.bucket}/${google_storage_bucket_object.init_script.name}\"\n      timeout_sec = 500\n    }\n\n  }\n\n  timeouts {\n    create = \"1h\"\n    update = \"1h\"\n    delete = \"20m\"\n  }\n}\n\n#File: firewall.tf\nresource \"google_compute_firewall\" \"allow_ssh\" {\n name    = \"dataproc-ssh-firewall\"\n network = google_compute_network.dataproc_network.id\n\n allow {\n   protocol = \"tcp\"\n   ports    = [\"22\"]\n }\n\n source_ranges = [\"0.0.0.0/0\"]\n}\n\n# allow all access from health check ranges\nresource \"google_compute_firewall\" \"dataproc-vpc-allow-internal\" {\n  project = var.project\n  name          = \"dataproc-vpc-allow-internal\"\n  provider      = google-beta\n  direction     = \"INGRESS\"\n  network       = google_compute_network.dataproc_network.id\n  source_ranges = [var.cidrs[0]]\n  allow {\n    protocol = \"tcp\"\n    ports = [\"0-65535\"]\n  }\n  allow {\n    protocol = \"udp\"\n    ports = [\"0-65535\"]\n  }\n  allow {\n    protocol = \"icmp\"\n  }\n }\n\n\n#File: main.tf\nprovider \"google\" {\n  project = var.project\n  region  = var.region\n  zone    = var.zone\n}\n\nresource \"random_id\" \"instance_id\" {\n   byte_length = 8\n}\n\nresource \"google_project_service\" \"compute_api\" {\n  project = var.project\n  service = \"compute.googleapis.com\"\n  disable_on_destroy = false\n}\n\nresource \"google_project_service\" \"oslogin_api\" {\n  project = var.project\n  service = \"oslogin.googleapis.com\"\n  disable_on_destroy = false\n}\n\nresource \"google_project_service\" \"iam_api\" {\n  project = var.project\n  service = \"iam.googleapis.com\"\n  disable_on_destroy = false\n}\n\n#File: network.tf\nresource \"google_compute_network\" \"dataproc_network\" {\n  name = \"dataproc-vpc-network-${random_id.instance_id.hex}\"\n  auto_create_subnetworks = false\n}\n\nresource \"google_compute_subnetwork\" \"dataproc_subnetwork\" {\n  name = \"dataproc-vpc-subnet-1\"\n  ip_cidr_range = var.cidrs[0]\n  network = google_compute_network.dataproc_network.name\n  region = var.region\n  private_ip_google_access = true\n}\n\n\n#File: terraform.tf\nterraform {\n  required_providers {\n    random = {\n      source  = \"hashicorp/random\"\n      version = \"3.0.0\"\n    }\n\n    google = {\n      source  = \"hashicorp/google\"\n      version = \"~> 3.83.0\"\n    }\n  }\n\n  required_version = \">= 1.1\"\n}\n#File: vars.tf\nvariable \"project\" {\n  type = string\n}\n\nvariable \"init_script\" {\n  default = \"data/init.sh\"\n}\n\nvariable \"staging_bucket\" {\n  type = string\n  default = \"dataproc-cluster-0\"\n}\n\nvariable \"location\" {\n  type = string\n  default = \"us\"\n}\n\nvariable \"region\" {\n  type = string\n  default = \"us-central1\"\n}\n\nvariable \"zone\" {\n  type = string\n  default = \"us-central1-a\"\n}\n\nvariable \"cidrs\" { default = [ \"10.0.0.0/16\", \"10.1.0.0/16\" ] }\n\nvariable \"environment\" {\n  type = string\n  default = \"master\"\n}\n\nvariable \"machine_types\" {\n  type = map(string)\n  default = {\n    \"worker\" = \"n1-standard-2\"\n    \"master\" = \"n1-standard-2\"\n    \"preemptible\" = \"n1-standard-2\"\n  }\n}\n\nvariable \"disk_type\" {\n  type = map(string)\n  default = {\n    \"worker\" = \"pd-standard\"\n    \"master\" = \"pd-standard\"\n    \"preemptible\" = \"pd-standard\"\n  }\n}\n\nvariable \"image_version\" {\n   type = string\n   default = \"2.0.49-debian10\"\n}\n\nvariable \"disk_size\" {\n  type = map(string)\n  default = {\n    \"worker\" = 30\n    \"master\" = 30\n  }\n}\n\nvariable \"count_server\" {\n  type = map(string)\n  default = {\n    \"worker\" = 2\n    \"master\" = 1\n    \"preemptible\" = 0\n  }\n}\n\nvariable \"sql_tier\" {\n  type = string\n  default = \"db-n1-standard-2\"\n}\n"}]}
{"messages": [{"role": "user", "content": "Create a Google Cloud provider configuration using the project name variable. Define a Google Artifact Registry repository with the specified location, repository ID, and description for Docker images. Set the artifact format to DOCKER. Ensure the required Google provider version is specified. Use the default values for region and zone if not otherwise specified."}, {"role": "assistant", "content": "\n#File: gcp-main.tf\nresource \"google_artifact_registry_repository\" \"my-repo\" {\n  location      = var.region\n  repository_id = \"devopslab\"\n  description   = \"Docker Images for DevOps Lab\"\n  format        = \"DOCKER\"\n}\n\n#File: providers.tf\nterraform {\n  required_providers {\n    google = {\n      source = \"hashicorp/google\"\n      version = \"4.54.0\"\n    }\n  }\n}\n\n# Configura o Provider Google Cloud com o Projeto\nprovider \"google\" {\n  project = var.project_name\n}\n#File: variables.tf\nvariable \"project_name\" {\n  description = \"GCP Project name\"\n  type        = string\n}\n\nvariable \"region\" {\n  description = \"Google Cloud region\"\n  type        = string\n  default     = \"us-east1\"\n}\n\nvariable \"zone\" {\n  description = \"Google Cloud zone\"\n  type        = string\n  default     = \"us-east1-a\"\n}\n"}]}
{"messages": [{"role":"user","content":"Create a new VPC for internal networking with CIDR block 10.100.0.0/16. Tag it for identification. This VPC should not include any subnets."},{"role":"assistant","content":"provider \"aws\" {\r\n  region = \"us-east-1\"\r\n}\r\n\r\nresource \"aws_vpc\" \"custom\" {\r\n  cidr_block = \"10.100.0.0/16\"\r\n\r\n  tags = {\r\n    Name = \"custom-vpc\"\r\n  }\r\n}\r\n"}]}
{"messages": [{"role": "user", "content": "Create a Google Cloud project for a high availability VPN with a specified name and billing account. Configure the Google Cloud and Google Beta providers with necessary authentication and region variables. Build a VPN Gateway, an external VPN Gateway with redundant IPs, and two VPN tunnels connecting them. Establish a Cloud Router and two interfaces with peers for redundancy. Define the necessary variables for this infrastructure setup, ensuring they are tailored to your project's needs."}, {"role": "assistant", "content": "\n#File: provider-main.tf\n#####################\n## Provider - Main ##\n#####################\n\nterraform {\n  required_version = \">= 0.13\"\n  # backend \"gcs\" {\n  #   credentials = \"account.json\"\n  #   bucket  = \"kopicloud-gcp-tfstate\"\n  #   prefix  = \"core/core-state\"\n  # }\n}\n\nprovider \"google\" {\n  project     = var.gcp_project\n  credentials = file(var.gcp_auth_file)\n  region      = var.gcp_region\n}\n\nprovider \"google-beta\" {\n  project     = var.gcp_project\n  credentials = file(var.gcp_auth_file)\n  region      = var.gcp_region\n}\n\n#File: provider-variables.tf\n##########################\n## Provider - Variables ##\n##########################\n\n# GCP authentication file\nvariable \"gcp_auth_file\" {\n  type        = string\n  description = \"GCP authentication file\"\n  default     = \"\"\n}\n\n# define GCP region\nvariable \"gcp_region\" {\n  type        = string\n  description = \"GCP region\"\n}\n\n# define GCP project name\nvariable \"gcp_project\" {\n  type        = string\n  description = \"GCP project name\"\n}\n\n#File: vpn-ha-main.tf\n###################\n## HA VPN - Main ##\n###################\n\n# Create VPN Gateway\nresource \"google_compute_ha_vpn_gateway\" \"vpn-gateway-ha\" {\n  depends_on = [google_compute_network.vpn-network-ha]\n\n  provider = google-beta\n  region   = var.gcp_region\n  name     = \"${var.prefix}-vpn-gateway-ha\"\n  project  = google_project.vpn-ha.project_id\n  network  = google_compute_network.vpn-network-ha.name\n}\n\n# Create a VPN External Gateway\nresource \"google_compute_external_vpn_gateway\" \"vpn-external-gateway-ha\" {\n  provider        = google-beta\n  name            = \"${var.prefix}-external-vpn-gateway-ha\"\n  project         = google_project.vpn-ha.project_id\n  redundancy_type = \"TWO_IPS_REDUNDANCY\"\n  description     = \"An externally managed VPN gateway\"\n\n  interface {\n    id         = 0\n    ip_address = var.ha_ext_vpn_gateway_ip_1\n  }\n\n  interface {\n    id         = 1\n    ip_address = var.ha_ext_vpn_gateway_ip_2\n  }\n}\n\n# Create VPN Tunnel 1\nresource \"google_compute_vpn_tunnel\" \"vpn-tunnel1-ha\" {\n  provider                        = google-beta\n  name                            = \"${var.prefix}-vpn-tunnel1-ha\"\n  project                         = google_project.vpn-ha.project_id\n  region                          = var.gcp_region\n  vpn_gateway                     = google_compute_ha_vpn_gateway.vpn-gateway-ha.id\n  peer_external_gateway           = google_compute_external_vpn_gateway.vpn-external-gateway-ha.id\n  peer_external_gateway_interface = 0\n  shared_secret                   = var.ha_shared_secret\n  router                          = google_compute_router.vpn-router-ha.id\n  vpn_gateway_interface           = 0\n}\n\n# Create VPN Tunnel 2\nresource \"google_compute_vpn_tunnel\" \"vpn-tunnel2-ha\" {\n  provider                        = google-beta\n  name                            = \"${var.prefix}-vpn-tunnel2-ha\"\n  project                         = google_project.vpn-ha.project_id\n  region                          = var.gcp_region\n  vpn_gateway                     = google_compute_ha_vpn_gateway.vpn-gateway-ha.id\n  peer_external_gateway           = google_compute_external_vpn_gateway.vpn-external-gateway-ha.id\n  peer_external_gateway_interface = 0\n  shared_secret                   = var.ha_shared_secret\n  router                          = google_compute_router.vpn-router-ha.id\n  vpn_gateway_interface           = 1\n}\n\n# Create Cloud Router\nresource \"google_compute_router\" \"vpn-router-ha\" {\n  depends_on = [google_compute_network.vpn-network-ha]\n\n  name    = \"${var.prefix}-cloud-router-ha\"\n  project  = google_project.vpn-ha.project_id\n  network  = google_compute_network.vpn-network-ha.name\n  bgp {\n    asn = var.ha_router_asn\n  }\n}\n\n# Create Cloud Router Interface 1\nresource \"google_compute_router_interface\" \"vpn-router-interface1-ha\" {\n  depends_on = [\n    google_compute_router.vpn-router-ha\n  ]\n\n  provider   = google-beta\n  name       = \"${var.prefix}-cloud-router-interface1-ha\"\n  project    = google_project.vpn-ha.project_id\n  router     = google_compute_router.vpn-router-ha.name\n  region     = var.gcp_region\n  ip_range   = var.ha_router_interface1_ip_range\n  vpn_tunnel = google_compute_vpn_tunnel.vpn-tunnel1-ha.name\n}\n\n# Create Cloud Router Peer 1\nresource \"google_compute_router_peer\" \"vpn-router-peer1-ha\" {\n  depends_on = [\n    google_compute_router.vpn-router-ha\n  ]\n\n  provider                  = google-beta\n  name                      = \"${var.prefix}-cloud-router-peer1-ha\"\n  project                   = google_project.vpn-ha.project_id\n  router                    = google_compute_router.vpn-router-ha.name\n  region                    = var.gcp_region\n  peer_ip_address           = var.ha_router_peer1_ip_address\n  peer_asn                  = var.ha_peer_asn\n  advertised_route_priority = 100\n  interface                 = google_compute_router_interface.vpn-router-interface1-ha.name\n}\n\n# Create Cloud Router Interface 2\nresource \"google_compute_router_interface\" \"vpn-router-interface2-ha\" {\n  depends_on = [\n    google_compute_router.vpn-router-ha\n  ]\n\n  provider   = google-beta\n  name       = \"${var.prefix}-cloud-router-interface2-ha\"\n  project    = google_project.vpn-ha.project_id\n  router     = google_compute_router.vpn-router-ha.name\n  region     = var.gcp_region\n  ip_range   = var.ha_router_interface2_ip_range\n  vpn_tunnel = google_compute_vpn_tunnel.vpn-tunnel2-ha.name\n}\n\n# Create Cloud Router Peer 2\nresource \"google_compute_router_peer\" \"vpn-router-peer2-ha\" {\n  depends_on = [\n    google_compute_router.vpn-router-ha\n  ]\n\n  provider                  = google-beta\n  name                      = \"${var.prefix}-cloud-router-peer2-ha\"\n  project                   = google_project.vpn-ha.project_id\n  router                    = google_compute_router.vpn-router-ha.name\n  region                    = var.gcp_region\n  peer_ip_address           = var.ha_router_peer2_ip_address\n  peer_asn                  = var.ha_peer_asn\n  advertised_route_priority = 100\n  interface                 = google_compute_router_interface.vpn-router-interface2-ha.name\n}\n\n#File: vpn-ha-network.tf\n###########################\n## HA VPN Network - Main ##\n###########################\n\n# random ID for project\nresource \"random_integer\" \"random-ha\" {\n  max = 2000\n  min = 1000\n}\n\n# Create the HA VPN Project\nresource \"google_project\" \"vpn-ha\" {\n  name                = \"${var.prefix}-vpn-ha\"\n  project_id          = \"${var.prefix}-vpn-ha-${random_integer.random-ha.id}\"\n  folder_id           = var.ha_vpn_folder_id \n  auto_create_network = false\n  billing_account     = var.billing_account_id\n}\n\n# Create the Network for VPN Project\nresource \"google_compute_network\" \"vpn-network-ha\" {\n  name                    = \"${var.prefix}-vpn-network-ha\"\n  project                 = google_project.vpn-ha.project_id\n  routing_mode            = \"GLOBAL\"\n  auto_create_subnetworks = \"false\"\n}\n\n# Create a Subnet \nresource \"google_compute_subnetwork\" \"vpn-network-subnet-ha\" {\n  depends_on = [google_compute_network.vpn-network-ha]\n \n  name          = \"${var.prefix}-vpn-subnet-ha\"\n  project       = google_project.vpn-ha.project_id\n  ip_cidr_range = var.ha_vpn_subnet_cidr\n  region        = var.gcp_region\n  network       = google_compute_network.vpn-network-ha.name\n}\n\n\n#File: vpn-ha-variables.tf\n############################\n## HA VPN GCP - Variables ##\n############################\n\nvariable \"billing_account_id\" {\n  description = \"Billing account id used as default for new projects.\"\n  type        = string\n}\n\nvariable \"prefix\" {\n  description = \"Prefix used for resources that need unique names.\"\n  type        = string\n}\n\nvariable \"ha_vpn_folder_id\" {\n  type        = string\n  description = \"Folder to host the Project\"\n}\n\nvariable \"ha_vpn_subnet_cidr\" {\n  type        = string\n  description = \"VPN Network Subnet 1\"\n  default     = \"10.0.1.0/24\"\n}\n\nvariable \"ha_ext_vpn_gateway_ip_1\" {\n  type        = string\n  description = \"Public IP #1 of the external VPN Gateway\"\n}\n\nvariable \"ha_ext_vpn_gateway_ip_2\" {\n  type        = string\n  description = \"Public IP #1 of the external VPN Gateway\"\n}\n\nvariable \"ha_router_asn\" {\n  description = \"ASN for local side of BGP sessions\"\n  type        = string\n  default     = \"64514\"\n}\n\nvariable \"ha_peer_asn\" {\n  description = \"ASN for local side of BGP sessions\"\n  type        = string\n  default     = \"64515\"\n}\n\nvariable \"ha_shared_secret\" {\n  description = \"Tunnel shared secret\"\n  type        = string\n}\n\nvariable \"ha_router_interface1_ip_range\" {\n  description = \"Router Interface #1 IP Range\"\n  type        = string\n}\n\nvariable \"ha_router_interface2_ip_range\" {\n  description = \"Router Interface #2 IP Range\"\n  type        = string\n}\n\nvariable \"ha_router_peer1_ip_address\" {\n  description = \"Router Peer #1 IP Address\"\n  type        = string\n}\n\nvariable \"ha_router_peer2_ip_address\" {\n  description = \"Router Peer #1 IP Address\"\n  type        = string\n}\n"}]}
{"messages": [{"role": "user", "content": "Create a Terraform configuration file named `main.tf` with a specified backend and required providers. Set up a Google Cloud provider using variables for project and region. Create a Google Cloud Storage bucket configured for data lake purposes with versioning and lifecycle rules. Define a BigQuery dataset that links to the project and region. Use a `variables.tf` file to declare necessary variables such as project ID, region, storage class, and BigQuery dataset name."}, {"role": "assistant", "content": "\n#File: main.tf\nterraform {\n  required_version = \">= 1.0\"\n  backend \"local\" {}  # Can change from \"local\" to \"gcs\" (for google) or \"s3\" (for aws), if you would like to preserve your tf-state online\n  required_providers {\n    google = {\n      source  = \"hashicorp/google\"\n    }\n  }\n}\n\nprovider \"google\" {\n  project = var.project\n  region = var.region\n  // credentials = file(var.credentials)  # Use this if you do not want to set env-var GOOGLE_APPLICATION_CREDENTIALS\n}\n\n# Data Lake Bucket\n# Ref: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/storage_bucket\nresource \"google_storage_bucket\" \"data-lake-bucket\" {\n  name          = \"${local.data_lake_bucket}_${var.project}\" # Concatenating DL bucket & Project name for unique naming\n  location      = var.region\n\n  # Optional, but recommended settings:\n  storage_class = var.storage_class\n  uniform_bucket_level_access = true\n\n  versioning {\n    enabled     = true\n  }\n\n  #Triggers the action if the condition meets\n  lifecycle_rule {\n    action {\n      type = \"Delete\"\n    }\n    condition {\n      age = 30  // days\n    }\n  }\n\n  force_destroy = true\n}\n\n# DWH\n# Ref: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_dataset\nresource \"google_bigquery_dataset\" \"dataset\" {\n  dataset_id = var.BQ_DATASET\n  project    = var.project\n  location   = var.region\n}\n\n#File: variables.tf\nlocals {\n  data_lake_bucket = \"gcp_with_tf\" #replace it with your google storage bucket id\n}\n\nvariable \"project\" {\n  description = \"Your_GCP_Project_ID\" #replace it with your project id\n}\n\nvariable \"region\" {\n  description = \"Region for GCP resources. Choose as per your location: https://cloud.google.com/about/locations\"\n  default = \"europe-west6\" #replace it with your region code \n  type = string\n}\n\nvariable \"storage_class\" {\n  description = \"Storage class type for your bucket. Check official docs for more info.\"\n  default = \"STANDARD\"\n}\n\nvariable \"BQ_DATASET\" {\n  description = \"BigQuery Dataset that raw data (from GCS) will be written to\"\n  type = string\n  default = \"bq_tf_dataset\"\n}\n"}]}
{"messages": [{"role":"user","content":"Setup the deployment of Docker containers on AWS ECS, running on auto-scaling EC2 instances within a fully provisioned network. Includes VPC, subnets, security groups, ECS services, RDS (MySQL), ElastiCache (Redis), and IAM roles/policies. Support seamless multi-environment deployments with remote state management via S3 and DynamoDB."},{"role":"assistant","content":"provider \"aws\" {\r\n  region  = var.aws_region\r\n  profile = var.aws_profile\r\n}\r\n\r\n# Terraform variables file\r\n\r\nvariable \"aws_region\" {\r\n  description = \"The AWS region to deploy to\"\r\n  default     = \"ap-southeast-2\"\r\n  type        = string\r\n}\r\n\r\nvariable \"aws_profile\" {\r\n  description = \"AWS Profile to use\"\r\n  type        = string\r\n  default     = \"default\"\r\n}\r\n\r\nvariable \"prefix\" {\r\n  description = \"The prefix for all infra resources\"\r\n  default     = \"myproject\"\r\n  type        = string\r\n}\r\n\r\n# RDS instance variables\r\nvariable \"rds_instance_name\" {\r\n  description = \"RDS instance db name\"\r\n  type        = string\r\n}\r\n\r\nvariable \"rds_instance_username\" {\r\n  description = \"RDS instance username\"\r\n  type        = string\r\n}\r\n\r\nvariable \"rds_instance_password\" {\r\n  description = \"RDS instance password\"\r\n  type        = string\r\n}\r\n\r\nvariable \"rds_engine\" {\r\n  description = \"The database engine to be used for the RDS instance\"\r\n  type        = string\r\n  default     = \"mysql\"\r\n}\r\n\r\nvariable \"rds_engine_version\" {\r\n  description = \"The engine version of the RDS instance\"\r\n  type        = string\r\n  default     = \"5.7.44-rds.20240408\"\r\n}\r\n\r\nvariable \"rds_instance_class\" {\r\n  description = \"The instance class of the RDS instance\"\r\n  type        = string\r\n  default     = \"db.t3.medium\"\r\n}\r\n\r\n# Elasticache Redis variables\r\nvariable \"redis_cluster_id\" {\r\n  description = \"The name of the cluster\"\r\n  type        = string\r\n  default     = \"redis-cluster\"\r\n}\r\n\r\nvariable \"redis_node_type\" {\r\n  description = \"The compute and memory capacity of the nodes\"\r\n  type        = string\r\n  default     = \"cache.m4.medium\"\r\n}\r\n\r\nvariable \"redis_num_cache_nodes\" {\r\n  description = \"The number of cache nodes the cluster should have\"\r\n  type        = number\r\n  default     = 1\r\n}\r\n\r\nvariable \"redis_parameter_group_name\" {\r\n  description = \"The name of the parameter group to associate with this cluster\"\r\n  type        = string\r\n  default     = \"default.redis5.0\"\r\n}\r\n\r\nvariable \"redis_engine_version\" {\r\n  description = \"The version number of the cache engine to be used for the nodes in this cluster\"\r\n  type        = string\r\n  default     = \"5.0.6\"\r\n}\r\n\r\nvariable \"redis_port\" {\r\n  description = \"The port number on which each of the cache nodes accepts connections\"\r\n  type        = number\r\n  default     = 6379\r\n}\r\n\r\n# EC2 Auto Scaling Group variables\r\nvariable \"ec2_min_size\" {\r\n  description = \"The minimum number of instances in the Auto Scaling Group\"\r\n  type        = number\r\n  default     = 1\r\n}\r\n\r\nvariable \"ec2_max_size\" {\r\n  description = \"The maximum number of instances in the Auto Scaling Group\"\r\n  type        = number\r\n  default     = 1\r\n}\r\n\r\nvariable \"ec2_desired_capacity\" {\r\n  description = \"The desired number of instances in the Auto Scaling Group\"\r\n  type        = number\r\n  default     = 1\r\n}\r\n\r\nvariable \"health_check_grace_period\" {\r\n  description = \"The amount of time, in seconds, that Auto Scaling waits before checking the health status of an EC2 instance\"\r\n  type        = number\r\n  default     = 300\r\n}\r\n\r\n# ECS task variables\r\nvariable \"ec2_instance_type\" {\r\n  description = \"The instance type to use for the EC2 instance\"\r\n  type        = string\r\n}\r\n\r\nvariable \"ec2_key\" {\r\n  description = \"The key pair used to SSH into EC2 instances\"\r\n  type        = string\r\n}\r\n\r\nvariable \"task_cpu\" {\r\n  description = \"The amount of CPU to allocate to the task\"\r\n  type        = number\r\n  default     = 256\r\n}\r\n\r\nvariable \"task_memory\" {\r\n  description = \"The amount of memory used by the task\"\r\n  type        = number\r\n  default     = \"512\"\r\n}\r\n\r\nvariable \"docker_image\" {\r\n  description = \"The Docker image to use for the task\"\r\n  type        = string\r\n  default     = \"DOCKER_IMAGE\"\r\n}\r\n\r\n# ECS Service variables\r\nvariable \"ecs_service_desired_count\" {\r\n  description = \"The number of tasks to run in the service\"\r\n  type        = number\r\n  default     = 1\r\n}\r\nlocals {\r\n  subnets = {\r\n    \"app_subnet1\" = { cidr_block = \"10.0.1.0/24\", availability_zone = \"ap-southeast-2a\" },\r\n    \"app_subnet2\" = { cidr_block = \"10.0.2.0/24\", availability_zone = \"ap-southeast-2b\" },\r\n    \"db_subnet1\"  = { cidr_block = \"10.0.3.0/24\", availability_zone = \"ap-southeast-2c\" },\r\n    \"db_subnet2\"  = { cidr_block = \"10.0.4.0/24\", availability_zone = \"ap-southeast-2a\" }\r\n  }\r\n}\r\n\r\nresource \"aws_vpc\" \"main\" {\r\n  cidr_block = \"10.0.0.0/16\"\r\n}\r\n\r\nresource \"aws_subnet\" \"main\" {\r\n  for_each = local.subnets\r\n\r\n  vpc_id                  = aws_vpc.main.id\r\n  cidr_block              = each.value.cidr_block\r\n  availability_zone       = each.value.availability_zone\r\n  map_public_ip_on_launch = each.key == \"app_subnet1\" ? true : false\r\n}\r\n\r\nresource \"aws_internet_gateway\" \"main\" {\r\n  vpc_id = aws_vpc.main.id\r\n}\r\n\r\nresource \"aws_eip\" \"main\" {\r\n  depends_on = [aws_internet_gateway.main]\r\n}\r\n\r\nresource \"aws_nat_gateway\" \"main\" {\r\n  allocation_id = aws_eip.main.id\r\n  subnet_id     = aws_subnet.main[\"app_subnet1\"].id\r\n}\r\n\r\nresource \"aws_route_table\" \"public\" {\r\n  vpc_id = aws_vpc.main.id\r\n\r\n  route {\r\n    cidr_block = \"0.0.0.0/0\"\r\n    gateway_id = aws_internet_gateway.main.id\r\n  }\r\n}\r\n\r\n# Route tables for each private subnet\r\nresource \"aws_route_table\" \"private2\" {\r\n  vpc_id = aws_vpc.main.id\r\n\r\n  route {\r\n    cidr_block     = \"0.0.0.0/0\"\r\n    nat_gateway_id = aws_nat_gateway.main.id\r\n  }\r\n}\r\n\r\nresource \"aws_route_table\" \"private3\" {\r\n  vpc_id = aws_vpc.main.id\r\n\r\n  route {\r\n    cidr_block     = \"0.0.0.0/0\"\r\n    nat_gateway_id = aws_nat_gateway.main.id\r\n  }\r\n}\r\n\r\nresource \"aws_route_table\" \"private4\" {\r\n  vpc_id = aws_vpc.main.id\r\n\r\n  route {\r\n    cidr_block     = \"0.0.0.0/0\"\r\n    nat_gateway_id = aws_nat_gateway.main.id\r\n  }\r\n}\r\n\r\nresource \"aws_route_table_association\" \"public1\" {\r\n  subnet_id      = aws_subnet.main[\"app_subnet1\"].id\r\n  route_table_id = aws_route_table.public.id\r\n}\r\n\r\nresource \"aws_route_table_association\" \"private2\" {\r\n  subnet_id      = aws_subnet.main[\"app_subnet2\"].id\r\n  route_table_id = aws_route_table.private2.id\r\n}\r\n\r\nresource \"aws_route_table_association\" \"private3\" {\r\n  subnet_id      = aws_subnet.main[\"db_subnet1\"].id\r\n  route_table_id = aws_route_table.private3.id\r\n}\r\n\r\nresource \"aws_route_table_association\" \"private4\" {\r\n  subnet_id      = aws_subnet.main[\"db_subnet2\"].id\r\n  route_table_id = aws_route_table.private4.id\r\n}\r\n\r\n# Security Groups\r\n# ECS Instances Security Group\r\nresource \"aws_security_group\" \"ecs_instances_sg\" {\r\n  name        = \"${var.prefix}_ecs_instances_sg\"\r\n  vpc_id      = aws_vpc.main.id\r\n  description = \"Allow network communication for ECS instances\"\r\n\r\n  ingress {\r\n    from_port   = 80\r\n    to_port     = 80\r\n    protocol    = \"tcp\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n\r\n  ingress {\r\n    from_port   = 443\r\n    to_port     = 443\r\n    protocol    = \"tcp\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n\r\n  ingress {\r\n    from_port   = 22\r\n    to_port     = 22\r\n    protocol    = \"tcp\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n\r\n  egress {\r\n    from_port   = 0\r\n    to_port     = 0\r\n    protocol    = \"-1\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n}\r\n\r\nresource \"aws_security_group\" \"rds_sg\" {\r\n  name        = \"${var.prefix}_rds_instance_sg\"\r\n  description = \"Security group for RDS instance\"\r\n  vpc_id      = aws_vpc.main.id\r\n\r\n  ingress {\r\n    from_port       = 3306\r\n    to_port         = 3306\r\n    protocol        = \"tcp\"\r\n    security_groups = [aws_security_group.ecs_instances_sg.id]\r\n  }\r\n\r\n  egress {\r\n    from_port   = 0\r\n    to_port     = 0\r\n    protocol    = \"-1\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n}\r\n\r\n\r\n# RDS Database Network Configurations\r\nresource \"aws_db_subnet_group\" \"default\" {\r\n  name       = \"db-subnet-group\"\r\n  subnet_ids = [aws_subnet.main[\"db_subnet1\"].id, aws_subnet.main[\"db_subnet2\"].id]\r\n\r\n  tags = {\r\n    Name = \"${var.prefix} Main DB subnet group\"\r\n  }\r\n}\r\n\r\n# Elastichache Network Configurations\r\nresource \"aws_elasticache_subnet_group\" \"redis_subnet_group\" {\r\n  name       = \"redis-subnet-group\"\r\n  subnet_ids = [for s in keys(local.subnets) : aws_subnet.main[s].id]\r\n}\r\n\r\nresource \"aws_security_group\" \"redis_security_group\" {\r\n  name        = \"${var.prefix}_redis_security_group\"\r\n  description = \"Redis security group\"\r\n  vpc_id      = aws_vpc.main.id\r\n\r\n  ingress {\r\n    from_port   = 6379\r\n    to_port     = 6379\r\n    protocol    = \"tcp\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n\r\n  egress {\r\n    from_port   = 0\r\n    to_port     = 0\r\n    protocol    = \"-1\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n}\r\n// AWS RDS Database instance\r\nresource \"aws_db_instance\" \"default\" {\r\n  identifier                      = var.rds_instance_name\r\n  db_name                         = var.rds_instance_name\r\n  engine                          = var.rds_engine\r\n  engine_version                  = var.rds_engine_version\r\n  instance_class                  = var.rds_instance_class\r\n  license_model                   = \"general-public-license\"\r\n  allocated_storage               = 20\r\n  username                        = var.rds_instance_username\r\n  password                        = var.rds_instance_password\r\n  vpc_security_group_ids          = [aws_security_group.rds_sg.id]\r\n  db_subnet_group_name            = aws_db_subnet_group.default.name\r\n  enabled_cloudwatch_logs_exports = [\"audit\", \"error\", \"general\", \"slowquery\"]\r\n  publicly_accessible             = false\r\n  skip_final_snapshot             = true\r\n}\r\n\r\nresource \"aws_elasticache_cluster\" \"redis_cluster\" {\r\n  cluster_id           = var.redis_cluster_id\r\n  engine               = \"redis\"\r\n  node_type            = var.redis_node_type\r\n  num_cache_nodes      = var.redis_num_cache_nodes\r\n  parameter_group_name = var.redis_parameter_group_name\r\n  engine_version       = var.redis_engine_version\r\n  port                 = var.redis_port\r\n\r\n  subnet_group_name  = aws_elasticache_subnet_group.redis_subnet_group.name\r\n  security_group_ids = [aws_security_group.redis_security_group.id]\r\n}\r\n# ECS Cluster and Services\r\nresource \"aws_iam_role\" \"ecs_task_execution_role\" {\r\n  name = \"${var.prefix}_ecs_task_execution_role\"\r\n\r\n  assume_role_policy = jsonencode(\r\n    {\r\n      \"Version\" : \"2012-10-17\",\r\n      \"Statement\" : [\r\n        {\r\n          \"Action\" : \"sts:AssumeRole\",\r\n          \"Principal\" : {\r\n            \"Service\" : \"ecs-tasks.amazonaws.com\"\r\n          },\r\n          \"Effect\" : \"Allow\"\r\n        }\r\n      ]\r\n  })\r\n}\r\n\r\nresource \"aws_iam_role_policy_attachment\" \"ecs_task_execution_role_policy_attachment\" {\r\n  role       = aws_iam_role.ecs_task_execution_role.name\r\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\"\r\n}\r\n\r\n# ECS instance role\r\nresource \"aws_iam_role\" \"ecs_instance_role\" {\r\n  name = \"${var.prefix}_ecs_instance_role\"\r\n\r\n  assume_role_policy = jsonencode(\r\n    {\r\n      \"Version\" : \"2012-10-17\",\r\n      \"Statement\" : [\r\n        {\r\n          \"Action\" : \"sts:AssumeRole\",\r\n          \"Principal\" : {\r\n            \"Service\" : \"ec2.amazonaws.com\"\r\n          },\r\n          \"Effect\" : \"Allow\"\r\n        }\r\n      ]\r\n  })\r\n}\r\n\r\nresource \"aws_iam_role_policy_attachment\" \"ecs_instance_role_ec2_full_access\" {\r\n  role       = aws_iam_role.ecs_instance_role.name\r\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEC2FullAccess\"\r\n}\r\n\r\nresource \"aws_iam_role_policy_attachment\" \"ecs_instance_role_ec2_container_service_for_ec2_role\" {\r\n  role       = aws_iam_role.ecs_instance_role.name\r\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\"\r\n}\r\n\r\nresource \"aws_iam_instance_profile\" \"ecs_instance_profile\" {\r\n  name = \"${var.prefix}_ecs_instance_role\"\r\n  role = aws_iam_role.ecs_instance_role.name\r\n\r\n  depends_on = [aws_iam_role_policy_attachment.ecs_instance_role_ec2_container_service_for_ec2_role, aws_iam_role_policy_attachment.ecs_instance_role_ec2_full_access]\r\n}\r\n\r\ndata \"aws_ami\" \"latest_ecs\" {\r\n  most_recent = true\r\n  owners      = [\"amazon\"]\r\n\r\n  filter {\r\n    name   = \"name\"\r\n    values = [\"amzn-ami-*-amazon-ecs-optimized\"]\r\n  }\r\n}\r\n\r\n# Cluster configurations\r\nresource \"aws_ecs_cluster\" \"cluster\" {\r\n  name = \"${var.prefix}_job_cluster\"\r\n}\r\n\r\n\r\nresource \"aws_launch_template\" \"lt\" {\r\n  name          = \"${var.prefix}_ecs_launch_template\"\r\n  image_id      = data.aws_ami.latest_ecs.id\r\n  instance_type = var.ec2_instance_type\r\n  key_name      = var.ec2_key\r\n\r\n  network_interfaces {\r\n    subnet_id       = aws_subnet.main[\"app_subnet1\"].id\r\n    security_groups = [aws_security_group.ecs_instances_sg.id]\r\n  }\r\n\r\n  iam_instance_profile {\r\n    name = aws_iam_instance_profile.ecs_instance_profile.name\r\n  }\r\n\r\n  user_data = base64encode(<<USERDATA\r\n  #!/bin/bash\r\n  echo ECS_CLUSTER=${aws_ecs_cluster.cluster.name} >> /etc/ecs/ecs.config\r\n  sudo service docker start\r\n  sudo start ecs\r\n  USERDATA\r\n  )\r\n\r\n  lifecycle {\r\n    create_before_destroy = true\r\n  }\r\n}\r\n\r\nresource \"aws_autoscaling_group\" \"asg\" {\r\n  desired_capacity = var.ec2_desired_capacity\r\n  min_size         = var.ec2_min_size\r\n  max_size         = var.ec2_max_size\r\n\r\n  health_check_grace_period = var.health_check_grace_period\r\n  health_check_type         = \"EC2\"\r\n  vpc_zone_identifier       = [aws_subnet.main[\"app_subnet1\"].id, aws_subnet.main[\"app_subnet2\"].id]\r\n\r\n  launch_template {\r\n    id      = aws_launch_template.lt.id\r\n    version = \"$Latest\"\r\n  }\r\n\r\n  tag {\r\n    key                 = \"Name\"\r\n    value               = \"${var.prefix}_ec2_instance\"\r\n    propagate_at_launch = true\r\n  }\r\n}\r\n\r\nresource \"aws_cloudwatch_log_group\" \"ecs_log_group\" {\r\n  name = \"/ecs/${var.prefix}_main_container\"\r\n}\r\n\r\nresource \"aws_ecs_task_definition\" \"main_task\" {\r\n  family                   = \"${var.prefix}_main_container\"\r\n  network_mode             = \"host\"\r\n  requires_compatibilities = [\"EC2\"]\r\n\r\n  cpu                = var.task_cpu\r\n  memory             = var.task_memory\r\n  execution_role_arn = aws_iam_role.ecs_task_execution_role.arn\r\n\r\n  lifecycle {\r\n    create_before_destroy = true\r\n  }\r\n\r\n  container_definitions = jsonencode([\r\n    {\r\n      \"name\" : \"main_container\",\r\n      \"image\" : var.docker_image,\r\n      \"essential\" : true,\r\n      \"cpu\" : var.task_cpu,\r\n      \"portMappings\" : [\r\n        {\r\n          \"containerPort\" : 80,\r\n          \"hostPort\" : 80\r\n        },\r\n        {\r\n          \"containerPort\" : 443,\r\n          \"hostPort\" : 443\r\n        },\r\n      ],\r\n      \"logConfiguration\" : {\r\n        \"logDriver\" : \"awslogs\",\r\n        \"options\" : {\r\n          \"awslogs-group\" : aws_cloudwatch_log_group.ecs_log_group.name,\r\n          \"awslogs-region\" : var.aws_region,\r\n          \"awslogs-stream-prefix\" : \"ecs\"\r\n        }\r\n      }\r\n    }\r\n  ])\r\n}\r\n\r\nresource \"aws_ecs_service\" \"main_task_service\" {\r\n  name            = \"${var.prefix}_ecs_main_service\"\r\n  cluster         = aws_ecs_cluster.cluster.arn\r\n  task_definition = aws_ecs_task_definition.main_task.arn\r\n  desired_count   = var.ecs_service_desired_count\r\n  launch_type     = \"EC2\"\r\n}\r\n"}]}
{"messages": [{"role":"user","content":"Define a custom VPC with a CIDR block of 10.0.0.0/16. Add tags for identification. This VPC will be used for internal networking"},{"role":"assistant","content":"provider \"aws\"{}\r\n\r\n\r\nresource \"aws_vpc\" \"main\" {\r\n  cidr_block = \"10.0.0.0/16\"\r\n\r\n  tags = {\r\n    Name = \"internal-vpc\"\r\n  }\r\n}\r\n"}]}
{"messages": [{"role": "user", "content": "Create a local backend configuration in a `backend.tf` file for Terraform state management. Define an Azure Service Plan in `main.tf` with a dynamic name using the workload variable, and set its resource group, location, OS type, and SKU. Establish necessary variables in `variables.tf` for resource group name, location, workload, and SKU name. Configure Azure provider settings in `provider.tf` to handle resource group and key vault features. Output the Service Plan ID in `output.tf` for reference."}, {"role": "assistant", "content": "\n#File: backend.tf\nterraform {\n  backend \"local\" {\n    path = \".workspace/terraform.tfstate\"\n  }\n}\n\n#File: main.tf\nresource \"azurerm_service_plan\" \"main\" {\n  name                = \"plan-${var.workload}\"\n  resource_group_name = var.resource_group_name\n  location            = var.location\n  os_type             = \"Linux\"\n  sku_name            = var.sku_name\n}\n\n#File: output.tf\noutput \"plan_id\" {\n  value = azurerm_service_plan.main.id\n}\n\n#File: provider.tf\nprovider \"azurerm\" {\n  features {\n    resource_group {\n      prevent_deletion_if_contains_resources = false\n    }\n    key_vault {\n      purge_soft_delete_on_destroy    = true\n      recover_soft_deleted_key_vaults = false\n    }\n  }\n}\n\n#File: variables.tf\nvariable \"resource_group_name\" {\n  type = string\n}\n\nvariable \"location\" {\n  type = string\n}\n\nvariable \"workload\" {\n  type = string\n}\n\nvariable \"sku_name\" {\n  type = string\n}\n"}]}
{"messages": [{"role": "user", "content": "Create a Google Cloud provider configuration with your project ID and region. Set up a Google Kubernetes Engine (GKE) cluster named \"primary-cluster\" in your specified zone with an initial node count of one. Establish a node pool called \"primary-node-pool\" with non-preemptible e2-medium machines. Deploy a Node.js application as a Kubernetes deployment with two replicas and expose it via a LoadBalancer service. Define the necessary variables for project ID, region, and cluster zone in a separate variables file."}, {"role": "assistant", "content": "\n#File: main.tf\nprovider \"google\" {\n  project = \"YOUR_PROJECT_ID\"\n  region  = \"YOUR_REGION\"\n}\n\nresource \"google_container_cluster\" \"primary\" {\n  name     = \"primary-cluster\"\n  location = \"YOUR_CLUSTER_ZONE\"\n\n  initial_node_count = 1\n\n  node_config {\n    machine_type = \"e2-medium\"\n    oauth_scopes = [\n      \"https://www.googleapis.com/auth/devstorage.read_only\",\n      \"https://www.googleapis.com/auth/logging.write\",\n      \"https://www.googleapis.com/auth/monitoring\",\n      \"https://www.googleapis.com/auth/servicecontrol\",\n      \"https://www.googleapis.com/auth/service.management.readonly\",\n      \"https://www.googleapis.com/auth/trace.append\",\n    ]\n  }\n}\n\nresource \"google_container_node_pool\" \"primary_nodes\" {\n  name       = \"primary-node-pool\"\n  location   = google_container_cluster.primary.location\n  cluster    = google_container_cluster.primary.name\n  node_count = 1\n\n  node_config {\n    preemptible  = false\n    machine_type = \"e2-medium\"\n\n    oauth_scopes = [\n      \"https://www.googleapis.com/auth/cloud-platform\",\n    ]\n  }\n}\n\ndata \"google_client_config\" \"default\" {}\n\nprovider \"kubernetes\" {\n  host = google_container_cluster.primary.endpoint\n\n  token = data.google_client_config.default.access_token\n\n  cluster_ca_certificate = base64decode(\n    google_container_cluster.primary.master_auth.0.cluster_ca_certificate\n  )\n}\n\nresource \"kubernetes_deployment\" \"nodejs\" {\n  metadata {\n    name = \"nodejs-deployment\"\n  }\n\n  spec {\n    replicas = 2\n\n    selector {\n      match_labels = {\n        app = \"nodejs\"\n      }\n    }\n\n    template {\n      metadata {\n        labels = {\n          app = \"nodejs\"\n        }\n      }\n\n      spec {\n        container {\n          name  = \"nodejs\"\n          image = \"gcr.io/YOUR_PROJECT_ID/nodejs-app:latest\"\n\n          port {\n            container_port = 3000\n          }\n        }\n      }\n    }\n  }\n}\n\nresource \"kubernetes_service\" \"nodejs\" {\n  metadata {\n    name = \"nodejs-service\"\n  }\n\n  spec {\n    selector = {\n      app = \"nodejs\"\n    }\n\n    port {\n      port        = 80\n      target_port = 3000\n    }\n\n    type = \"LoadBalancer\"\n  }\n}\n  \n\n#File: variables.tf\nvariable \"project_id\" {\n  description = \"The GCP project ID\"\n  type        = string\n}\n\nvariable \"region\" {\n  description = \"The GCP region\"\n  type        = string\n}\n\nvariable \"cluster_zone\" {\n  description = \"The GCP zone for the cluster\"\n  type        = string\n}\n"}]}
{"messages": [{"role": "user", "content": "Create a VPC in Google Cloud with no automatic subnetworks. Generate public and private subnets based on specified CIDR ranges and set up a NAT router and NAT gateway to enable internet access for private instances. Launch both private and public instances in their respective subnets with Apache installed on startup. Configure firewall rules to allow SSH access from your IP and allow HTTP/HTTPS traffic between public and private instances. Output the VPC ID and subnet IDs for reference."}, {"role": "assistant", "content": "\n#File: main.tf\n### Create VPC\nresource \"google_compute_network\" \"vpc\" {\n  name                    = \"${var.environment}-vpc\"\n  auto_create_subnetworks = \"false\"\n}\n\nresource \"google_compute_subnetwork\" \"public-subnet\" {\n  name          = \"${var.environment}-public-subnet-${count.index}\"\n  count         = length(var.public_subnets_cidr)\n  ip_cidr_range = element(var.public_subnets_cidr, count.index)\n  region        = var.region\n  network       = google_compute_network.vpc.id\n}\n\nresource \"google_compute_subnetwork\" \"private-subnet\" {\n  name                     = \"${var.environment}-private-subnet-${count.index}\"\n  count                    = length(var.private_subnets_cidr)\n  ip_cidr_range            = element(var.private_subnets_cidr, count.index)\n  region                   = var.region\n  network                  = google_compute_network.vpc.id\n  private_ip_google_access = true\n}\n\n### Create a public ip for nat service\nresource \"google_compute_address\" \"nat-ip\" {\n  name    = \"${var.environment}-nap-ip-${count.index}\"\n  project = var.project\n  region  = var.region\n  count   = length(var.private_subnets_cidr)\n}\n\n### Create a nat to allow private instances connect to internet\nresource \"google_compute_router\" \"nat-router\" {\n  name    = \"${var.environment}-nat-router-${count.index}\"\n  region  = var.region\n  network = google_compute_network.vpc.name\n  count   = length(var.private_subnets_cidr)\n}\n\nresource \"google_compute_router_nat\" \"nat-gateway\" {\n  name                               = \"${var.environment}-nat-gateway-${count.index}\"\n  count                              = length(var.private_subnets_cidr)\n  router                             = element(google_compute_router.nat-router.*.name, count.index)\n  nat_ip_allocate_option             = \"MANUAL_ONLY\"\n  nat_ips                            = [\"${element(google_compute_address.nat-ip.*.self_link, count.index)}\"]\n  source_subnetwork_ip_ranges_to_nat = \"LIST_OF_SUBNETWORKS\"\n  subnetwork {\n    name                    = element(google_compute_subnetwork.private-subnet.*.self_link, count.index)\n    source_ip_ranges_to_nat = [\"ALL_IP_RANGES\"]\n  }\n}\n\n### Launch Intances in PRIVATE subnet\nresource \"google_compute_instance\" \"private-instance\" {\n  name         = \"${var.environment}-private-instance-${count.index}\"\n  count        = 1\n  machine_type = \"n1-standard-1\"\n  zone         = \"${element(var.availability_zones, count.index)}\"\n  tags         = [\"${var.environment}\", \"private-instances\"]\n  boot_disk {\n    initialize_params {\n      image = \"debian-cloud/debian-9\"\n    }\n  }\n  network_interface {\n    subnetwork = element(google_compute_subnetwork.private-subnet.*.self_link, count.index)\n  }\n  metadata_startup_script = \"sudo apt update; sudo apt install apache2 -y\"\n}\n\n### Launch Intances in PUBLIC subnet\nresource \"google_compute_instance\" \"public-instance\" {\n  name         = \"${var.environment}-public-instance-${count.index}\"\n  count        = 1\n  machine_type = \"n1-standard-1\"\n  zone         = \"${element(var.availability_zones, count.index)}\"\n  tags         = [\"${var.environment}\", \"public-instances\"]\n  boot_disk {\n    initialize_params {\n      image = \"debian-cloud/debian-9\"\n    }\n  }\n  network_interface {\n    subnetwork = element(google_compute_subnetwork.public-subnet.*.self_link, count.index)\n    access_config {\n        # It will assign external IP to isnatance if not specified\n    }\n  }\n  metadata_startup_script = \"sudo apt update; sudo apt install apache2 -y\"\n}\n\n# Firewall: Allow SSH to all Instances from my Local\nresource \"google_compute_firewall\" \"firewall-ssh\" {\n  name = \"${var.environment}-ssh2allinstance-firewall\"\n  network = google_compute_network.vpc.name\n  allow {\n    protocol = \"tcp\"\n  }\n  source_ranges = [\"97.102.162.197/32\"]\n  #target_tags = [\"private-instances\", \"public-instances\"]\n}\n\n### Firewall: For Instances in Public Subnet\nresource \"google_compute_firewall\" \"firewall-public\" {\n  name = \"${var.environment}-public-subnet-firewall\"\n  network = google_compute_network.vpc.name\n  allow {\n    protocol = \"tcp\"\n    ports = [ \"80\", \"443\" ]\n  }\n  source_ranges = [\"0.0.0.0/0\"]\n  target_tags = [\"public-instances\"]\n}\n\n### Firewall: For Instances in Private Subnet\nresource \"google_compute_firewall\" \"firewall-private\" {\n  name = \"${var.environment}-private-subnet-firewall\"\n  network = google_compute_network.vpc.name\n  allow {\n    protocol = \"tcp\"\n    ports = [ \"80\", \"443\" ]\n  }\n  source_ranges = var.public_subnets_cidr # Allow traffic from only Public Subnet\n  target_tags = [\"private-instances\"]\n}\n\n### Firewall: SSH through IAP Tunnel\nresource \"google_compute_firewall\" \"firewall-iap\" {\n  name = \"${var.environment}-firewall-iap\"\n  network = google_compute_network.vpc.name\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"22\"]\n  }\n  source_ranges = [\"35.235.240.0/20\"]\n  target_tags = [\"private-instances\"]\n}\n#File: variables.tf\nvariable \"project\" {\n}\n\nvariable \"region\" {\n}\n\nvariable \"availability_zones\" {\n}\n\nvariable \"environment\" {\n}\n\nvariable \"vpc_cidr\" {\n}\n\nvariable \"public_subnets_cidr\" {\n}\n\nvariable \"private_subnets_cidr\" {\n}\n\n\n#File: output.tf\noutput \"vpc_id\" {\n  value = google_compute_network.vpc.id\n}\n\noutput \"private_subnet_id\" {\n  value = google_compute_subnetwork.private-subnet.*.id\n}\n\noutput \"public_subnet_id\" {\n  value = google_compute_subnetwork.public-subnet.*.id\n}\n\noutput \"subnets\" {\n  value = [google_compute_subnetwork.private-subnet.*.id, google_compute_subnetwork.public-subnet.*.id]\n}"}]}
{"messages": [{"role": "user", "content": "Create a TLS private key for the admin user. Create an Azure resource group with a specified location. Create a virtual network and a subnet within that resource group. Create a public IP address and a network security group, then configure SSH access rules for the network security group. Finally, create a Linux virtual machine associated with the network interface and public IP, and generate necessary Ansible inventory and variables files."}, {"role": "assistant", "content": "\n#File: main.tf\n# Configure the Microsoft Azure Provider\nterraform {\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \">= 2.26\"\n    }\n  }\n}\n\n# Declare Azure provider\nprovider \"azurerm\" {\n  features {}\n}\n\n# Create admin user SSH key\nresource \"tls_private_key\" \"admin\" {\n  # algorithm   = \"ECDSA\"\n  # ecdsa_curve = \"P256\"\n  algorithm = \"RSA\"\n  rsa_bits  = \"4096\"\n}\n\n# Create resource group\nresource \"azurerm_resource_group\" \"rg\" {\n  name     = \"${var.prefix}RG\"\n  location = var.location\n}\n\n# Create virtual network\nresource \"azurerm_virtual_network\" \"vnet\" {\n  name                = \"${var.prefix}Vnet\"\n  address_space       = [\"10.0.0.0/16\"]\n  location            = var.location\n  resource_group_name = azurerm_resource_group.rg.name\n}\n\n# Create subnet\nresource \"azurerm_subnet\" \"subnet\" {\n  name                 = \"${var.prefix}Subnet\"\n  resource_group_name  = azurerm_resource_group.rg.name\n  virtual_network_name = azurerm_virtual_network.vnet.name\n  address_prefixes     = [\"10.0.1.0/24\"]\n}\n\n# Create public IP\nresource \"azurerm_public_ip\" \"publicip\" {\n  name                = \"${var.prefix}PublicIP\"\n  location            = var.location\n  resource_group_name = azurerm_resource_group.rg.name\n  allocation_method   = \"Dynamic\"\n}\n\n# Create Network Security Group\nresource \"azurerm_network_security_group\" \"nsg\" {\n  name                = \"${var.prefix}NSG\"\n  location            = var.location\n  resource_group_name = azurerm_resource_group.rg.name\n}\n\n# Create SSH NSG rule\nresource \"azurerm_network_security_rule\" \"ssh_prefixes\" {\n  count = length(var.ssh_addresses) > 1 ? 1 : 0\n\n  name                        = \"SSH\"\n  priority                    = 1001\n  direction                   = \"Inbound\"\n  access                      = \"Allow\"\n  protocol                    = \"Tcp\"\n  source_port_range           = \"*\"\n  destination_port_range      = \"22\"\n  source_address_prefixes     = var.ssh_addresses #tfsec:ignore:AZU001\n  destination_address_prefix  = \"*\"\n  resource_group_name         = azurerm_resource_group.rg.name\n  network_security_group_name = azurerm_network_security_group.nsg.name\n}\nresource \"azurerm_network_security_rule\" \"ssh_prefix\" {\n  #tfsec:ignore:AZU017\n  count = length(var.ssh_addresses) > 1 ? 0 : 1\n\n  name                        = \"SSH\"\n  priority                    = 1001\n  direction                   = \"Inbound\"\n  access                      = \"Allow\"\n  protocol                    = \"Tcp\"\n  source_port_range           = \"*\"\n  destination_port_range      = \"22\"\n  source_address_prefix       = var.ssh_addresses[0] #tfsec:ignore:AZU001\n  destination_address_prefix  = \"*\"\n  resource_group_name         = azurerm_resource_group.rg.name\n  network_security_group_name = azurerm_network_security_group.nsg.name\n}\n\n# Create network interface\nresource \"azurerm_network_interface\" \"nic\" {\n  name                = \"${var.prefix}NIC\"\n  location            = var.location\n  resource_group_name = azurerm_resource_group.rg.name\n\n  ip_configuration {\n    name                          = \"${var.prefix}NICConfig\"\n    subnet_id                     = azurerm_subnet.subnet.id\n    private_ip_address_allocation = \"dynamic\"\n    public_ip_address_id          = azurerm_public_ip.publicip.id\n  }\n}\n\n# Associate network interface with network security group\nresource \"azurerm_network_interface_security_group_association\" \"example\" {\n  network_interface_id      = azurerm_network_interface.nic.id\n  network_security_group_id = azurerm_network_security_group.nsg.id\n}\n\n# Create a Linux virtual machine\nresource \"azurerm_linux_virtual_machine\" \"vm\" {\n  name                  = \"${var.prefix}VM\"\n  location              = var.location\n  resource_group_name   = azurerm_resource_group.rg.name\n  network_interface_ids = [azurerm_network_interface.nic.id]\n  size                  = var.vm_size\n  computer_name         = \"${var.prefix}VM\"\n  admin_username        = var.admin_username\n\n  disable_password_authentication = true\n\n  admin_ssh_key {\n    username   = var.admin_username\n    public_key = tls_private_key.admin.public_key_openssh\n  }\n\n  os_disk {\n    name                 = \"${var.prefix}OsDisk\"\n    caching              = \"ReadWrite\"\n    storage_account_type = var.storage_type\n  }\n\n  source_image_reference {\n    publisher = var.vm_image.publisher\n    offer     = var.vm_image.offer\n    sku       = var.vm_image.sku\n    version   = var.vm_image.version\n  }\n}\n\n# Create a data disk\nresource \"azurerm_managed_disk\" \"disk\" {\n  name                = \"${var.prefix}DataDisk\"\n  location            = var.location\n  resource_group_name = azurerm_resource_group.rg.name\n\n  storage_account_type = var.storage_type\n  create_option        = \"Empty\"\n  disk_size_gb         = var.data_disk_size_gb\n\n  count = var.data_disk_size_gb > 0 ? 1 : 0\n}\n\n# Attach data disk\nresource \"azurerm_virtual_machine_data_disk_attachment\" \"disk\" {\n  managed_disk_id    = azurerm_managed_disk.disk[count.index].id\n  virtual_machine_id = azurerm_linux_virtual_machine.vm.id\n  lun                = \"0\"\n  caching            = \"ReadWrite\"\n\n  count = var.data_disk_size_gb > 0 ? 1 : 0\n}\n\n# Register public IP address to write to Ansible inventory\ndata \"azurerm_public_ip\" \"ip\" {\n  name                = azurerm_public_ip.publicip.name\n  resource_group_name = azurerm_linux_virtual_machine.vm.resource_group_name\n  depends_on          = [azurerm_linux_virtual_machine.vm]\n}\n\n# Print public IP address\noutput \"public_ip_address\" {\n  value = data.azurerm_public_ip.ip.ip_address\n}\n\n# Write admin account private key to a file\nresource \"local_file\" \"admin_private_key\" {\n  filename        = \"../ansible/admin_id_rsa.pem\"\n  file_permission = \"0600\"\n  content         = tls_private_key.admin.private_key_pem\n}\n\n# Create Ansible inventory for the defined virtual machine\nresource \"local_file\" \"ansible_inventory\" {\n  filename        = \"../ansible/inventory.yaml\"\n  file_permission = \"0644\"\n  content         = <<-DOC\n    ---\n    all:\n      hosts:\n        vm:\n          ansible_host: ${data.azurerm_public_ip.ip.ip_address}\n          ansible_user: ${var.admin_username}\n          ansible_ssh_private_key_file: ${local_file.admin_private_key.filename}\n    DOC\n}\n\n# Write variables needed by Ansible to a YAML file\nresource \"local_file\" \"ansible_variables\" {\n  filename        = \"../ansible/terraform_vars.yaml\"\n  file_permission = \"0644\"\n  content         = <<-DOC\n    ---\n    data_disk_size_gb: ${var.data_disk_size_gb}\n    DOC\n}\n\n#File: variables.tf\nvariable \"vm_size\" {\n  type    = string\n  default = \"Standard_B2s\"\n}\n\nvariable \"ssh_addresses\" {\n  type    = list(string)\n  default = [\"*\"]\n}\n\nvariable \"location\" {\n  type    = string\n  default = \"eastus\"\n}\n\nvariable \"prefix\" {\n  type    = string\n  default = \"my\"\n}\n\nvariable \"admin_username\" {\n  type    = string\n  default = \"ansible_admin\"\n}\n\nvariable \"storage_type\" {\n  type    = string\n  default = \"StandardSSD_LRS\"\n  validation {\n    condition     = can(contains([\"Standard_LRS\", \"StandardSSD_LRS\", \"Premium_LRS\"], var.storage_type))\n    error_message = \"The storage type must be one of Standard_LRS, StandardSSD_LRS and Premium_LRS.\"\n  }\n}\n\nvariable \"data_disk_size_gb\" {\n  type    = number\n  default = 0\n  validation {\n    condition     = var.data_disk_size_gb >= 0\n    error_message = \"The data disk size must be a positive integer or 0.\"\n  }\n}\n\nvariable \"vm_image\" {\n  type = object({\n    publisher = string\n    offer     = string\n    sku       = string\n    version   = string\n  })\n  default = {\n    publisher = \"Canonical\"\n    offer     = \"0001-com-ubuntu-server-focal\"\n    sku       = \"20_04-lts\"\n    version   = \"latest\"\n  }\n}\n"}]}
{"messages": [{"role": "user", "content": "Create a Google Cloud SQL database instance with the specified version, tier, and settings. Configure the instance with automatic disk resizing and set the appropriate maintenance window. Generate a random password for the database user unless a custom password is provided. Create the specified default database and user, assigning them the necessary permissions. Finally, output the database instance's IP address, name, user name, and generated user password."}, {"role": "assistant", "content": "\n#File: my-sql-instance-outputs.tf\n# Database output | mysql-instance-output.tf\n\noutput db_instance_address {\n  description = \"IP address of the master database instance\"\n  value       = \"${google_sql_database_instance.my_sql.ip_address.0.ip_address}\"\n}\n\noutput db_instance_name {\n  description = \"Name of the database instance\"\n  value       = \"${google_sql_database_instance.my_sql.name}\"\n}\n\noutput db_instance_username {\n  description = \"Name of the database user\"\n  value       = \"${var.db_user_name}\"\n}\n\noutput db_instance_generated_user_password {\n  description = \"The auto generated default user password if no input password was provided\"\n  value       = \"${random_id.user_password.hex}\"\n}\n\n#File: my-sql-instance-variables.tf\n# database instance settings\nvariable db_version {\n  description = \"The version of of the database. For example, MYSQL_5_6 or MYSQL_5_7\"\n  default     = \"MYSQL_5_7\"\n}\n\nvariable db_tier {\n  description = \"The machine tier (First Generation) or type (Second Generation). Reference: https://cloud.google.com/sql/pricing\"\n  default     = \"db-f1-micro\"\n}\n\nvariable db_activation_policy {\n  description = \"Specifies when the instance should be active. Options are ALWAYS, NEVER or ON_DEMAND\"\n  default     = \"ALWAYS\"\n}\n\nvariable db_disk_autoresize {\n  description = \"Second Generation only. Configuration to increase storage size automatically.\"\n  default     = true\n}\n\nvariable db_disk_size {\n  description = \"Second generation only. The size of data disk, in GB. Size of a running instance cannot be reduced but can be increased.\"\n  default     = 10\n}\n\nvariable db_disk_type {\n  description = \"Second generation only. The type of data disk: PD_SSD or PD_HDD\"\n  default     = \"PD_SSD\"\n}\n\nvariable db_pricing_plan {\n  description = \"First generation only. Pricing plan for this instance, can be one of PER_USE or PACKAGE\"\n  default     = \"PER_USE\"\n}\n\nvariable db_instance_access_cidr {\n  description = \"The IPv4 CIDR to provide access the database instance\"\n  default     = \"0.0.0.0/0\"\n}\n\n# database settings\nvariable db_name {\n  description = \"Name of the default database to create\"\n  default     = \"tfdb\"\n}\n\nvariable db_charset {\n  description = \"The charset for the default database\"\n  default     = \"\"\n}\n\nvariable db_collation {\n  description = \"The collation for the default database. Example for MySQL databases: 'utf8_general_ci'\"\n  default     = \"\"\n}\n\n# user settings\nvariable db_user_name {\n  description = \"The name of the default user\"\n  default     = \"dbadmin\"\n}\n\nvariable db_user_host {\n  description = \"The host for the default user\"\n  default     = \"%\"\n}\n\nvariable db_user_password {\n  description = \"The password for the default user. If not set, a random one will be generated and available in the generated_user_password output variable.\"\n  default     = \"\"\n}\n\n\n#File: my-sql-instance.tf\n# Terraform plugin for creating random ids\nresource \"random_id\" \"instance_id\" {\n byte_length = 4\n}\n\n# create My SQL database instance\nresource \"google_sql_database_instance\" \"my_sql\" {\n  name                 = \"${var.app_name}-${var.app_environment}-db-${random_id.instance_id.hex}\"\n  project              = \"${var.app_project}\"\n  region               = \"${var.gcp_region_1}\"\n  database_version     = \"${var.db_version}\"\n  \n  settings {\n    tier = \"${var.db_tier}\"\n    activation_policy           = \"${var.db_activation_policy}\"\n    disk_autoresize             = \"${var.db_disk_autoresize}\"\n    disk_size                   = \"${var.db_disk_size}\"\n    disk_type                   = \"${var.db_disk_type}\"\n    pricing_plan                = \"${var.db_pricing_plan}\"\n    \n    location_preference {\n      zone = \"${var.gcp_zone_1}\"\n    }\n\n    maintenance_window {\n      day  = \"7\"  # sunday\n      hour = \"3\" # 3am  \n    }\n\n    database_flags {\n      name  = \"log_bin_trust_function_creators\"\n      value = \"on\"\n    }\n\n    backup_configuration {\n      binary_log_enabled = true\n      enabled            = true\n      start_time         = \"00:00\"\n    }\n\n    ip_configuration {\n      ipv4_enabled = \"true\"\n      authorized_networks {\n        value = \"${var.db_instance_access_cidr}\"\n      }\n    }\n  }\n}\n\n# create database\nresource \"google_sql_database\" \"my_sql_db\" {\n  name      = \"${var.db_name}\"\n  project   = \"${var.app_project}\"\n  instance  = \"${google_sql_database_instance.my_sql.name}\"\n  charset   = \"${var.db_charset}\"\n  collation = \"${var.db_collation}\"\n}\n\n# create user\nresource \"random_id\" \"user_password\" {\n  byte_length = 8\n}\n\nresource \"google_sql_user\" \"my-sql\" {\n  name     = \"${var.db_user_name}\"\n  project  = \"${var.app_project}\"\n  instance = \"${google_sql_database_instance.my_sql.name}\"\n  host     = \"${var.db_user_host}\"\n  password = \"${var.db_user_password == \"\" ? random_id.user_password.hex : var.db_user_password}\"\n}\n\n#File: provider.tf\n# setup the GCP provider | provider.tf\n\nterraform {\n  required_version = \">= 0.12\"\n}\n\nprovider \"google\" {\n  project = var.app_project\n  credentials = file(var.gcp_auth_file)\n  region  = var.gcp_region_1\n  zone    = var.gcp_zone_1\n}\n\nprovider \"google-beta\" {\n  project = var.app_project\n  credentials = file(var.gcp_auth_file)\n  region  = var.gcp_region_1\n  zone    = var.gcp_zone_1\n}\n\n#File: variables-auth.tf\n# Google Cloud connection & authentication and Application configuration | variables-auth.tf\n\n# GCP authentication file\nvariable \"gcp_auth_file\" {\n  type = string\n  description = \"GCP authentication file\"\n}\n\n# define GCP region\nvariable \"gcp_region_1\" {\n  type = string\n  description = \"GCP region\"\n}\n\n# define GCP zone\nvariable \"gcp_zone_1\" {\n  type = string\n  description = \"GCP zone\"\n}\n\n# define GCP project name\nvariable \"app_project\" {\n  type = string\n  description = \"GCP project name\"\n}\n\n# define application name\nvariable \"app_name\" {\n  type = string\n  description = \"Application name\"\n}\n\n# define application environment\nvariable \"app_environment\" {\n  type = string\n  description = \"Application environment\"\n}\n"}]}
{"messages": [{"role": "user", "content": "Create a resource group named \"rs-k8s-small-001\" in the \"West Europe\" location. Set up a virtual network called \"vnet-k8s-small-001\" with an address space of \"10.1.0.0/16\" within the created resource group. Establish a subnet named \"internal\" with an address prefix of \"10.1.0.0/22\" in the virtual network. Deploy an Azure Kubernetes Service cluster named \"aks-small-001\" with specific configurations for the default node pool and networking. Output the Kubernetes client certificate, kube config, and other sensitive details for cluster access."}, {"role": "assistant", "content": "\n#File: k8s-small.tf\n# Create a resource group\nresource \"azurerm_resource_group\" \"rg-k8s-small-001\" {\n  name     = \"rs-k8s-small-001\"\n  location = \"West Europe\"\n}\n\nresource \"azurerm_virtual_network\" \"vnet-k8s-small-001\" {\n  name                = \"vnet-k8s-small-001\"\n  location            = azurerm_resource_group.rg-k8s-small-001.location\n  resource_group_name = azurerm_resource_group.rg-k8s-small-001.name\n  address_space       = [\"10.1.0.0/16\"]\n}\n\nresource \"azurerm_subnet\" \"internal\" {\n  name                 = \"internal\"\n  virtual_network_name = azurerm_virtual_network.vnet-k8s-small-001.name\n  resource_group_name  = azurerm_resource_group.rg-k8s-small-001.name\n  address_prefixes     = [\"10.1.0.0/22\"]\n}\n\nresource \"azurerm_kubernetes_cluster\" \"k8s-small-001\" {\n  name                = \"aks-small-001\"\n  location            = azurerm_resource_group.rg-k8s-small-001.location\n  resource_group_name = azurerm_resource_group.rg-k8s-small-001.name\n  dns_prefix          = \"aks-small-001\"\n\n  default_node_pool {\n    name                = \"default\"\n    node_count          = 1\n    vm_size             = \"Standard_B2s\"\n    enable_auto_scaling = false\n  }\n\n  network_profile {\n    network_plugin    = \"azure\"\n    network_policy    = \"calico\"\n    load_balancer_sku = \"standard\"\n  }\n\n  identity {\n    type = \"SystemAssigned\"\n  }\n\n  #tags = {\n  #  Environment = \"Production\"\n  #}\n\n  #zones = [\"1\", \"2\"]\n  #api_server_authorized_ip_ranges  = [\"YOUR_IP/32\"]\n  azure_policy_enabled             = true\n  http_application_routing_enabled = true\n  #loadBalancerSku                  = \"standard\"\n  #network_plugin                   = \"calico\"\n  private_cluster_enabled = false\n\n}\n\noutput \"client_certificate\" {\n  value     = azurerm_kubernetes_cluster.k8s-small-001.kube_config.0.client_certificate\n  sensitive = true\n}\n\noutput \"kube_config\" {\n  value     = azurerm_kubernetes_cluster.k8s-small-001.kube_config_raw\n  sensitive = true\n}\n\noutput \"id\" {\n  value = azurerm_kubernetes_cluster.k8s-small-001.id\n}\n\noutput \"client_key\" {\n  value     = azurerm_kubernetes_cluster.k8s-small-001.kube_config.0.client_key\n  sensitive = true\n}\n\noutput \"cluster_ca_certificate\" {\n  value     = azurerm_kubernetes_cluster.k8s-small-001.kube_config.0.cluster_ca_certificate\n  sensitive = true\n}\n\noutput \"host\" {\n  value     = azurerm_kubernetes_cluster.k8s-small-001.kube_config.0.host\n  sensitive = true\n}\n\n#File: providers.tf\nterraform {\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"3.16.0\"\n    }\n  }\n}\n\nprovider \"azurerm\" {\n  # Configuration options\\\n  features {}\n}\n\n"}]}
{"messages": [{"role": "user", "content": "Create a Google Cloud organization data resource using the specified domain. Generate a unique random ID for the project with a 4-byte length and a prefix based on the provided name. Create a Google Cloud project using the generated ID, specified billing account, and optional folder ID. Enable the Compute Engine API service for the newly created project. Output the organization ID, project ID, and project name for verification."}, {"role": "assistant", "content": "\n#File: main.tf\n# vars\nvariable \"name\" {}\nvariable \"region\" {}\nvariable \"billing_account\" {\n  description = \"The ID of the associated billing account (optional).\"\n}\nvariable \"org_id\" {\n  description = \"The ID of the Google Cloud Organization.\"\n}\nvariable \"domain\" {}\nvariable \"folder\" {\n  default = \"\"\n}\nvariable \"folder_id\" {\n  default = \"\"\n}\n#variable \"credentials_file_path\" {}\n\n# resources\n#provider \"google\" {\n#  region = \"${var.region}\"\n##  credentials = \"${file(\"${var.credentials_file_path}\")}\"\n#}\n\ndata \"google_organization\" \"theorganization\" {\n  domain = \"${var.domain}\"\n}\n\nresource \"random_id\" \"id\" {\n  byte_length = 4\n  prefix      = \"${var.name}-\"\n}\n\nresource \"google_project\" \"project\" {\n  name            = \"${var.name}\"\n  project_id      = \"${random_id.id.hex}\"\n  billing_account = \"${var.billing_account}\"\n  folder_id       = \"${var.folder_id}\"\n}\n\nresource \"google_project_service\" \"project_compute_service\" {\n  project = \"${google_project.project.project_id}\"\n  service = \"compute.googleapis.com\"\n}\n#resource \"google_project_service\" \"project_iam_service\" {\n#  project = \"${google_project.project.project_id}\"\n#  service = \"iam.googleapis.com\"\n#}\n#resource \"google_project_service\" \"project_sqladmin_service\" {\n#  project = \"${google_project.project.project_id}\"\n#  service = \"sqladmin.googleapis.com\"\n#}\n\n# outputs\noutput \"org_id\" {\n  value = \"${data.google_organization.theorganization.id}\"\n}\noutput \"project_id\" {\n  value = \"${google_project.project.id}\"\n}\noutput \"name\" {\n  value = \"${google_project.project.name}\"\n}\n"}]}
{"messages": [{"role":"user","content":"Define a variable instance_name with a default value used for naming an EC2 instance. It configures the AWS provider with default settings. The resource aws_instance.app_server creates a t2.micro EC2 instance using a specified AMI, tagging it with the name provided by the instance_name variable."},{"role":"assistant","content":"\r\nvariable \"instance_name\" {\r\n  description = \"Value of the Name tag for the EC2 instance\"\r\n  type        = string\r\n  default     = \"ExampleAppServerInstance\"\r\n}\r\nprovider \"aws\" {\r\n\r\n}\r\n\r\n\r\n\r\nresource \"aws_instance\" \"app_server\" {\r\n  ami           = \"ami-830c94e3\"\r\n  instance_type = \"t2.micro\"\r\n\r\n  tags = {\r\n    Name = var.instance_name\r\n  }\r\n}"}]}
{"messages": [{"role":"user","content":"Define a configuration with an AWS Lambda function with customizable deployment options, including local or S3-based source code, environment variables, VPC settings, and resource limits like memory and timeout. Create an IAM role with the necessary trust policy for Lambda execution and attaches the basic execution role and optional VPC access policy if VPC configuration is provided. Use variables to allow flexible parameterization of the Lambda function, including function name, handler, runtime, and tagging."},{"role":"assistant","content":"data \"aws_region\" \"current\" {\r\n}\r\n\r\nresource \"aws_lambda_function\" \"lambda\" {\r\n  description = var.description\r\n  dynamic \"environment\" {\r\n    for_each = length(var.environment) < 1 ? [] : [var.environment]\r\n    content {\r\n      variables = environment.value.variables\r\n    }\r\n  }\r\n  filename                       = var.s3_bucket == \"\" ? var.filename : null\r\n  function_name                  = var.function_name\r\n  handler                        = var.handler\r\n  memory_size                    = var.memory_size\r\n  publish                        = var.publish\r\n  reserved_concurrent_executions = var.reserved_concurrent_executions\r\n  role                           = aws_iam_role.lambda.arn\r\n  runtime                        = var.runtime\r\n  s3_bucket                      = var.filename == \"\" ? var.s3_bucket : null\r\n  s3_key                         = var.filename == \"\" ? var.s3_key : null\r\n  s3_object_version              = var.filename == \"\" ? var.s3_object_version : null\r\n  source_code_hash               = var.source_code_hash\r\n  tags                           = var.tags\r\n  timeout                        = var.timeout\r\n\r\n  dynamic \"vpc_config\" {\r\n    for_each = length(var.vpc_config) < 1 ? [] : [var.vpc_config]\r\n    content {\r\n      security_group_ids = vpc_config.value.security_group_ids\r\n      subnet_ids         = vpc_config.value.subnet_ids\r\n    }\r\n  }\r\n}\r\n\r\ndata \"aws_iam_policy_document\" \"assume_role_policy\" {\r\n  statement {\r\n    actions = [\"sts:AssumeRole\"]\r\n\r\n    principals {\r\n      type        = \"Service\"\r\n      identifiers = [\"lambda.amazonaws.com\"]\r\n    }\r\n  }\r\n}\r\n\r\nresource \"aws_iam_role\" \"lambda\" {\r\n  name               = \"${var.function_name}-${data.aws_region.current.name}\"\r\n  assume_role_policy = data.aws_iam_policy_document.assume_role_policy.json\r\n}\r\n\r\nresource \"aws_iam_role_policy_attachment\" \"cloudwatch_logs\" {\r\n  role       = aws_iam_role.lambda.name\r\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\r\n}\r\n\r\nresource \"aws_iam_role_policy_attachment\" \"vpc_attachment\" {\r\n  count = length(var.vpc_config) < 1 ? 0 : 1\r\n  role  = aws_iam_role.lambda.name\r\n\r\n  // see https://docs.aws.amazon.com/lambda/latest/dg/vpc.html\r\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole\"\r\n}\r\n\r\n# ---------------------------------------------------------------------------------------------------------------------\r\n# REQUIRED PARAMETERS\r\n# You must provide a value for each of these parameters.\r\n# ---------------------------------------------------------------------------------------------------------------------\r\n\r\nvariable \"filename\" {\r\n  description = \"The path to the function's deployment package within the local filesystem.\"\r\n}\r\n\r\nvariable \"function_name\" {\r\n  description = \"A unique name for your Lambda Function.\"\r\n}\r\n\r\nvariable \"handler\" {\r\n  description = \"The function entrypoint in your code.\"\r\n}\r\n\r\nvariable \"runtime\" {\r\n  description = \"The runtime environment for the Lambda function you are uploading.\"\r\n}\r\n\r\n# ---------------------------------------------------------------------------------------------------------------------\r\n# OPTIONAL PARAMETERS\r\n# These parameters have reasonable defaults.\r\n# ---------------------------------------------------------------------------------------------------------------------\r\n\r\nvariable \"description\" {\r\n  description = \"Description of what your Lambda Function does.\"\r\n  default     = \"\"\r\n}\r\n\r\nvariable \"environment\" {\r\n  description = \"Environment (e.g. env variables) configuration for the Lambda function enable you to dynamically pass settings to your function code and libraries\"\r\n  type        = map(map(string))\r\n  default     = {}\r\n}\r\n\r\nvariable \"memory_size\" {\r\n  description = \"Amount of memory in MB your Lambda Function can use at runtime. Defaults to 128.\"\r\n  default     = 128\r\n}\r\n\r\nvariable \"publish\" {\r\n  description = \"Whether to publish creation/change as new Lambda Function Version. Defaults to false.\"\r\n  default     = false\r\n}\r\n\r\nvariable \"reserved_concurrent_executions\" {\r\n  description = \"The amount of reserved concurrent executions for this lambda function. A value of 0 disables lambda from being triggered and -1 removes any concurrency limitations. Defaults to Unreserved Concurrency Limits -1.\"\r\n  default     = \"-1\"\r\n}\r\n\r\nvariable \"s3_bucket\" {\r\n  description = \"The S3 bucket location containing the function's deployment package. Conflicts with filename. This bucket must reside in the same AWS region where you are creating the Lambda function.\"\r\n  default     = \"\"\r\n}\r\n\r\nvariable \"s3_key\" {\r\n  description = \" The S3 key of an object containing the function's deployment package. Conflicts with filename.\"\r\n  default     = \"\"\r\n}\r\n\r\nvariable \"s3_object_version\" {\r\n  description = \"The object version containing the function's deployment package. Conflicts with filename.\"\r\n  default     = \"\"\r\n}\r\n\r\nvariable \"source_code_hash\" {\r\n  description = \"Used to trigger updates. Must be set to a base64-encoded SHA256 hash of the package file specified with either filename or s3_key. The usual way to set this is filebase64sha256('file.zip') where 'file.zip' is the local filename of the lambda function source archive.\"\r\n  default     = \"\"\r\n}\r\n\r\nvariable \"tags\" {\r\n  description = \"A mapping of tags to assign to the Lambda function.\"\r\n  type        = map(string)\r\n  default     = {}\r\n}\r\n\r\nvariable \"timeout\" {\r\n  description = \"The amount of time your Lambda Function has to run in seconds. Defaults to 3.\"\r\n  default     = 3\r\n}\r\n\r\nvariable \"vpc_config\" {\r\n  description = \"Provide this to allow your function to access your VPC (if both 'subnet_ids' and 'security_group_ids' are empty then vpc_config is considered to be empty or unset, see https://docs.aws.amazon.com/lambda/latest/dg/vpc.html for details).\"\r\n  type        = map(list(string))\r\n  default     = {}\r\n}\r\n\r\n"}]}
{"messages": [{"role": "user", "content": "Create an Azure Resource Group named \"rg-demo\" in the \"West Europe\" location. Create an Azure Container Registry named \"crdemotf01\" within the resource group. Create an Azure API Management instance named \"apim-sync-openapi-defs-demo\" and configure it with the necessary publisher information. Import two APIs named \"app-a-webapi\" and \"app-b-webapi\" into the API Management instance from specified OpenAPI definitions. Create two Azure Container Apps, \"ca-app-a\" and \"ca-app-b\", connecting them to the Container Registry and configure necessary settings for startup, readiness, and liveness probes."}, {"role": "assistant", "content": "\n#File: acr.tf\n# Create acr\nresource \"azurerm_container_registry\" \"acr\" {\n    name                    = \"crdemotf01\"\n    resource_group_name     = azurerm_resource_group.rg.name\n    location                = azurerm_resource_group.rg.location\n    sku                     = \"Standard\"\n}\n#File: apim-products.tf\nresource \"azurerm_api_management_product\" \"demo\" {\n  product_id            = \"Demo\"\n  api_management_name   = azurerm_api_management.apim.name\n  resource_group_name   = azurerm_resource_group.rg.name\n  display_name          = \"Demo APIs\"\n  subscription_required = false\n  approval_required     = false\n  published             = true\n}\n\nresource \"azurerm_api_management_product_api\" \"demo_product_app_a_assignment\" {\n  api_name            = azurerm_api_management_api.apim_app_a_api.name\n  product_id          = azurerm_api_management_product.demo.product_id\n  api_management_name = azurerm_api_management.apim.name\n  resource_group_name = azurerm_resource_group.rg.name\n}\n\nresource \"azurerm_api_management_product_api\" \"demo_product_app_b_assignment\" {\n  api_name            = azurerm_api_management_api.apim_app_b_api.name\n  product_id          = azurerm_api_management_product.demo.product_id\n  api_management_name = azurerm_api_management.apim.name\n  resource_group_name = azurerm_resource_group.rg.name\n}\n\n#File: apim.tf\n## Create APIM\nresource \"azurerm_api_management\" \"apim\" {\n    name                = \"apim-sync-openapi-defs-demo\"\n    location            = azurerm_resource_group.rg.location\n    resource_group_name = azurerm_resource_group.rg.name\n    publisher_name      = \"mytechramblings\"\n    publisher_email     = \"me@mytechramblings.com\"\n    sku_name            = \"Developer_1\"\n}\n\n## Import App A to APIM using directly the OpenApi import feature\nresource \"azurerm_api_management_api\" \"apim_app_a_api\" {\n  name                = \"app-a-webapi\"\n  resource_group_name = azurerm_resource_group.rg.name\n  api_management_name = azurerm_api_management.apim.name\n  revision            = \"1\"\n  display_name        = \"app-a-webapi\"\n  path                = \"app-a\"\n  protocols           = [\"https\"]\n  service_url         = \"https://${azurerm_container_app.aca_app_a.ingress[0].fqdn}\"\n  subscription_required = false\n\n  import {\n    content_format = \"openapi+json-link\"\n    content_value  = \"https://${azurerm_container_app.aca_app_a.ingress[0].fqdn}/swagger/v1/swagger.json\"\n  }\n}\n\n## Import App B to APIM using OpenApi alongside with the Terraform http resource\ndata \"http\" \"apim_app_b_openapi\" {\n  url = \"https://${azurerm_container_app.aca_app_b.ingress[0].fqdn}/swagger/v1/swagger.json\"\n  request_headers = {\n    Accept = \"application/json\"\n  }\n}\n\n## Import App B to APIM using OpenApi alongside with the Terraform http resource\nresource \"azurerm_api_management_api\" \"apim_app_b_api\" {\n  name                = \"app-b-webapi\"\n  resource_group_name = azurerm_resource_group.rg.name\n  api_management_name = azurerm_api_management.apim.name\n  revision            = \"1\"\n  display_name        = \"app-b-webapi\"\n  path                = \"app-b\"\n  protocols           = [\"https\"]\n  service_url         = \"https://${azurerm_container_app.aca_app_b.ingress[0].fqdn}\"\n  subscription_required = false\n\n  import {\n    content_format = \"openapi+json\"\n    content_value  = data.http.apim_app_b_openapi.response_body\n  }\n}\n#File: container_apps.tf\n## Create Azure Container Apps Environment\nresource \"azurerm_container_app_environment\" \"aca_env\" {\n  name                       = \"cae-demo\"\n  location                   = azurerm_resource_group.rg.location\n  resource_group_name        = azurerm_resource_group.rg.name\n}\n\n## Create container app for app A\nresource \"azurerm_container_app\" \"aca_app_a\" {\n    name                         = \"ca-app-a\"\n    container_app_environment_id = azurerm_container_app_environment.aca_env.id\n    resource_group_name          = azurerm_resource_group.rg.name\n    revision_mode                = \"Single\"\n\n    template {\n        container {\n            name   = \"app-a-webapi\"\n            image  = \"${azurerm_container_registry.acr.login_server}/app-a-webapi\"\n            cpu    = 0.5\n            memory = \"1Gi\"\n            \n            startup_probe {\n                port                    = 8080\n                transport               = \"HTTP\"\n                path                    = \"/health\"\n                timeout                 = 240\n                interval_seconds        = 30\n                failure_count_threshold = 10    \n            }\n\n            readiness_probe {\n                port                    = 8080\n                transport               = \"HTTP\"\n                path                    = \"/health\"\n                timeout                 = 60\n                interval_seconds        = 10\n                failure_count_threshold = 3\n            }\n\n            liveness_probe {\n                port                    = 8080\n                transport               = \"HTTP\"\n                path                    = \"/health\"\n                timeout                 = 60\n                initial_delay           = 30   \n                interval_seconds        = 10\n                failure_count_threshold = 3\n            }\n        }\n\n        max_replicas =  1\n        min_replicas =  1   \n    }\n\n    registry {\n        server = azurerm_container_registry.acr.login_server\n        identity = azurerm_user_assigned_identity.aca_apps_user_assigned_identity.id\n    }\n\n    ingress {\n        allow_insecure_connections = false\n        external_enabled = true\n        target_port = 8080\n        transport = \"http\"\n        \n        traffic_weight {\n          latest_revision = true\n          percentage = 100\n        }\n    }\n\n    identity {\n      type = \"UserAssigned\"\n      identity_ids = [ azurerm_user_assigned_identity.aca_apps_user_assigned_identity.id ]\n    }\n\n    depends_on = [ \n        azurerm_role_assignment.user_assigned_identity_acrpull_role_assignment,\n        null_resource.container_image_app_a\n    ]\n}\n\n\n## Create container app for app B\nresource \"azurerm_container_app\" \"aca_app_b\" {\n    name                         = \"ca-app-b\"\n    container_app_environment_id = azurerm_container_app_environment.aca_env.id\n    resource_group_name          = azurerm_resource_group.rg.name\n    revision_mode                = \"Single\"\n\n    template {\n        container {\n            name   = \"app-b\"\n            image  = \"${azurerm_container_registry.acr.login_server}/app-b-webapi\"\n            cpu    = 0.5\n            memory = \"1Gi\"\n            \n            startup_probe {\n                port                    = 8080\n                transport               = \"HTTP\"\n                path                    = \"/health\"\n                timeout                 = 240\n                interval_seconds        = 30\n                failure_count_threshold = 10    \n            }\n\n            readiness_probe {\n                port                    = 8080\n                transport               = \"HTTP\"\n                path                    = \"/health\"\n                timeout                 = 60\n                interval_seconds        = 10\n                failure_count_threshold = 3\n            }\n\n            liveness_probe {\n                port                    = 8080\n                transport               = \"HTTP\"\n                path                    = \"/health\"\n                timeout                 = 60\n                initial_delay           = 30   \n                interval_seconds        = 10\n                failure_count_threshold = 3\n            }\n        }\n\n        max_replicas =  1\n        min_replicas =  1   \n    }\n\n    registry {\n        server = azurerm_container_registry.acr.login_server\n        identity = azurerm_user_assigned_identity.aca_apps_user_assigned_identity.id\n    }\n\n    ingress {\n        allow_insecure_connections = false\n        external_enabled = true\n        target_port = 8080\n        transport = \"http\"\n        \n        traffic_weight {\n          latest_revision = true\n          percentage = 100\n        }\n    }\n\n    identity {\n      type = \"UserAssigned\"\n      identity_ids = [ azurerm_user_assigned_identity.aca_apps_user_assigned_identity.id ]\n    }\n\n    depends_on = [ \n        azurerm_role_assignment.user_assigned_identity_acrpull_role_assignment,\n        null_resource.container_image_app_b\n    ]\n}\n\n\n#File: container_images.tf\nlocals {\n  app_a_image_name = \"app-a-webapi\"\n  app_a_image_tag = \"latest\"\n  app_b_image_name = \"app-b-webapi\"\n  app_b_image_tag = \"latest\"\n}\n\n# Create container image for app A and push it to ACR\nresource \"null_resource\" \"container_image_app_a\" {\n    triggers = {\n        image_name = local.app_a_image_name\n        image_tag = local.app_a_image_tag\n        registry_name = azurerm_container_registry.acr.name\n        dockerfile_path = \"${path.cwd}/AppA.WebApi/Dockerfile\"\n        dockerfile_context = \"${path.cwd}/AppA.WebApi\"\n        dir_sha1 = sha1(join(\"\", [for f in fileset(path.cwd, \"AppA.WebApi/*\") : filesha1(f)]))\n    }\n    provisioner \"local-exec\" {\n        command = \"./scripts/docker_build_and_push_to_acr.sh ${self.triggers.image_name} ${self.triggers.image_tag} ${self.triggers.registry_name} ${self.triggers.dockerfile_path} ${self.triggers.dockerfile_context}\" \n        interpreter = [\"bash\", \"-c\"]\n    }\n}\n\n# Create container image for app B and push it to ACR\nresource \"null_resource\" \"container_image_app_b\" {\n    triggers = {\n        image_name = local.app_b_image_name\n        image_tag = local.app_b_image_tag\n        registry_name = azurerm_container_registry.acr.name\n        dockerfile_path = \"${path.cwd}/AppB.WebApi/Dockerfile\"\n        dockerfile_context = \"${path.cwd}/AppB.WebApi\"\n        dir_sha1 = sha1(join(\"\", [for f in fileset(path.cwd, \"AppB.WebApi/*\") : filesha1(f)]))\n    }\n    provisioner \"local-exec\" {\n        command = \"./scripts/docker_build_and_push_to_acr.sh ${self.triggers.image_name} ${self.triggers.image_tag} ${self.triggers.registry_name} ${self.triggers.dockerfile_path} ${self.triggers.dockerfile_context}\" \n        interpreter = [\"bash\", \"-c\"]\n    }\n}\n#File: identity.tf\n## Create an User Assigned Identity with ACRPull permissions to attach it to the container apps\nresource \"azurerm_user_assigned_identity\" \"aca_apps_user_assigned_identity\" {\n  resource_group_name = azurerm_resource_group.rg.name\n  location            = azurerm_resource_group.rg.location\n  name                = \"id-aca-acrpush\"\n}\n\n# Add ACRPull permission to user assigned identity\nresource \"azurerm_role_assignment\" \"user_assigned_identity_acrpull_role_assignment\" {\n  scope                = azurerm_container_registry.acr.id\n  role_definition_name = \"AcrPull\"\n  principal_id         = azurerm_user_assigned_identity.aca_apps_user_assigned_identity.principal_id\n}\n\n#File: providers.tf\nterraform {\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \">=3.88.0\"\n    }\n  }\n}\n\nprovider \"azurerm\" {\n  features {}\n}\n#File: resource_group.tf\n# Create resource group\nresource \"azurerm_resource_group\" \"rg\" {\n    name      = \"rg-demo\"\n    location  = \"West Europe\"\n}"}]}
{"messages": [{"role": "user", "content": "Create an Azure Resource Group for your resources using the specified name and location. Set up a Network Security Group with inbound rules to allow SSH, Jenkins UI, and Jenkins slave traffic. Establish a Virtual Network with an address space for the Jenkins deployment. Create a Subnet within that Virtual Network and associate it with the Network Security Group. Finally, deploy a Linux Virtual Machine with the specified size, username, and SSH key for admin access."}, {"role": "assistant", "content": "\n#File: main.tf\nresource \"azurerm_resource_group\" \"this\" {\n  name     = var.resource_group_name\n  location = var.location\n}\n\nresource \"azurerm_network_security_group\" \"this\" {\n  name                = \"jenkins_nsg\"\n  location            = var.location\n  resource_group_name = azurerm_resource_group.this.name\n\n  security_rule {\n    name                       = \"allow_ssh\"\n    priority                   = 1001\n    direction                  = \"Inbound\"\n    access                     = \"Allow\"\n    protocol                   = \"Tcp\"\n    source_port_range          = \"*\"\n    destination_port_range     = \"22\"\n    source_address_prefix      = \"*\"\n    destination_address_prefix = \"*\"\n  }\n\n  security_rule {\n    name                       = \"allow_jenkins_ui\"\n    priority                   = 1002\n    direction                  = \"Inbound\"\n    access                     = \"Allow\"\n    protocol                   = \"Tcp\"\n    source_port_range          = \"*\"\n    destination_port_range     = \"8080\"\n    source_address_prefix      = \"*\"\n    destination_address_prefix = \"*\"\n  }\n\n  security_rule {\n    name                       = \"allow_jenkins_slave\"\n    priority                   = 1003\n    direction                  = \"Inbound\"\n    access                     = \"Allow\"\n    protocol                   = \"Tcp\"\n    source_port_range          = \"*\"\n    destination_port_range     = \"50000\"\n    source_address_prefix      = \"*\"\n    destination_address_prefix = \"*\"\n  }\n}\n\nresource \"azurerm_virtual_network\" \"this\" {\n  name                = \"jenkins_vnet\"\n  location            = var.location\n  resource_group_name = azurerm_resource_group.this.name\n  address_space       = [\"10.0.0.0/16\"]\n}\n\nresource \"azurerm_subnet\" \"this\" {\n  name                 = \"jenkins_subnet\"\n  resource_group_name  = var.resource_group_name\n  address_prefixes     = [\"10.0.1.0/24\"]\n  virtual_network_name = azurerm_virtual_network.this.name\n}\n\nresource \"azurerm_subnet_network_security_group_association\" \"jenkins_subnet_nsg_association\" {\n  subnet_id                 = azurerm_subnet.this.id\n  network_security_group_id = azurerm_network_security_group.this.id\n}\n\nresource \"azurerm_public_ip\" \"this\" {\n  name                = \"jenkins_public_ip\"\n  resource_group_name = azurerm_resource_group.this.name\n  location            = var.location\n  allocation_method   = \"Static\"\n}\n\nresource \"azurerm_network_interface\" \"this\" {\n  name                = \"jenkins_nic\"\n  location            = var.location\n  resource_group_name = azurerm_resource_group.this.name\n\n  ip_configuration {\n    name                          = \"internal\"\n    subnet_id                     = azurerm_subnet.this.id\n    private_ip_address_allocation = \"Dynamic\"\n    public_ip_address_id          = azurerm_public_ip.this.id\n  }\n}\n\nresource \"azurerm_linux_virtual_machine\" \"this\" {\n  name                = \"jenkinsVm\"\n  resource_group_name = azurerm_resource_group.this.name\n  location            = var.location\n  size                = \"Standard_B2s\"\n  admin_username      = var.admin_username\n\n  admin_ssh_key {\n    username   = \"tarek\"\n    public_key = file(var.public_key_path)\n  }\n\n  network_interface_ids = [\n    azurerm_network_interface.this.id,\n  ]\n\n  os_disk {\n    name                 = \"jenkins_os_disk\"\n    caching              = \"None\"\n    storage_account_type = \"Standard_LRS\"\n    disk_size_gb         = \"30\"\n  }\n\n  source_image_reference {\n    publisher = \"Canonical\"\n    offer     = \"0001-com-ubuntu-server-jammy\"\n    sku       = \"22_04-lts\"\n    version   = \"latest\"\n  }\n\n}\n\n#File: outputs.tf\noutput \"public_ip_address\" {\n  description = \"the public IP address of the Jenkins VM\"\n  value       = azurerm_public_ip.this.ip_address\n}\n#File: provider.tf\nterraform {\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"=3.0.0\"\n    }\n  }\n}\n\nprovider \"azurerm\" {\n  features {}\n}\n\n#File: variables.tf\nvariable \"resource_group_name\" {\n  description = \"The name of the resource group in which to create the resources\"\n  type        = string\n}\n\nvariable \"location\" {\n  description = \"The location in which to create the resources\"\n  type        = string\n}\n\nvariable \"admin_username\" {\n  description = \"The username of the VM admin user \"\n  type        = string\n}\n\nvariable \"public_key_path\" {\n  description = \"The path to the public key used to authenticate the VM admin user\"\n  type        = string\n}\n"}]}
{"messages": [{"role":"user","content":"Define an AWS ECR registry scanning setup that conditionally enables enhanced or basic image scanning with customizable scan rules and repository filters. It integrates the cloudposse/terraform-null-label module to generate consistent resource naming and tagging conventions based on a flexible context and various label settings. The configuration validates inputs for scan types and frequencies, ensuring proper and safe deployment of scanning configurations alongside standardized labels and tags."},{"role":"assistant","content":"\r\nresource \"aws_ecr_registry_scanning_configuration\" \"default\" {\r\n  count     = module.this.enabled && var.scan_config != null ? 1 : 0\r\n  scan_type = var.scan_config.scan_type\r\n\r\n  dynamic \"rule\" {\r\n    for_each = var.scan_config.rules\r\n    content {\r\n      scan_frequency = rule.value.scan_frequency\r\n      dynamic \"repository_filter\" {\r\n        for_each = rule.value.repository_filter\r\n        content {\r\n          filter      = repository_filter.value.filter\r\n          filter_type = repository_filter.value.filter_type\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\nvariable \"scan_config\" {\r\n  description = \"Scan configuration for ECR\"\r\n  type = object({\r\n    scan_type = string\r\n    rules = list(object({\r\n      scan_frequency = string\r\n      repository_filter = list(object({\r\n        filter      = string\r\n        filter_type = optional(string, \"WILDCARD\")\r\n      }))\r\n    }))\r\n  })\r\n  validation {\r\n    condition     = var.scan_config == null || contains([\"ENHANCED\", \"BASIC\"], var.scan_config.scan_type)\r\n    error_message = \"scan_type must be either ENHANCED or BASIC\"\r\n  }\r\n  # validate scan_frequency is set to SCAN_ON_PUSH, MANUAL, or CONTINUOUS_SCAN\r\n  validation {\r\n    condition     = var.scan_config == null || alltrue([for rule in var.scan_config.rules : contains([\"SCAN_ON_PUSH\", \"MANUAL\", \"CONTINUOUS_SCAN\"], rule.scan_frequency)])\r\n    error_message = \"scan_frequency must be either SCAN_ON_PUSH, MANUAL, or CONTINUOUS_SCAN\"\r\n  }\r\n  default = null\r\n}\r\n\r\nmodule \"this\" {\r\n  source  = \"cloudposse/label/null\"\r\n\r\n  enabled             = var.enabled\r\n  namespace           = var.namespace\r\n  tenant              = var.tenant\r\n  environment         = var.environment\r\n  stage               = var.stage\r\n  name                = var.name\r\n  delimiter           = var.delimiter\r\n  attributes          = var.attributes\r\n  tags                = var.tags\r\n  additional_tag_map  = var.additional_tag_map\r\n  label_order         = var.label_order\r\n  regex_replace_chars = var.regex_replace_chars\r\n  id_length_limit     = var.id_length_limit\r\n  label_key_case      = var.label_key_case\r\n  label_value_case    = var.label_value_case\r\n  descriptor_formats  = var.descriptor_formats\r\n  labels_as_tags      = var.labels_as_tags\r\n\r\n  context = var.context\r\n}\r\n\r\n\r\nvariable \"context\" {\r\n  type = any\r\n  default = {\r\n    enabled             = true\r\n    namespace           = null\r\n    tenant              = null\r\n    environment         = null\r\n    stage               = null\r\n    name                = null\r\n    delimiter           = null\r\n    attributes          = []\r\n    tags                = {}\r\n    additional_tag_map  = {}\r\n    regex_replace_chars = null\r\n    label_order         = []\r\n    id_length_limit     = null\r\n    label_key_case      = null\r\n    label_value_case    = null\r\n    descriptor_formats  = {}\r\n    # Note: we have to use [] instead of null for unset lists due to\r\n    # https://github.com/hashicorp/terraform/issues/28137\r\n    # which was not fixed until Terraform 1.0.0,\r\n    # but we want the default to be all the labels in `label_order`\r\n    # and we want users to be able to prevent all tag generation\r\n    # by setting `labels_as_tags` to `[]`, so we need\r\n    # a different sentinel to indicate \"default\"\r\n    labels_as_tags = [\"unset\"]\r\n  }\r\n  description = <<-EOT\r\n    Single object for setting entire context at once.\r\n    See description of individual variables for details.\r\n    Leave string and numeric variables as `null` to use default value.\r\n    Individual variable settings (non-null) override settings in context object,\r\n    except for attributes, tags, and additional_tag_map, which are merged.\r\n  EOT\r\n\r\n  validation {\r\n    condition     = lookup(var.context, \"label_key_case\", null) == null ? true : contains([\"lower\", \"title\", \"upper\"], var.context[\"label_key_case\"])\r\n    error_message = \"Allowed values: `lower`, `title`, `upper`.\"\r\n  }\r\n\r\n  validation {\r\n    condition     = lookup(var.context, \"label_value_case\", null) == null ? true : contains([\"lower\", \"title\", \"upper\", \"none\"], var.context[\"label_value_case\"])\r\n    error_message = \"Allowed values: `lower`, `title`, `upper`, `none`.\"\r\n  }\r\n}\r\n\r\nvariable \"enabled\" {\r\n  type        = bool\r\n  default     = null\r\n  description = \"Set to false to prevent the module from creating any resources\"\r\n}\r\n\r\nvariable \"namespace\" {\r\n  type        = string\r\n  default     = null\r\n  description = \"ID element. Usually an abbreviation of your organization name, e.g. 'eg' or 'cp', to help ensure generated IDs are globally unique\"\r\n}\r\n\r\nvariable \"tenant\" {\r\n  type        = string\r\n  default     = null\r\n  description = \"ID element _(Rarely used, not included by default)_. A customer identifier, indicating who this instance of a resource is for\"\r\n}\r\n\r\nvariable \"environment\" {\r\n  type        = string\r\n  default     = null\r\n  description = \"ID element. Usually used for region e.g. 'uw2', 'us-west-2', OR role 'prod', 'staging', 'dev', 'UAT'\"\r\n}\r\n\r\nvariable \"stage\" {\r\n  type        = string\r\n  default     = null\r\n  description = \"ID element. Usually used to indicate role, e.g. 'prod', 'staging', 'source', 'build', 'test', 'deploy', 'release'\"\r\n}\r\n\r\nvariable \"name\" {\r\n  type        = string\r\n  default     = null\r\n  description = <<-EOT\r\n    ID element. Usually the component or solution name, e.g. 'app' or 'jenkins'.\r\n    This is the only ID element not also included as a `tag`.\r\n    The \"name\" tag is set to the full `id` string. There is no tag with the value of the `name` input.\r\n    EOT\r\n}\r\n\r\nvariable \"delimiter\" {\r\n  type        = string\r\n  default     = null\r\n  description = <<-EOT\r\n    Delimiter to be used between ID elements.\r\n    Defaults to `-` (hyphen). Set to `\"\"` to use no delimiter at all.\r\n  EOT\r\n}\r\n\r\nvariable \"attributes\" {\r\n  type        = list(string)\r\n  default     = []\r\n  description = <<-EOT\r\n    ID element. Additional attributes (e.g. `workers` or `cluster`) to add to `id`,\r\n    in the order they appear in the list. New attributes are appended to the\r\n    end of the list. The elements of the list are joined by the `delimiter`\r\n    and treated as a single ID element.\r\n    EOT\r\n}\r\n\r\nvariable \"labels_as_tags\" {\r\n  type        = set(string)\r\n  default     = [\"default\"]\r\n  description = <<-EOT\r\n    Set of labels (ID elements) to include as tags in the `tags` output.\r\n    Default is to include all labels.\r\n    Tags with empty values will not be included in the `tags` output.\r\n    Set to `[]` to suppress all generated tags.\r\n    **Notes:**\r\n      The value of the `name` tag, if included, will be the `id`, not the `name`.\r\n      Unlike other `null-label` inputs, the initial setting of `labels_as_tags` cannot be\r\n      changed in later chained modules. Attempts to change it will be silently ignored.\r\n    EOT\r\n}\r\n\r\nvariable \"tags\" {\r\n  type        = map(string)\r\n  default     = {}\r\n  description = <<-EOT\r\n    Additional tags (e.g. `{'BusinessUnit': 'XYZ'}`).\r\n    Neither the tag keys nor the tag values will be modified by this module.\r\n    EOT\r\n}\r\n\r\nvariable \"additional_tag_map\" {\r\n  type        = map(string)\r\n  default     = {}\r\n  description = <<-EOT\r\n    Additional key-value pairs to add to each map in `tags_as_list_of_maps`. Not added to `tags` or `id`.\r\n    This is for some rare cases where resources want additional configuration of tags\r\n    and therefore take a list of maps with tag key, value, and additional configuration.\r\n    EOT\r\n}\r\n\r\nvariable \"label_order\" {\r\n  type        = list(string)\r\n  default     = null\r\n  description = <<-EOT\r\n    The order in which the labels (ID elements) appear in the `id`.\r\n    Defaults to [\"namespace\", \"environment\", \"stage\", \"name\", \"attributes\"].\r\n    You can omit any of the 6 labels (\"tenant\" is the 6th), but at least one must be present.\r\n    EOT\r\n}\r\n\r\nvariable \"regex_replace_chars\" {\r\n  type        = string\r\n  default     = null\r\n  description = <<-EOT\r\n    Terraform regular expression (regex) string.\r\n    Characters matching the regex will be removed from the ID elements.\r\n    If not set, `\"/[^a-zA-Z0-9-]/\"` is used to remove all characters other than hyphens, letters and digits.\r\n  EOT\r\n}\r\n\r\nvariable \"id_length_limit\" {\r\n  type        = number\r\n  default     = null\r\n  description = <<-EOT\r\n    Limit `id` to this many characters (minimum 6).\r\n    Set to `0` for unlimited length.\r\n    Set to `null` for keep the existing setting, which defaults to `0`.\r\n    Does not affect `id_full`.\r\n  EOT\r\n  validation {\r\n    condition     = var.id_length_limit == null ? true : var.id_length_limit >= 6 || var.id_length_limit == 0\r\n    error_message = \"The id_length_limit must be >= 6 if supplied (not null), or 0 for unlimited length.\"\r\n  }\r\n}\r\n\r\nvariable \"label_key_case\" {\r\n  type        = string\r\n  default     = null\r\n  description = <<-EOT\r\n    Controls the letter case of the `tags` keys (label names) for tags generated by this module.\r\n    Does not affect keys of tags passed in via the `tags` input.\r\n    Possible values: `lower`, `title`, `upper`.\r\n    Default value: `title`.\r\n  EOT\r\n\r\n  validation {\r\n    condition     = var.label_key_case == null ? true : contains([\"lower\", \"title\", \"upper\"], var.label_key_case)\r\n    error_message = \"Allowed values: `lower`, `title`, `upper`.\"\r\n  }\r\n}\r\n\r\nvariable \"label_value_case\" {\r\n  type        = string\r\n  default     = null\r\n  description = <<-EOT\r\n    Controls the letter case of ID elements (labels) as included in `id`,\r\n    set as tag values, and output by this module individually.\r\n    Does not affect values of tags passed in via the `tags` input.\r\n    Possible values: `lower`, `title`, `upper` and `none` (no transformation).\r\n    Set this to `title` and set `delimiter` to `\"\"` to yield Pascal Case IDs.\r\n    Default value: `lower`.\r\n  EOT\r\n\r\n  validation {\r\n    condition     = var.label_value_case == null ? true : contains([\"lower\", \"title\", \"upper\", \"none\"], var.label_value_case)\r\n    error_message = \"Allowed values: `lower`, `title`, `upper`, `none`.\"\r\n  }\r\n}\r\n\r\nvariable \"descriptor_formats\" {\r\n  type        = any\r\n  default     = {}\r\n  description = <<-EOT\r\n    Describe additional descriptors to be output in the `descriptors` output map.\r\n    Map of maps. Keys are names of descriptors. Values are maps of the form\r\n    `{\r\n       format = string\r\n       labels = list(string)\r\n    }`\r\n    (Type is `any` so the map values can later be enhanced to provide additional options.)\r\n    `format` is a Terraform format string to be passed to the `format()` function.\r\n    `labels` is a list of labels, in order, to pass to `format()` function.\r\n    Label values will be normalized before being passed to `format()` so they will be\r\n    identical to how they appear in `id`.\r\n    Default is `{}` (`descriptors` output will be empty).\r\n    EOT\r\n}\r\n"}]}
{"messages": [{"role": "user", "content": "Create a Private DNS Zone Virtual Network Link for PostgreSQL. Set up a PostgreSQL Public Flexible Server with specified configurations, ensuring public network access is disabled. Establish a Private Endpoint linked to the PostgreSQL server and configure the Private DNS Zone settings. Create PostgreSQL Firewall Rules for both Azure services and general access, and enable necessary PostgreSQL extensions. Finally, output the server and database names for reference."}, {"role": "assistant", "content": "\n#File: database-private-endpoint.tf\n##############################################\n## PostgresSQL Private Endpoint - Resources ##\n##############################################\n\n# Create Private DNS Zone Virtual Network Link for PostgreSQL\nresource \"azurerm_private_dns_zone_virtual_network_link\" \"pe\" {\n  name                  = \"${lower(replace(var.company,\" \",\"-\"))}-${var.app_name}-${var.environment}-pe-vnet-link\"\n  resource_group_name   = data.azurerm_private_dns_zone.postgres_dns_zone.resource_group_name\n  private_dns_zone_name = data.azurerm_private_dns_zone.postgres_dns_zone.name\n  virtual_network_id    = azurerm_virtual_network.this.id\n\n  depends_on = [ azurerm_subnet.pe, azurerm_virtual_network.this ]\n}\n\n# Create PostgreSQL Public Flexible Server\nresource \"azurerm_postgresql_flexible_server\" \"pe\" {\n  name                = \"${lower(replace(var.company,\" \",\"-\"))}-${var.app_name}-${var.environment}-postgresql-pe\"\n  location            = azurerm_resource_group.this.location\n  resource_group_name = azurerm_resource_group.this.name\n\n  version  = var.postgres_server_version\n  sku_name = var.postgres_server_sku\n  \n  public_network_access_enabled = false\n\n  administrator_login    = var.postgres_user\n  administrator_password = var.postgres_password\n  \n  storage_mb   = var.postgres_server_storage_mb\n  storage_tier = var.postgres_server_storage_tier\n\n  zone = 2\n\n  tags = var.tags\n}\n\n# Create the Private Endpoint\nresource \"azurerm_private_endpoint\" \"pe\" {\nname                  = \"${lower(replace(var.company,\" \",\"-\"))}-${var.app_name}-${var.environment}-pe\"\n  location            = azurerm_resource_group.this.location\n  resource_group_name = azurerm_resource_group.this.name\n  subnet_id           = azurerm_subnet.pe.id\n\n  private_service_connection {\n    name                           = \"${lower(replace(var.company,\" \",\"-\"))}-${var.app_name}-${var.environment}-psc\"\n    private_connection_resource_id = azurerm_postgresql_flexible_server.pe.id\n    subresource_names              = [\"postgresqlServer\"]\n    is_manual_connection           = false\n  }\n\n  private_dns_zone_group {\n    name                 = azurerm_postgresql_flexible_server.pe.name\n    private_dns_zone_ids = [data.azurerm_private_dns_zone.postgres_dns_zone.id]\n  }\n\n  depends_on = [ azurerm_postgresql_flexible_server.pe, azurerm_subnet.pe ]\n}\n\n# Create PostgreSQL Database\nresource \"azurerm_postgresql_flexible_server_database\" \"pe\" {\n  name      = \"${var.app_name}-${var.environment}-db-pe\"\n  server_id = azurerm_postgresql_flexible_server.pe.id\n  charset   = var.postgres_database_charset\n  collation = var.postgres_database_collation\n\n  # To  prevent the possibility of accidental data loss change to true in production\n  lifecycle {\n    prevent_destroy = false\n  }\n\n  depends_on = [ azurerm_postgresql_flexible_server.pe ]\n}  \n\n# Create PostgreSQL Firewall Rule for Azure Services\nresource \"azurerm_postgresql_flexible_server_firewall_rule\" \"azure\" {\n  name             = \"azure_services\"\n  server_id        = azurerm_postgresql_flexible_server.pe.id\n  start_ip_address = \"0.0.0.0\"\n  end_ip_address   = \"0.0.0.0\"\n\n  depends_on = [ azurerm_postgresql_flexible_server.pe ]\n}\n\n# Create PostgreSQL Firewall Rule for everyone\nresource \"azurerm_postgresql_flexible_server_firewall_rule\" \"everyone\" {\n  name             = \"everyone\"\n  server_id        = azurerm_postgresql_flexible_server.pe.id\n  start_ip_address = \"0.0.0.0\"\n  end_ip_address   = \"255.255.255.255\"\n\n  depends_on = [ azurerm_postgresql_flexible_server.pe ]\n}\n\n# Enable PostgreSQL Extensions\nresource \"azurerm_postgresql_flexible_server_configuration\" \"extensions\" {\n  name      = \"azure.extensions\"\n  server_id = azurerm_postgresql_flexible_server.pe.id\n  value     = \"VECTOR\"\n}\n\n##########################################\n## PostgresSQL Public Database - Output ##\n##########################################\n\noutput \"private_endpoint_postgresql_server_name\" {\n  value       = azurerm_postgresql_flexible_server.pe.name\n  description = \"The name of the PostgreSQL Server\"\n}\n\noutput \"private_endpoint_postgresql_database_name\" {\n  value       = azurerm_postgresql_flexible_server_database.pe.name\n  description = \"The name of the PostgreSQL Database\"\n}\n\n#File: database-variables.tf\n########################\n## Database Variables ##\n########################\n\nvariable \"postgres_user\" {\n  type        = string\n  description = \"The username for PostgreSQL administrator login\"\n  default     = \"dbadmin\"\n}\n\nvariable \"postgres_password\" {\n  type        = string\n  description = \"The password for PostgreSQL administrator login\"\n}\n\nvariable \"postgres_server_sku\" {\n  type        = string\n  description = \"PostgreSQL server type\"\n  default     = \"B_Standard_B1ms\"\n}\n\nvariable \"postgres_server_version\" {\n  type        = string\n  description = \"PostgreSQL server version (Possible values are 11, 12, 13, 14, 15 and 16)\"\n  default     = \"16\"\n}\n\nvariable \"postgres_server_storage_mb\" {\n  type        = number\n  description = \"PostgreSQL server storage in MB (Possible values are 32768, 65536, 131072, 262144, 524288, 1048576, 2097152, 4193280, 4194304, 8388608, 16777216 and 33553408)\"\n  default     = 32768\n}\n\nvariable \"postgres_server_storage_tier\" {\n  type        = string\n  description = \"PostgreSQL server storage tier (Possible values are P4, P6, P10, P15,P20, P30,P40, P50,P60, P70 or P80)\"\n  default     = \"P4\"\n}\n\nvariable \"postgres_admin_access_cidr\" {\n  type        = string\n  description = \"PostgreSQL admin access CIDR\"\n  default     = \"0.0.0.0/0\"\n}\n\nvariable \"postgres_database_collation\" {\n  type        = string\n  description = \"Specifies the Collation for the Azure PostgreSQL Flexible Server Database\"\n  default     = \"en_US.utf8\"\n}\n\nvariable \"postgres_database_charset\" {\n  type        = string\n  description = \"Specifies the charset for the Azure PostgreSQL Flexible Server Database\"\n  default     = \"UTF8\"\n}\n\n\n#File: dns-zone.tf\n#####################\n## DNS - Resources ##\n#####################\n\n# Reference to Private DNS Zone for PostgreSQL\ndata \"azurerm_private_dns_zone\" \"postgres_dns_zone\" {\n  name                = \"privatelink.postgres.database.azure.com\"\n  resource_group_name = var.private_dns_resource_group\n}\n\n#File: network.tf\n#########################\n## Network - Resources ##\n#########################\n\n# Create the Resource Group\nresource \"azurerm_resource_group\" \"this\" {\n  name     = \"${lower(replace(var.company,\" \",\"-\"))}-${var.app_name}-${var.environment}-rg\"\n  location = var.location\n\n  tags = var.tags\n}\n\n# Create the VNET\nresource \"azurerm_virtual_network\" \"this\" {\n  name                = \"${lower(replace(var.company,\" \",\"-\"))}-${var.app_name}-${var.environment}-vnet\"\n  address_space       = [var.vnet_address_space]\n  location            = azurerm_resource_group.this.location\n  resource_group_name = azurerm_resource_group.this.name\n\n  tags = var.tags\n}\n\n# Create the Subnet for PostgreSQL Private Endpoint\nresource \"azurerm_subnet\" \"pe\" {\n  name                 = \"${lower(replace(var.company,\" \",\"-\"))}-${var.app_name}-${var.environment}-postgres-pe-subnet\"\n  resource_group_name  = azurerm_resource_group.this.name\n  virtual_network_name = azurerm_virtual_network.this.name\n  address_prefixes     = [var.pe_subnet_address_space]\n\n  private_endpoint_network_policies = \"Enabled\"\n\n  service_endpoints = [\"Microsoft.Sql\"] \n}\n\n# Create NSG\nresource \"azurerm_network_security_group\" \"pe\" {\n  name                = \"${lower(replace(var.company,\" \",\"-\"))}-${var.app_name}-${var.environment}-postgres-pe-nsg\"\n  location            = azurerm_resource_group.this.location\n  resource_group_name = azurerm_resource_group.this.name\n\n  security_rule {\n    name                       = \"PostgreSQL\"\n    priority                   = 100\n    direction                  = \"Inbound\"\n    access                     = \"Allow\"\n    protocol                   = \"Tcp\"\n    source_port_range          = \"*\"\n    destination_port_range     = \"5432\"\n    source_address_prefix      = var.postgres_admin_access_cidr\n    destination_address_prefix = \"*\"\n  }\n\n  security_rule {\n    name                       = \"HTTPS\"\n    priority                   = 110\n    direction                  = \"Inbound\"\n    access                     = \"Allow\"\n    protocol                   = \"Tcp\"\n    source_port_range          = \"*\"\n    destination_port_range     = \"443\"\n    source_address_prefix      = \"0.0.0.0/0\"\n    destination_address_prefix = \"*\"\n  }\n}\n\n# Attach NSG to Subnet\nresource \"azurerm_subnet_network_security_group_association\" \"pe\" {\n  subnet_id                 = azurerm_subnet.pe.id\n  network_security_group_id = azurerm_network_security_group.pe.id\n}\n#File: output.tf\n############\n## Output ##\n############\n\noutput \"azure_region\" {\n  value       = azurerm_resource_group.this.location\n  description = \"The region in which this module should be deployed\"\n}\n\n\n#File: provider.tf\n# Define the Terraform provider\nterraform {\n  required_version = \"~> 1.8\"\n  required_providers {\n    azurerm = {\n      source = \"hashicorp/azurerm\"\n    }\n  }\n}\n\n# Define the Azure provider\nprovider \"azurerm\" {\n  features {}\n  environment     = \"public\"\n  subscription_id = var.azure_subscription_id\n  client_id       = var.azure_client_id\n  client_secret   = var.azure_client_secret\n  tenant_id       = var.azure_tenant_id\n}\n#File: variables.tf\n##########################\n## Azure Authentication ##\n##########################\n\nvariable \"azure_subscription_id\" {\n  type        = string\n  description = \"Azure Subscription ID\"\n}\n\nvariable \"azure_client_id\" {\n  type        = string\n  description = \"Azure Client ID\"\n}\n\nvariable \"azure_client_secret\" {\n  type        = string\n  description = \"Azure Client Secret\"\n}\n\nvariable \"azure_tenant_id\" {\n  type        = string\n  description = \"Azure Tenant ID\"\n}\n\n###########################\n## Application Variables ##\n###########################\n\n# Company name \nvariable \"company\" {\n  type        = string\n  description = \"This variable defines the company name used to build resources\"\n  default     = \"bracket\"\n}\n\n# Application name \nvariable \"app_name\" {\n  type        = string\n  description = \"This variable defines the application name used to build resources\"\n  default     = \"eurorad-leasingportal\"\n}\n\n# Environment\nvariable \"environment\" {\n  type        = string\n  description = \"This variable defines the environment to be built\"\n  default     = \"dev\"\n}\n\n# Azure region\nvariable \"location\" {\n  type        = string\n  description = \"Azure region where resources will be created\"\n  default     = \"North Europe\"\n}\n\n# Tags\nvariable \"tags\" {\n  type        = map(string)\n  description = \"The collection of tags to be applied to all resources\"\n  default     = {}\n}\n\n#######################\n## Network Variables ##\n#######################\n\nvariable \"vnet_address_space\" {\n  type        = string\n  description = \"VNET CIDR Block\"\n}\n\nvariable \"pe_subnet_address_space\" {\n  type        = string\n  description = \"PostgreSQL Private Endpoint Subnet CIDR\"\n}\n\n#####################\n## DNS - Variables ##\n#####################\n\nvariable \"private_dns_resource_group\" {\n  type        = string\n  description = \"The Resource Group where the Private DNS was created\"\n}"}]}
{"messages": [{"role": "user", "content": "Create a Google Cloud provider configuration with the specified project ID and region. Deploy a Cloud Run service using the provided service name, location, and container image URL. Configure the service to route 100% of traffic to the latest revision. Assign the `roles/artifactregistry.reader` IAM role to the Cloud Run service's service account. Ensure that all variables are properly defined in the variables file."}, {"role": "assistant", "content": "\n#File: main.tf\nprovider \"google\" {\n  project = var.project_id\n  region  = var.region\n}\n\nresource \"google_cloud_run_service\" \"default\" {\n  name     = var.service_name\n  location = var.region\n\n  template {\n    spec {\n      containers {\n        image = var.image_url\n      }\n    }\n  }\n\n  traffic {\n    percent         = 100\n    latest_revision = true\n  }\n}\n\nresource \"google_project_iam_binding\" \"artifact_registry_reader\" {\n  project = var.project_id\n  role    = \"roles/artifactregistry.reader\"\n\n  members = [\n    \"serviceAccount:${google_cloud_run_service.default.name}@${var.project_id}.iam.gserviceaccount.com\"\n  ]\n}\n\n#File: variables.tf\nvariable \"project_id\" {\n  description = \"The ID of the project in which to create resources.\"\n  type        = string\n}\n\nvariable \"region\" {\n  description = \"The region in which to create resources.\"\n  type        = string\n  default     = \"us-central1\"\n}\n\nvariable \"service_name\" {\n  description = \"The name of the Cloud Run service.\"\n  type        = string\n}\n\nvariable \"image_url\" {\n  description = \"The URL of the container image in Artifact Registry.\"\n  type        = string\n}\n"}]}
{"messages": [{"role":"user","content":"Create two Amazon SQS queues: a main queue and a corresponding dead-letter queue (DLQ), both configured as FIFO queues. The queues support server-side encryption using either a provided or newly created KMS key and include configurable settings such as visibility timeout, message retention, and redrive policy."},{"role":"assistant","content":"variable \"name\" {\r\n    type        = string\r\n    description = \"SQS identifier queue identifier\"\r\n}\r\n\r\nvariable \"fifo\" {\r\n  type          = bool\r\n  description   = \"Boolean designating a FIFO queue.\"\r\n  default       = false\r\n}\r\n\r\nvariable \"fifo_deduplication_scope\" {\r\n  type          = string\r\n  description   = \"Specifies whether message deduplication occurs at the message group or queue level.\"\r\n  default       = \"messageGroup\"\r\n}\r\n\r\nvariable \"fifo_throughput_limit\" {\r\n  type          = string\r\n  description   = \"Specifies whether the FIFO queue throughput quota applies to the entire queue or per message group.\"\r\n  default       = \"perMessageGroupId\"\r\n}\r\nvariable \"max_retry\" {\r\n  type      = number\r\n  default   = 3\r\n}\r\n\r\nvariable \"max_message_size\" {\r\n  type          = number\r\n  default       = 262144\r\n}\r\n\r\nvariable \"visibility_timeout\" {\r\n  type          = number\r\n  description   = \"Timeout to non/ack messages return to queue to be resconsumed\"\r\n  default       = 60 \r\n}   \r\n\r\nvariable \"visibility_timeout_dlq\" {\r\n  type          = number\r\n  description   = \"Timeout to non/ack messages return to queue to be resconsumed\"\r\n  default       = 180 \r\n}  \r\n\r\nvariable \"expiration_time_seconds\" {\r\n  type          = number\r\n  description   = \"The number of seconds Amazon SQS retains a message. Integer representing seconds\"\r\n  default       = 86400 \r\n} \r\n\r\nvariable \"expiration_time_seconds_dlq\" {\r\n  type          = number\r\n  description   = \"The number of seconds Amazon SQS retains a message. Integer representing seconds\"\r\n  default       = 1209600 \r\n} \r\n\r\nvariable \"delay\" {\r\n  type          = number\r\n  description   = \"The time in seconds that the delivery of all messages in the queue will be delayed\"\r\n  default       = 0 \r\n} \r\n\r\nvariable \"delay_dlq\" {\r\n  type          = number\r\n  description   = \"The time in seconds that the delivery of all messages in the queue will be delayed\"\r\n  default       = 900\r\n} \r\n\r\nvariable \"receive_wait_time_seconds\" {\r\n  type          = number \r\n  description   = \"The time for which a ReceiveMessage call will wait for a message to arrive; Optimized to long polling\"\r\n  default       = 20\r\n}\r\n\r\nvariable \"receive_wait_time_seconds_dlq\" {\r\n  type          = number \r\n  description   = \"The time for which a ReceiveMessage call will wait for a message to arrive; Optimized to long polling\"\r\n  default       = 20\r\n}\r\n\r\nvariable \"kms_key\" {\r\n    description = \"The ARN of the key that you wish to use if encrypting at rest\"\r\n    type        = string\r\n    default     = \"\"\r\n}\r\n\r\nvariable \"kms_cache_time\" {\r\n    description = \"The length of time, in seconds, for which Amazon SQS can reuse a data key to encrypt or decrypt messages before calling AWS KMS again\"\r\n    type    = number\r\n    default = 3600\r\n}\r\n\r\nvariable \"tags\" {\r\n    type    = map(any)\r\n    default = {}\r\n}\r\nresource \"aws_sqs_queue\" \"main\" {\r\n    name                        = format(\"%s%s\", var.name, var.fifo ? \".fifo\" : \"\")\r\n\r\n    max_message_size            = var.max_message_size\r\n    visibility_timeout_seconds  = var.visibility_timeout \r\n    message_retention_seconds   = var.expiration_time_seconds\r\n    receive_wait_time_seconds   = var.receive_wait_time_seconds\r\n\r\n    delay_seconds               = var.delay\r\n\r\n    kms_master_key_id                   = var.kms_key != \"\" ? var.kms_key : aws_kms_key.main[0].arn\r\n    kms_data_key_reuse_period_seconds   = var.kms_cache_time\r\n\r\n    fifo_queue                  = var.fifo\r\n    content_based_deduplication = var.fifo\r\n    deduplication_scope         = var.fifo ? var.fifo_deduplication_scope : null\r\n    fifo_throughput_limit       = var.fifo ? var.fifo_throughput_limit : null\r\n\r\n    redrive_policy  = jsonencode({\r\n        deadLetterTargetArn = aws_sqs_queue.dlq.arn\r\n        maxReceiveCount     = var.max_retry\r\n    })\r\n\r\n    tags                        = var.tags    \r\n}\r\n\r\nresource \"aws_sqs_queue\" \"dlq\" {\r\n    name                        = format(\"%s-dlq%s\", var.name, var.fifo ? \".fifo\" : \"\")\r\n\r\n    max_message_size            = var.max_message_size\r\n    visibility_timeout_seconds  = var.visibility_timeout_dlq\r\n    message_retention_seconds   = var.expiration_time_seconds_dlq\r\n    receive_wait_time_seconds   = var.receive_wait_time_seconds_dlq\r\n\r\n    delay_seconds               = var.delay_dlq\r\n\r\n    kms_master_key_id                   = var.kms_key != \"\" ? var.kms_key : aws_kms_key.main[0].arn\r\n    kms_data_key_reuse_period_seconds   = var.kms_cache_time\r\n\r\n    fifo_queue                  = var.fifo\r\n    content_based_deduplication = var.fifo\r\n    deduplication_scope         = var.fifo ? var.fifo_deduplication_scope : null\r\n    fifo_throughput_limit       = var.fifo ? var.fifo_throughput_limit : null\r\n\r\n    tags                        = var.tags\r\n}\r\nprovider \"aws\" {\r\n}\r\nresource \"aws_kms_key\" \"main\" {\r\n    count                       = var.kms_key == \"\" ? 1 : 0\r\n\r\n    description                 = var.name\r\n    key_usage                   = \"ENCRYPT_DECRYPT\"\r\n    customer_master_key_spec    = \"SYMMETRIC_DEFAULT\"\r\n\r\n    tags                        = var.tags\r\n    enable_key_rotation         = true\r\n}\r\n"}]}
{"messages": [{"role":"user","content":"Create an AWS WAF Regional Web ACL to protect a web application from common threats like SQL injection, XSS, and HTTP flood attacks. Define multiple WAF rules, including rate-based blocking for high request rates and detection of malicious IPs and bad user agents. The Web ACL is associated with an AWS resource, such as an Application Load Balancer or API Gateway, to actively block or allow traffic based on these rules"},{"role":"assistant","content":"provider \"aws\" {\r\n  region  = var.aws_region\r\n}\r\n\r\nvariable \"waf_name\" {\r\n    default = \"waf-production\"\r\n}\r\n\r\nvariable \"aws_region\" {\r\n    default = \"us-east-1\"\r\n}\r\n\r\nvariable \"request_threshold\"{\r\n    default = 1000\r\n}\r\n\r\n##################################\r\n####        Bad IP's    ####\r\n##################################\r\n\r\nvariable \"enable_bad_ips_rule\" {\r\n    default = true\r\n}\r\n\r\nvariable \"bad_ips\" {\r\n    type = list\r\n    default = [\r\n        {\r\n            value   = \"8.8.8.8/32\"\r\n            type    = \"IPV4\"\r\n        },\r\n        {\r\n            value   = \"9.9.9.9/32\"\r\n            type    = \"IPV4\"\r\n        }\r\n    ]\r\n}\r\n\r\n##################################\r\n####  Regex Pattern on Body   ####\r\n##################################\r\n\r\nvariable \"enable_body_regex\" {\r\n    default = true\r\n}\r\n\r\nvariable \"body_regex\" {\r\n    type = list\r\n    default = [\"(?i)BODY_BLOCK_ME\"]\r\n}\r\n\r\n##################################\r\n#### Regex Pattern on Header  ####\r\n##################################\r\n\r\nvariable \"enable_header_regex\" {\r\n    default = true\r\n}\r\n\r\nvariable \"header_regex\" {\r\n    type = list\r\n    default = [\"(?i)blockme\"]\r\n}\r\n\r\n##################################\r\n####    Regex Pattern on URI  ####\r\n##################################\r\n\r\nvariable \"enable_uri_regex\" {\r\n    default = true\r\n}\r\n\r\nvariable \"uri_regex\" {\r\n    type = list(string)\r\n    default = [\r\n        \"(?i)/block/me\",\r\n    ]\r\n}\r\nresource \"aws_wafregional_sql_injection_match_set\" \"sql_injection\" {\r\n\r\n  name  = format(\"%s-sql-injection\", var.waf_name)\r\n\r\n  sql_injection_match_tuple {\r\n    text_transformation = \"URL_DECODE\"\r\n\r\n    field_to_match {\r\n      type = \"QUERY_STRING\"\r\n    }\r\n  }\r\n\r\n  sql_injection_match_tuple {\r\n    field_to_match {\r\n      type = \"QUERY_STRING\"\r\n    }\r\n\r\n    text_transformation = \"HTML_ENTITY_DECODE\"\r\n  }\r\n\r\n  sql_injection_match_tuple {\r\n    field_to_match {\r\n      type = \"BODY\"\r\n    }\r\n\r\n    text_transformation = \"URL_DECODE\"\r\n  }\r\n\r\n  sql_injection_match_tuple {\r\n    field_to_match {\r\n      type = \"BODY\"\r\n    }\r\n\r\n    text_transformation = \"HTML_ENTITY_DECODE\"\r\n  }\r\n\r\n  sql_injection_match_tuple {\r\n    field_to_match {\r\n      type = \"URI\"\r\n    }\r\n\r\n    text_transformation = \"URL_DECODE\"\r\n  }\r\n\r\n  sql_injection_match_tuple {\r\n    field_to_match {\r\n      type = \"URI\"\r\n    }\r\n\r\n    text_transformation = \"HTML_ENTITY_DECODE\"\r\n  }\r\n\r\n  sql_injection_match_tuple {\r\n    field_to_match {\r\n      type = \"HEADER\"\r\n      data = \"Cookie\"\r\n    }\r\n\r\n    text_transformation = \"URL_DECODE\"\r\n  }\r\n\r\n  sql_injection_match_tuple {\r\n    field_to_match {\r\n      type = \"HEADER\"\r\n      data = \"Cookie\"\r\n    }\r\n\r\n    text_transformation = \"HTML_ENTITY_DECODE\"\r\n  }\r\n\r\n  sql_injection_match_tuple {\r\n    field_to_match {\r\n      type = \"HEADER\"\r\n      data = \"Authorization\"\r\n    }\r\n\r\n    text_transformation = \"URL_DECODE\"\r\n  }\r\n\r\n  sql_injection_match_tuple {\r\n    field_to_match {\r\n      type = \"HEADER\"\r\n      data = \"Authorization\"\r\n    }\r\n\r\n    text_transformation = \"HTML_ENTITY_DECODE\"\r\n  }\r\n}\r\n\r\n\r\nresource \"aws_wafregional_rule\" \"sql_injection_rule\" {\r\n  name        = format(\"%s-sql-injection-rule\", var.waf_name)\r\n  metric_name = \"SecurityAutomationsSqlInjectionRule\"\r\n\r\n  predicate {\r\n    type    = \"SqlInjectionMatch\"\r\n    data_id = aws_wafregional_sql_injection_match_set.sql_injection.id\r\n    negated = false\r\n  }\r\n}\r\nresource \"aws_wafregional_regex_pattern_set\" \"uri\" {\r\n    name                  = \"${var.waf_name}-uri-regex\"\r\n    regex_pattern_strings = var.uri_regex\r\n}\r\n\r\nresource \"aws_wafregional_regex_match_set\" \"regex_uri\" {\r\n    name = \"${var.waf_name}-uri-regex\"\r\n\r\n    regex_match_tuple {\r\n        field_to_match {\r\n            type = \"URI\"\r\n        }\r\n        regex_pattern_set_id = aws_wafregional_regex_pattern_set.uri.id\r\n        text_transformation  = \"COMPRESS_WHITE_SPACE\"\r\n    }\r\n}\r\n\r\nresource \"aws_wafregional_rule\" \"regex_uri\" {\r\n  name        = \"${var.waf_name}-regex-uri\"\r\n  metric_name = \"WAFMetricRegexUri\"\r\n\r\n  predicate {\r\n    type    = \"RegexMatch\"\r\n    data_id = aws_wafregional_regex_match_set.regex_uri.id\r\n    negated = false\r\n  }\r\n}\r\nresource \"aws_wafregional_web_acl\" \"WAFWebACL\" {\r\n    name        = format(\"%s-web-acl\", var.waf_name)\r\n\r\n    metric_name = \"SecurityAutomationsMaliciousRequesters\"\r\n\r\n    default_action { type = \"ALLOW\" }\r\n\r\n    rule {\r\n        action { type = \"BLOCK\" }\r\n        priority = 1\r\n        rule_id  = aws_wafregional_rule.bad_ips_rule.id\r\n    }\r\n\r\n    rule {\r\n        action { type = \"BLOCK\" }\r\n        priority = 2\r\n        rule_id  = aws_wafregional_rule.regex_uri.id\r\n    }\r\n\r\n    rule {\r\n        action { type = \"BLOCK\" }\r\n        priority = 3\r\n        rule_id  = aws_wafregional_rule.regex_body.id\r\n    }\r\n\r\n    rule {\r\n        action { type = \"BLOCK\" }\r\n        priority = 4\r\n        rule_id  = aws_wafregional_rule.sql_injection_rule.id\r\n    }\r\n\r\n    rule {\r\n        action { type = \"BLOCK\" }\r\n        priority = 5\r\n        rule_id  = aws_wafregional_rule.xss_rule.id\r\n    }\r\n\r\n    rule {\r\n        action { type = \"BLOCK\" }\r\n        priority = 6\r\n        rule_id  = aws_wafregional_rule.generic_insecuire_rules_qs.id\r\n    }\r\n\r\n    rule {\r\n        action { type = \"BLOCK\" }\r\n        priority = 7\r\n        rule_id  = aws_wafregional_rule.generic_insecuire_rules_uri.id\r\n    }\r\n\r\n\r\n    rule {\r\n        action { type = \"BLOCK\" }\r\n        priority = 8\r\n        rule_id  = aws_wafregional_rate_based_rule.ddos_ip_rule.id\r\n        type     = \"RATE_BASED\"\r\n    }\r\n\r\n}\r\nresource \"aws_wafregional_xss_match_set\" \"xss\" {\r\n\r\n  name  = format(\"%s-xss\", var.waf_name)\r\n\r\n  xss_match_tuple {\r\n    field_to_match {\r\n      type = \"QUERY_STRING\"\r\n    }\r\n\r\n    text_transformation = \"URL_DECODE\"\r\n  }\r\n\r\n  xss_match_tuple {\r\n    field_to_match {\r\n      type = \"QUERY_STRING\"\r\n    }\r\n\r\n    text_transformation = \"HTML_ENTITY_DECODE\"\r\n  }\r\n\r\n  xss_match_tuple {\r\n    field_to_match {\r\n      type = \"BODY\"\r\n    }\r\n\r\n    text_transformation = \"URL_DECODE\"\r\n  }\r\n\r\n  xss_match_tuple {\r\n    field_to_match {\r\n      type = \"BODY\"\r\n    }\r\n\r\n    text_transformation = \"HTML_ENTITY_DECODE\"\r\n  }\r\n\r\n  xss_match_tuple {\r\n    field_to_match {\r\n      type = \"URI\"\r\n    }\r\n\r\n    text_transformation = \"URL_DECODE\"\r\n  }\r\n\r\n  xss_match_tuple {\r\n    field_to_match {\r\n      type = \"URI\"\r\n    }\r\n\r\n    text_transformation = \"HTML_ENTITY_DECODE\"\r\n  }\r\n\r\n  xss_match_tuple {\r\n    field_to_match {\r\n      type = \"HEADER\"\r\n      data = \"Cookie\"\r\n    }\r\n\r\n    text_transformation = \"URL_DECODE\"\r\n  }\r\n\r\n  xss_match_tuple {\r\n    field_to_match {\r\n      type = \"HEADER\"\r\n      data = \"Cookie\"\r\n    }\r\n\r\n    text_transformation = \"HTML_ENTITY_DECODE\"\r\n  }\r\n}\r\n\r\nresource \"aws_wafregional_rule\" \"xss_rule\" {\r\n  name        = format(\"%s-xss-rule\", var.waf_name)\r\n  metric_name = \"SecurityAutomationsXssRule\"\r\n\r\n  predicate {\r\n    type    = \"XssMatch\"\r\n    data_id = aws_wafregional_xss_match_set.xss.id\r\n    negated = false\r\n  }\r\n}\r\nresource \"aws_wafregional_ipset\" \"bad_ips\" {\r\n\r\n    name  = format(\"%s-bad-ips\", var.waf_name)\r\n\r\n    dynamic \"ip_set_descriptor\" {\r\n        for_each = var.bad_ips\r\n        content {\r\n            type    = ip_set_descriptor.value.type\r\n            value   = ip_set_descriptor.value.value\r\n        }\r\n    }\r\n}\r\n\r\nresource \"aws_wafregional_rule\" \"bad_ips_rule\" {\r\n\r\n    name        = format(\"%s-bad-ips-rule\", var.waf_name)\r\n    metric_name = \"SecurityAutomationsBadIPSRule\"\r\n\r\n    predicate {\r\n        type    = \"IPMatch\"\r\n        data_id = aws_wafregional_ipset.bad_ips.id\r\n        negated = false\r\n    }\r\n}\r\nresource \"aws_wafregional_regex_pattern_set\" \"body\" {\r\n    name                  = format(\"%s-body-regex\", var.waf_name)\r\n    regex_pattern_strings = var.body_regex\r\n}\r\n\r\nresource \"aws_wafregional_regex_match_set\" \"regex_body\" {\r\n    name = format(\"%s-body-regex\", var.waf_name)\r\n\r\n    regex_match_tuple {\r\n        field_to_match {\r\n            type = \"BODY\"\r\n        }\r\n        regex_pattern_set_id = aws_wafregional_regex_pattern_set.body.id\r\n        text_transformation  = \"HTML_ENTITY_DECODE\"\r\n    }\r\n}\r\n\r\nresource \"aws_wafregional_rule\" \"regex_body\" {\r\n  name        = format(\"%s-regex-body\", var.waf_name)\r\n  metric_name = \"WAFMetricRegexBody\"\r\n\r\n  predicate {\r\n    type    = \"RegexMatch\"\r\n    data_id = aws_wafregional_regex_match_set.regex_body.id\r\n    negated = false\r\n  }\r\n}\r\nresource \"aws_wafregional_ipset\" \"ddos_ip\" {\r\n  name  = format(\"%s-ddos-ip\", var.waf_name)\r\n}\r\n\r\nresource \"aws_wafregional_rate_based_rule\" \"ddos_ip_rule\" {\r\n  name        = format(\"%s-ddos-ip\", var.waf_name)\r\n  metric_name = \"SecurityAutomationsHttpFloodRule\"\r\n\r\n  rate_key   = \"IP\"\r\n  rate_limit = var.request_threshold\r\n\r\n  predicate {\r\n    data_id = aws_wafregional_ipset.ddos_ip.id\r\n    negated = false\r\n    type    = \"IPMatch\"\r\n  }\r\n}\r\nresource \"aws_wafregional_byte_match_set\" \"insecure_params_qs\" {\r\n  name = format(\"%s-generic-insecure-params\", var.waf_name)\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"_ENV[\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"QUERY_STRING\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"auto_append_file=\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"QUERY_STRING\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"disable_functions=\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"QUERY_STRING\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"auto_prepend_file=\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"QUERY_STRING\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"safe_mode=\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"QUERY_STRING\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"_SERVER[\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"QUERY_STRING\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"allow_url_include=\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"QUERY_STRING\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"open_basedir=\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"QUERY_STRING\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"../\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"QUERY_STRING\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"HTML_ENTITY_DECODE\"\r\n    target_string         = \"../\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"QUERY_STRING\"\r\n    }\r\n  }\r\n\r\n}\r\n\r\nresource \"aws_wafregional_rule\" \"generic_insecuire_rules_qs\" {\r\n  name        = format(\"%s-generic-insecure-rules-querystring\", var.waf_name)\r\n  metric_name = \"GenericInsecurureParamsQueryString\"\r\n\r\n  predicate {\r\n    data_id = aws_wafregional_byte_match_set.insecure_params_qs.id\r\n    negated = false\r\n    type    = \"ByteMatch\"\r\n  }\r\n}\r\nresource \"aws_wafregional_byte_match_set\" \"insecure_params_uri\" {\r\n  name = format(\"%s-generic-insecure-params\", var.waf_name)\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"_ENV[\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"URI\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"auto_append_file=\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"URI\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"disable_functions=\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"URI\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"auto_prepend_file=\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"URI\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"safe_mode=\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"URI\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"_SERVER[\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"URI\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"allow_url_include=\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"URI\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"open_basedir=\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"URI\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"URL_DECODE\"\r\n    target_string         = \"../\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"URI\"\r\n    }\r\n  }\r\n\r\n  byte_match_tuples {\r\n    text_transformation   = \"HTML_ENTITY_DECODE\"\r\n    target_string         = \"../\"\r\n    positional_constraint = \"CONTAINS\"\r\n\r\n    field_to_match {\r\n      type = \"URI\"\r\n    }\r\n  }\r\n\r\n}\r\n\r\nresource \"aws_wafregional_rule\" \"generic_insecuire_rules_uri\" {\r\n  name        = format(\"%s-generic-insecure-rules-querystring\", var.waf_name)\r\n  metric_name = \"GenericInsecurureParamsQueryString\"\r\n\r\n  predicate {\r\n    data_id = aws_wafregional_byte_match_set.insecure_params_uri.id\r\n    negated = false\r\n    type    = \"ByteMatch\"\r\n  }\r\n}\r\n\r\n"}]}
{"messages": [{"role":"user","content":"Create an AWS security group with customizable ingress and egress rules defined by lists of ports and a specified protocol. It then launches an Amazon Linux 2 EC2 instance using the given AMI and instance type, attaching the created security group and installing Nginx on startup via user data. The default VPC is queried by its tag to ensure the instance is launched within the correct network."},{"role":"assistant","content":"provider \"aws\" {\r\n    region = var.region \r\n}\r\nresource \"aws_security_group\" \"instance\" {\r\n\r\n    name    = var.name_sg\r\n    \r\n    dynamic \"ingress\" {\r\n        iterator        = port\r\n        for_each        = var.ingressrules\r\n        content {\r\n            from_port   = port.value\r\n            to_port     = port.value\r\n            protocol    = var.protocol_net\r\n            cidr_blocks = [\"0.0.0.0/0\"]\r\n        }\r\n    }\r\n\r\n    dynamic \"egress\" {\r\n        iterator        = port\r\n        for_each        = var.egressrules\r\n        content {\r\n            from_port   = port.value\r\n            to_port     = port.value\r\n            protocol    = var.protocol_net\r\n            cidr_blocks = [\"0.0.0.0/0\"]\r\n        }\r\n    }\r\n\r\n}\r\nvariable \"region\"{\r\n    description = \"\"\r\n    type = string\r\n}\r\n\r\nvariable \"tags\"{\r\n    description = \"\"\r\n    type = string\r\n}\r\n\r\nvariable \"instance_type\"{\r\n    description = \"\"\r\n    type = string\r\n}\r\n\r\nvariable \"ami\"{\r\n    description = \"\"\r\n    type = string\r\n}\r\n\r\nvariable \"name_sg\"{\r\n    description = \"\"\r\n    type = string\r\n}\r\n\r\n#variable \"http_port\"{\r\n#    description = \"\"\r\n#}\r\n\r\nvariable \"protocol_net\"{\r\n    description = \"\"\r\n    type = string\r\n}\r\n\r\nvariable \"ingressrules\"{\r\n    description = \"\"\r\n    type = list(number)\r\n}\r\n\r\nvariable \"egressrules\"{\r\n    description = \"\"\r\n    type = list(number)\r\n}\r\nresource \"aws_instance\" \"linux2\" {\r\n    instance_type   = var.instance_type\r\n    ami             = var.ami\r\n\r\n    tags = {\r\n        \r\n        Name = var.tags\r\n    }\r\n\r\n    vpc_security_group_ids = [aws_security_group.instance.id]\r\n\r\n    user_data = <<-EOF\r\n\r\n                #!/bin/bash\r\n                sudo amazon-linux-extras install nginx1.12 -y\r\n                sudo service nginx start\r\n                EOF\r\n\r\n}\r\n\r\ndata \"aws_vpc\" \"default_vpc\" {\r\n\r\n    filter {\r\n      name = \"tag:Name\"\r\n      values = [\"Default\"]\r\n    }\r\n}"}]}
{"messages": [{"role":"user","content":"Provide a Amazon EC2 instances within a specified VPC and private subnets, assigning them an IAM role with SSM access and attaching security groups that allow node-to-node communication and SSH access. It will retrieves the latest Amazon Linux 2023 AMI via SSM Parameter Store, injects a custom root certificate into the instances trusted CA store via user data, and enforces metadata service security settings. Additionally, it defines variables for flexible configuration of instance count, type, key pair, tags, and networking parameters to enable reusable and customizable deployments."},{"role":"assistant","content":"data \"aws_vpc\" \"selected\" {\r\n  id = var.vpc_id\r\n}\r\ndata \"aws_partition\" \"workload_current_partition\" {}\r\n\r\ndata \"aws_ssm_parameter\" \"amazon_linux_latest\" {\r\n  name = \"/aws/service/ami-amazon-linux-latest/al2023-ami-kernel-default-x86_64\"\r\n}\r\n\r\nresource \"aws_iam_role\" \"node_iam_role\" {\r\n  name = \"${var.name_prefix}-node-iam-role-${var.resource_tag}\"\r\n\r\n  assume_role_policy = <<POLICY\r\n{\r\n  \"Statement\": [\r\n    {\r\n      \"Effect\": \"Allow\",\r\n      \"Principal\": {\r\n        \"Service\": \"ec2.amazonaws.com\"\r\n      },\r\n      \"Action\": \"sts:AssumeRole\"\r\n    }\r\n  ]\r\n}\r\nPOLICY\r\n}\r\n\r\nresource \"aws_iam_role_policy_attachment\" \"ssm_managed_instance_core\" {\r\n  policy_arn = \"arn:${data.aws_partition.workload_current_partition.partition}:iam::aws:policy/${var.iam_role_policy_ssmcore}\"\r\n  role       = aws_iam_role.node_iam_role.name\r\n}\r\n\r\nresource \"aws_iam_instance_profile\" \"server_host_profile\" {\r\n  name = \"${var.name_prefix}-server_host_profile-${var.resource_tag}\"\r\n  role = aws_iam_role.node_iam_role.name\r\n}\r\n\r\nresource \"aws_security_group\" \"node_sg\" {\r\n  name        = \"${var.name_prefix}-node-sg-${var.resource_tag}\"\r\n  description = \"Security group for all Server nodes in the cluster\"\r\n  vpc_id      = data.aws_vpc.selected.id\r\n\r\n  egress {\r\n    from_port   = 0\r\n    to_port     = 0\r\n    protocol    = \"-1\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n\r\n  tags = merge(var.global_tags,\r\n    { Name = \"${var.name_prefix}-server-sg-${var.resource_tag}\" }\r\n  )\r\n}\r\n\r\nresource \"aws_security_group_rule\" \"server_node_ingress_self\" {\r\n  description              = \"Allow node to communicate with each other\"\r\n  from_port                = 0\r\n  protocol                 = \"-1\"\r\n  security_group_id        = aws_security_group.node_sg.id\r\n  source_security_group_id = aws_security_group.node_sg.id\r\n  to_port                  = 65535\r\n  type                     = \"ingress\"\r\n}\r\n\r\nresource \"aws_security_group_rule\" \"server_node_ingress_ssh\" {\r\n  description       = \"SSH for nodes\"\r\n  from_port         = 22\r\n  protocol          = \"tcp\"\r\n  security_group_id = aws_security_group.node_sg.id\r\n  cidr_blocks       = [\"0.0.0.0/0\"]\r\n  to_port           = 22\r\n  type              = \"ingress\"\r\n}\r\n\r\ndata \"local_sensitive_file\" \"zscaler_root_cert\" {\r\n  filename = \"${path.module}/ZscalerRootCA.crt\"\r\n}\r\n\r\nlocals {\r\n  workloaduserdata = <<WORKLOADUSERDATA\r\n#!/bin/bash\r\n\r\necho \"${data.local_sensitive_file.zscaler_root_cert.content}\" > /etc/pki/ca-trust/source/anchors/ZscalerRootCA.crt\r\nupdate-ca-trust\r\nWORKLOADUSERDATA\r\n}\r\n\r\nresource \"aws_instance\" \"server_host\" {\r\n  count                  = var.workload_count\r\n  ami                    = data.aws_ssm_parameter.amazon_linux_latest.value\r\n  instance_type          = var.instance_type\r\n  key_name               = var.instance_key\r\n  subnet_id              = element(var.subnet_id, count.index)\r\n  iam_instance_profile   = aws_iam_instance_profile.server_host_profile.name\r\n  vpc_security_group_ids = [aws_security_group.node_sg.id]\r\n  user_data              = local.workloaduserdata\r\n\r\n  metadata_options {\r\n    http_endpoint = \"enabled\"\r\n    http_tokens   = \"required\"\r\n  }\r\n\r\n  tags = merge(var.global_tags,\r\n    { Name = \"${var.name_prefix}-server-node${count.index + 1}-${var.resource_tag}\" }\r\n  )\r\n}\r\n\r\nvariable \"name_prefix\" {\r\n  type        = string\r\n  description = \"A prefix to associate to all the Workload module resources\"\r\n  default     = null\r\n}\r\n\r\nvariable \"resource_tag\" {\r\n  type        = string\r\n  description = \"A tag to associate to all the Workload module resources\"\r\n  default     = null\r\n}\r\n\r\nvariable \"global_tags\" {\r\n  type        = map(string)\r\n  description = \"Populate any custom user defined tags from a map\"\r\n  default     = {}\r\n}\r\n\r\nvariable \"vpc_id\" {\r\n  type        = string\r\n  description = \"Cloud Connector VPC ID\"\r\n}\r\n\r\nvariable \"subnet_id\" {\r\n  type        = list(string)\r\n  description = \"List of private subnet IDs where workload servers will be deployed\"\r\n}\r\n\r\nvariable \"instance_type\" {\r\n  type        = string\r\n  description = \"The workload server EC2 instance type\"\r\n  default     = \"t3.micro\"\r\n}\r\n\r\nvariable \"instance_key\" {\r\n  type        = string\r\n  description = \"SSH Key for instances\"\r\n}\r\n\r\nvariable \"workload_count\" {\r\n  type        = number\r\n  description = \"number of workloads to deploy\"\r\n  default     = 1\r\n}\r\n\r\nvariable \"iam_role_policy_ssmcore\" {\r\n  type        = string\r\n  description = \"AWS EC2 Instance predefined IAM Role to access AWS SSM\"\r\n  default     = \"AmazonSSMManagedInstanceCore\"\r\n}\r\nterraform {\r\n  backend \"local\" {\r\n    path = \"../terraform.tfstate\"\r\n  }\r\n}\r\n"}]}
{"messages": [{"role":"user","content":"Automate the deployment of Amazon Lightsail instances, including instance creation, key pair setup, static IP assignment, and firewall configuration. Include CI/CD integration with GitHub Actions or GitLab CI."},{"role":"assistant","content":"# AWS Infrastructure Variables\r\nvariable \"region\" {\r\n  description = \"The AWS region in which the infrastructure will be deployed\"\r\n  type        = string\r\n  default     = \"ca-central-1\"\r\n}\r\n\r\n# Instance Variables\r\nvariable \"instance_availability_zone\" {\r\n  description = \"The availability zone for the AWS Lightsail instance\"\r\n  type        = string\r\n  default     = \"ca-central-1a\"\r\n}\r\n\r\nvariable \"instance_name\" {\r\n  description = \"The name of the AWS Lightsail instance\"\r\n  type        = string\r\n  default     = \"wordpress-1\"\r\n}\r\n\r\n# You can easily deploy an app: WordPress, LAMP, Node.js, Joomla, Magento, MEAN, Drupal, GitLab CE, Redmine, Nginx, Ghost, Django, PrestaShop, Plesk Hosting Stack, cPanel & WHM for AlmaLinux\r\n# Or you can deploy a clean operating system: Amazon Linux, Ubuntu, Debian, FreeBSD, openSUSE, CentOS\r\n# The blueprint_id parameter determines the operating system or application that will be installed on your instance:\r\n# aws lightsail get-blueprints\r\nvariable \"instance_blueprintid\" {\r\n  description = \"The blueprint ID of the AWS Lightsail instance, which determines the software to install\"\r\n  type        = string\r\n  default     = \"wordpress\"\r\n}\r\n\r\n# The bundle_id parameter specifies the plan for your Lightsail instance, which includes aspects such as RAM, CPU, storage, and data transfer allowance:\r\n# aws lightsail get-bundles\r\nvariable \"instance_bundleid\" {\r\n  description = \"The bundle ID of the AWS Lightsail instance, which determines the hardware of the instance\"\r\n  type        = string\r\n  default     = \"small_2_0\"\r\n}\r\n\r\nvariable \"key_pair_1_name\" {\r\n  description = \"The name of the key pair to use for the AWS Lightsail instance\"\r\n  type        = string\r\n  default     = \"key-pair-wordpress-1\"\r\n}\r\n\r\nvariable \"instance_addon_type\" {\r\n  description = \"Type of add-on for the Lightsail instance\"\r\n  type        = string\r\n  default     = \"AutoSnapshot\"\r\n}\r\n\r\nvariable \"instance_snapshot_time\" {\r\n  description = \"The time of day when the snapshot is taken\"\r\n  type        = string\r\n  default     = \"06:00\"\r\n}\r\n\r\nvariable \"instance_addon_status\" {\r\n  description = \"Status of the add-on\"\r\n  type        = string\r\n  default     = \"Enabled\"\r\n}\r\n\r\nvariable \"static_ip_1\" {\r\n  description = \"The name of the static IP to be created in AWS Lightsail\"\r\n  type        = string\r\n  default     = \"static-ip-wordpress-1\"\r\n}\r\n\r\nvariable \"static_ip_1_attachment\" {\r\n  description = \"The name of the static IP attachment to be created in AWS Lightsail\"\r\n  type        = string\r\n  default     = \"static-ip-wordpress-1\"\r\n}\r\n\r\n# KMS Variables\r\nvariable \"kms_key_1_default_retention_days\" {\r\n  description = \"The default retention period in days for keys created in the KMS keyring\"\r\n  type        = number\r\n  default     = 10\r\n}\r\n\r\nvariable \"kms_key_2_default_retention_days\" {\r\n  description = \"The default retention period in days for keys created in the KMS keyring\"\r\n  type        = number\r\n  default     = 10\r\n}\r\n\r\n# DynamoDB Variables\r\nvariable \"dynamodb_terraform_state_lock_1_billing_mode\" {\r\n  description = \"The billing mode for the DynamoDB table used for Terraform state locking\"\r\n  type        = string\r\n  default     = \"PAY_PER_REQUEST\"\r\n}\r\n# Providers region\r\nprovider \"aws\" {\r\n  region = var.region\r\n}\r\n# Creating an AWS Lightsail instance\r\nresource \"aws_lightsail_instance\" \"instance_1\" {\r\n  name              = var.instance_name\r\n  availability_zone = var.instance_availability_zone\r\n  key_pair_name     = var.key_pair_1_name\r\n  blueprint_id      = var.instance_blueprintid\r\n  bundle_id         = var.instance_bundleid\r\n\r\n  # An add-on block, which enables automatic snapshots of the instance at 06:00 every day\r\n  add_on {\r\n    type          = var.instance_addon_type\r\n    snapshot_time = var.instance_snapshot_time\r\n    status        = var.instance_addon_status\r\n  }\r\n\r\n  tags = {\r\n    Environment = \"production\"\r\n  }\r\n}\r\n\r\n# Public ports definition on the AWS Lightsail instance\r\nresource \"aws_lightsail_instance_public_ports\" \"public_ports\" {\r\n  instance_name = aws_lightsail_instance.instance_1.name\r\n\r\n  port_info {\r\n    protocol  = \"tcp\"\r\n    from_port = 22\r\n    to_port   = 22\r\n  }\r\n\r\n  port_info {\r\n    protocol  = \"tcp\"\r\n    from_port = 80\r\n    to_port   = 80\r\n  }\r\n\r\n  port_info {\r\n    protocol  = \"tcp\"\r\n    from_port = 443\r\n    to_port   = 443\r\n  }\r\n}\r\n# Creating a key pair for AWS Lightsail instances\r\nresource \"aws_lightsail_key_pair\" \"private_key_1\" {\r\n  name = var.key_pair_1_name\r\n}\r\n\r\n# Saving the private key to a local file\r\nresource \"local_file\" \"private_key_1_export\" {\r\n  filename = \"${path.root}/${var.key_pair_1_name}.pem\"\r\n  content  = aws_lightsail_key_pair.private_key_1.private_key\r\n\r\n  provisioner \"local-exec\" {\r\n    command = \"chmod 600 ${self.filename}\"\r\n  }\r\n}\r\n# Static IP address creation in AWS Lightsail\r\nresource \"aws_lightsail_static_ip\" \"static_ip_1\" {\r\n  name = var.static_ip_1\r\n}\r\n\r\n# Static IP address attachment to a Lightsail instance\r\nresource \"aws_lightsail_static_ip_attachment\" \"static_ip_1_attachment\" {\r\n  instance_name  = aws_lightsail_instance.instance_1.name\r\n  static_ip_name = var.static_ip_1_attachment\r\n}\r\n# KMS key creation\r\nresource \"aws_kms_key\" \"kms_key_1\" {\r\n  description             = \"KMS key for terraform state storage bucket\"\r\n  deletion_window_in_days = var.kms_key_1_default_retention_days\r\n  enable_key_rotation     = true\r\n}\r\n\r\n# AWS KMS alias creation\r\nresource \"aws_kms_alias\" \"kms_key_1_alias\" {\r\n  name          = \"alias/terraform-bucket-key-wordpress-1\"\r\n  target_key_id = aws_kms_key.kms_key_1.key_id\r\n\r\n  depends_on = [aws_kms_key.kms_key_1]\r\n}\r\n\r\n# KMS key creation\r\nresource \"aws_kms_key\" \"kms_key_2\" {\r\n  description             = \"KMS key for DynamoDB table encryption\"\r\n  deletion_window_in_days = var.kms_key_2_default_retention_days\r\n  enable_key_rotation     = true\r\n}\r\n\r\n# AWS KMS alias creation\r\nresource \"aws_kms_alias\" \"kms_key_2_alias\" {\r\n  name          = \"alias/dynamodb-table-encryption-wordpress-1\"\r\n  target_key_id = aws_kms_key.kms_key_2.key_id\r\n\r\n  depends_on = [aws_kms_key.kms_key_2]\r\n}\r\n# Random string generation\r\nresource \"random_id\" \"random_id_1\" {\r\n  byte_length = 5\r\n}\r\n\r\n# S3 bucket creation\r\nresource \"aws_s3_bucket\" \"bucket_1\" {\r\n  # S3 bucket name\r\n  # Note that S3 buckets in AWS are global, which means that it is not possible to use a name that has been used by someone else\r\n  bucket              = \"terraform-state-storage-wordpress-1-${random_id.random_id_1.hex}\"\r\n  object_lock_enabled = true\r\n\r\n  tags = {\r\n    Name = \"terraform-state-storage-wordpress-1\"\r\n  }\r\n\r\n  depends_on = [\r\n    random_id.random_id_1,\r\n    aws_kms_key.kms_key_1,\r\n    aws_s3_bucket.log_bucket_1\r\n  ]\r\n}\r\n\r\n# S3 bucket versioning\r\nresource \"aws_s3_bucket_versioning\" \"bucket_1_versioning\" {\r\n  bucket = aws_s3_bucket.bucket_1.id\r\n\r\n  versioning_configuration {\r\n    status = \"Enabled\"\r\n  }\r\n\r\n  depends_on = [aws_s3_bucket.bucket_1]\r\n}\r\n\r\n# S3 bucket public access configuration\r\nresource \"aws_s3_bucket_public_access_block\" \"bucket_1_public_access_block_block\" {\r\n  bucket = aws_s3_bucket.bucket_1.id\r\n\r\n  block_public_acls       = true\r\n  block_public_policy     = true\r\n  ignore_public_acls      = true\r\n  restrict_public_buckets = true\r\n\r\n  depends_on = [aws_s3_bucket.bucket_1]\r\n}\r\n\r\n# S3 bucket server-side encryption configuration\r\nresource \"aws_s3_bucket_server_side_encryption_configuration\" \"bucket_1_sse_configuration\" {\r\n  bucket = aws_s3_bucket.bucket_1.id\r\n\r\n  rule {\r\n    apply_server_side_encryption_by_default {\r\n      kms_master_key_id = aws_kms_key.kms_key_1.arn\r\n      sse_algorithm     = \"aws:kms\"\r\n    }\r\n  }\r\n\r\n  depends_on = [\r\n    aws_s3_bucket.bucket_1,\r\n    aws_kms_key.kms_key_1\r\n  ]\r\n}\r\n\r\n# Create a new S3 bucket to store logs\r\n# tfsec:ignore:aws-s3-enable-bucket-logging\r\nresource \"aws_s3_bucket\" \"log_bucket_1\" {\r\n  bucket              = \"terraform-state-storage-logs-wordpress-1-${random_id.random_id_1.hex}\"\r\n  object_lock_enabled = true\r\n}\r\n\r\n# S3 bucket versioning\r\nresource \"aws_s3_bucket_versioning\" \"log_bucket_1_versioning\" {\r\n  bucket = aws_s3_bucket.log_bucket_1.id\r\n\r\n  versioning_configuration {\r\n    status = \"Enabled\"\r\n  }\r\n\r\n  depends_on = [aws_s3_bucket.log_bucket_1]\r\n}\r\n\r\n# S3 bucket public access configuration\r\nresource \"aws_s3_bucket_public_access_block\" \"log_bucket_1_public_access_block_block\" {\r\n  bucket = aws_s3_bucket.log_bucket_1.id\r\n\r\n  block_public_acls       = true\r\n  block_public_policy     = true\r\n  ignore_public_acls      = true\r\n  restrict_public_buckets = true\r\n\r\n  depends_on = [aws_s3_bucket.log_bucket_1]\r\n}\r\n\r\n# Log bucket policy to allow write access for log delivery\r\nresource \"aws_s3_bucket_policy\" \"log_bucket_1_policy\" {\r\n  bucket = aws_s3_bucket.log_bucket_1.id\r\n\r\n  policy = jsonencode({\r\n    Version = \"2012-10-17\"\r\n    Statement = [\r\n      {\r\n        Effect = \"Allow\"\r\n        Principal = {\r\n          Service = \"delivery.logs.amazonaws.com\"\r\n        }\r\n        Action   = \"s3:PutObject\"\r\n        Resource = \"${aws_s3_bucket.log_bucket_1.arn}/*\"\r\n      }\r\n    ]\r\n  })\r\n\r\n  depends_on = [aws_s3_bucket.log_bucket_1]\r\n}\r\n\r\n# S3 bucket server-side encryption configuration\r\nresource \"aws_s3_bucket_server_side_encryption_configuration\" \"log_bucket_1_sse_configuration\" {\r\n  bucket = aws_s3_bucket.log_bucket_1.id\r\n\r\n  rule {\r\n    apply_server_side_encryption_by_default {\r\n      kms_master_key_id = aws_kms_key.kms_key_1.arn\r\n      sse_algorithm     = \"aws:kms\"\r\n    }\r\n  }\r\n\r\n  depends_on = [\r\n    aws_s3_bucket.log_bucket_1,\r\n    aws_kms_key.kms_key_1\r\n  ]\r\n}\r\n\r\n# Enable logging for the main S3 bucket and set the log bucket as the target for log storage\r\nresource \"aws_s3_bucket_logging\" \"log_bucket_1_logging\" {\r\n  bucket = aws_s3_bucket.bucket_1.id\r\n\r\n  # Specify the target bucket for storing logs and the prefix for log files\r\n  target_bucket = aws_s3_bucket.log_bucket_1.id\r\n  target_prefix = \"log/\"\r\n\r\n  depends_on = [\r\n    aws_s3_bucket.log_bucket_1,\r\n    aws_s3_bucket.bucket_1\r\n  ]\r\n}\r\n\r\n# DynamoDB table creation\r\nresource \"aws_dynamodb_table\" \"dynamodb_terraform_state_lock_1\" {\r\n  name         = \"dynamodb-terraform-state-lock-wordpress-1\"\r\n  billing_mode = var.dynamodb_terraform_state_lock_1_billing_mode\r\n  hash_key     = \"LockID\"\r\n\r\n  attribute {\r\n    name = \"LockID\"\r\n    type = \"S\"\r\n  }\r\n\r\n  server_side_encryption {\r\n    enabled     = true\r\n    kms_key_arn = aws_kms_key.kms_key_2.arn\r\n  }\r\n\r\n  point_in_time_recovery {\r\n    enabled = true\r\n  }\r\n\r\n  tags = {\r\n    Name = \"dynamodb-terraform-state-lock-wordpress-1\"\r\n  }\r\n\r\n  depends_on = [aws_kms_key.kms_key_2]\r\n}\r\n"}]}
{"messages": [{"role": "user", "content": "Create a Terraform configuration to set up an Azure Red Hat OpenShift cluster. Start by defining the required providers, including `azurerm` and `azapi`. Create a virtual network with specified address space and subnets for both master and worker nodes. Assign the necessary role permissions for the service principals to manage the network resources. Finally, configure the Azure Red Hat OpenShift cluster with appropriate settings, including VM sizes, network profiles, and security options."}, {"role": "assistant", "content": "\n#File: main.tf\nterraform {\n  required_version = \">= 1.0\"\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \">=3.3.0\"\n    }\n    azapi = {\n      source  = \"Azure/azapi\"\n      version = \">=1.0.0\"\n    }\n  }\n}\n\nprovider \"azurerm\" {\n  features {}\n}\n\nprovider \"azapi\" {\n}\n\ndata \"azurerm_client_config\" \"current\" {\n}\n\nlocals {\n  resource_group_id = \"/subscriptions/${data.azurerm_client_config.current.subscription_id}/resourceGroups/aro-${var.domain}-${var.location}\"\n}\n\nresource \"random_string\" \"resource_prefix\" {\n  length  = 6\n  special = false\n  upper   = false\n  numeric  = false\n}\n\nresource \"azurerm_virtual_network\" \"virtual_network\" {\n  name                = \"${var.resource_prefix != \"\" ? var.resource_prefix : random_string.resource_prefix.result}VNet\"\n  address_space       = var.virtual_network_address_space\n  location            = var.location\n  resource_group_name = var.resource_group_name\n  tags                = var.tags\n  \n  lifecycle {\n    ignore_changes = [\n        tags\n    ]\n  }\n}\n\nresource \"azurerm_subnet\" \"master_subnet\" {\n  name                                           = var.master_subnet_name\n  resource_group_name                            = var.resource_group_name\n  virtual_network_name                           = azurerm_virtual_network.virtual_network.name\n  address_prefixes                               = var.master_subnet_address_space\n  private_link_service_network_policies_enabled  = false\n  service_endpoints                              = [\"Microsoft.ContainerRegistry\"]\n}\n\nresource \"azurerm_subnet\" \"worker_subnet\" {\n  name                                           = var.worker_subnet_name\n  resource_group_name                            = var.resource_group_name\n  virtual_network_name                           = azurerm_virtual_network.virtual_network.name\n  address_prefixes                               = var.worker_subnet_address_space\n  service_endpoints                              = [\"Microsoft.ContainerRegistry\"]\n}\n\nresource \"azurerm_role_assignment\" \"aro_cluster_service_principal_network_contributor\" {\n  scope                = azurerm_virtual_network.virtual_network.id\n  role_definition_name = \"Contributor\"\n  principal_id         = var.aro_cluster_aad_sp_object_id\n  skip_service_principal_aad_check = true\n}\n\nresource \"azurerm_role_assignment\" \"aro_resource_provider_service_principal_network_contributor\" {\n  scope                = azurerm_virtual_network.virtual_network.id\n  role_definition_name = \"Contributor\"\n  principal_id         = var.aro_rp_aad_sp_object_id\n  skip_service_principal_aad_check = true\n}\n\ndata \"azurerm_resource_group\" \"resource_group\" {\n  name                = var.resource_group_name\n}\n\nresource \"azapi_resource\" \"aro_cluster\" {\n  name      = \"${var.resource_prefix != \"\" ? var.resource_prefix : random_string.resource_prefix.result}Aro\"\n  location  = var.location\n  parent_id = data.azurerm_resource_group.resource_group.id\n  type      = \"Microsoft.RedHatOpenShift/openShiftClusters@2022-04-01\"\n  tags      = var.tags\n  \n  body = jsonencode({\n    properties = {\n      clusterProfile = {\n        domain               = var.domain\n        fipsValidatedModules = var.fips_validated_modules\n        resourceGroupId      = local.resource_group_id\n        pullSecret           = var.pull_secret\n      }\n      networkProfile = {\n        podCidr              = var.pod_cidr\n        serviceCidr          = var.service_cidr\n      }\n      servicePrincipalProfile = {\n        clientId             = var.aro_cluster_aad_sp_client_id\n        clientSecret         = var.aro_cluster_aad_sp_client_secret\n      }\n      masterProfile = {\n        vmSize               = var.master_node_vm_size\n        subnetId             = azurerm_subnet.master_subnet.id\n        encryptionAtHost     = var.master_encryption_at_host\n      }\n      workerProfiles = [\n        {\n          name               = var.worker_profile_name\n          vmSize             = var.worker_node_vm_size\n          diskSizeGB         = var.worker_node_vm_disk_size\n          subnetId           = azurerm_subnet.worker_subnet.id\n          count              = var.worker_node_count\n          encryptionAtHost   = var.worker_encryption_at_host\n        }\n      ]\n      apiserverProfile = {\n        visibility           = var.api_server_visibility\n      }\n      ingressProfiles = [\n        {\n          name               = var.ingress_profile_name\n          visibility         = var.ingress_visibility\n        }\n      ]\n    }\n  })\n\n  lifecycle {\n    ignore_changes = [\n        tags\n    ]\n  }\n}\n#File: variables.tf\nvariable \"resource_prefix\" {\n  description = \"Specifies the name prefix for all the Azure resources.\"\n  type        = string\n}\n\nvariable \"location\" {\n  description = \"Specifies the location of Azure resource.\"\n  default     = \"eastus\"\n  type        = string\n}\n\nvariable \"resource_group_name\" {\n  description = \"Specifies the name of the resource group.\"\n  type        = string\n}\n\nvariable \"domain\" {\n  description = \"Specifies the domain prefix of the Azure Red Hat OpenShift cluster.\"\n  default     = \"\"\n  type        = string\n}\n\nvariable \"pull_secret\" {\n  description = \"Specifies the pull secret from cloud.redhat.com. The JSON should be provided as a string.\"\n  type        = string\n}\n\nvariable \"virtual_network_address_space\" {\n  description = \"Specifies the address space of the virtual virtual network hosting the Azure Red Hat OpenShift cluster.\"\n  default     = [\"10.100.0.0/15\"]\n  type        = list(string)\n}\n\nvariable \"worker_subnet_name\" {\n  description = \"Specifies the name of the worker node subnet.\"\n  default     = \"worker\"\n  type        = string\n}\n\nvariable \"worker_subnet_address_space\" {\n  description = \"Specifies the address space of the worker node subnet.\"\n  default     = [\"10.100.70.0/23\"]\n  type        = list(string)\n}\n\nvariable \"master_subnet_name\" {\n  description = \"Specifies the name of the master node subnet.\"\n  default     = \"master\"\n  type        = string\n}\n\nvariable \"master_subnet_address_space\" {\n  description = \"Specifies the address space of the master node subnet.\"\n  default     = [\"10.100.76.0/24\"]\n  type        = list(string)\n}\n\nvariable \"worker_node_vm_size\" {\n  description = \"Specifies the VM size for worker nodes of the Azure Red Hat OpenShift cluster.\"\n  default     = \"Standard_D4s_v3\"\n  type        = string\n}\n\nvariable \"master_node_vm_size\" {\n  description = \"Specifies the VM size for master nodes of the Azure Red Hat OpenShift cluster.\"\n  default     = \"Standard_D8s_v3\"\n  type        = string\n}\n\nvariable \"worker_profile_name\" {\n  description = \"Specifies the name of the worker profile of the Azure Red Hat OpenShift cluster.\"\n  default     = \"worker\"\n  type        = string\n}\n\nvariable \"worker_node_vm_disk_size\" {\n  description = \"Specifies the VM disk size for worker nodes of the Azure Red Hat OpenShift cluster.\"\n  default     = 128\n  type        = number\n}\n\nvariable \"worker_node_count\" {\n  description = \"Specifies the number of worker nodes of the Azure Red Hat OpenShift cluster.\"\n  default     = 3\n  type        = number\n}\n\nvariable \"pod_cidr\" {\n  description = \"Specifies the CIDR for the pods.\"\n  default     = \"10.128.0.0/14\"\n  type        = string\n}\n\nvariable \"service_cidr\" {\n  description = \"Specifies the CIDR for the services.\"\n  default     = \"172.30.0.0/16\"\n  type        = string\n}\n\nvariable \"tags\" {\n  description = \"(Optional) Specifies tags for all the resources\"\n  default     = {\n    createdWith = \"Terraform\"\n    environment = \"Development\"\n    department  = \"Ops\"\n  }\n}\n\nvariable \"api_server_visibility\" {\n  description = \"Specifies the API Server visibility for the Azure Red Hat OpenShift cluster.\"\n  default  = \"Public\" \n  validation {\n    condition = contains([\"Private\", \"Public\"], var.api_server_visibility)\n    error_message = \"The value of the api_server_visibility parameter is invalid.\"\n  }\n}\n\nvariable \"ingress_profile_name\" {\n  description = \"Specifies the name of the ingress profile of the Azure Red Hat OpenShift cluster.\"\n  default     = \"default\"\n  type        = string\n}\n\nvariable \"ingress_visibility\" {\n  description = \"Specifies the ingress visibility for the Azure Red Hat OpenShift cluster.\"\n  default  = \"Public\" \n  validation {\n    condition = contains([\"Private\", \"Public\"], var.ingress_visibility)\n    error_message = \"The value of the ingress_visibility parameter is invalid.\"\n  }\n}\n\nvariable \"fips_validated_modules\" {\n  description = \"Specifies whether FIPS validated crypto modules are used.\"\n  default  = \"Disabled\" \n  validation {\n    condition = contains([\"Disabled\", \"Enabled\"], var.fips_validated_modules)\n    error_message = \"The value of the fips_validated_modules parameter is invalid.\"\n  }\n}\n\nvariable \"master_encryption_at_host\" {\n  description = \"Specifies whether master virtual machines are encrypted at host.\"\n  default  = \"Disabled\" \n  validation {\n    condition = contains([\"Disabled\", \"Enabled\"], var.master_encryption_at_host)\n    error_message = \"The value of the master_encryption_at_host parameter is invalid.\"\n  }\n}\n\nvariable \"worker_encryption_at_host\" {\n  description = \"Specifies whether master virtual machines are encrypted at host.\"\n  default  = \"Disabled\" \n  validation {\n    condition = contains([\"Disabled\", \"Enabled\"], var.worker_encryption_at_host)\n    error_message = \"The value of the worker_encryption_at_host parameter is invalid.\"\n  }\n}\n\nvariable \"aro_cluster_aad_sp_client_id\" {\n  description = \"Specifies the client id of the service principal of the Azure Red Hat OpenShift cluster.\"\n  type        = string\n}\n\nvariable \"aro_cluster_aad_sp_client_secret\" {\n  description = \"Specifies the client secret of the service principal of the Azure Red Hat OpenShift cluster.\"\n  type        = string\n}\n\nvariable \"aro_cluster_aad_sp_object_id\" {\n  description = \"Specifies the object id of the service principal of the Azure Red Hat OpenShift cluster.\"\n  type        = string\n}\n\nvariable \"aro_rp_aad_sp_object_id\" {\n  description = \"Specifies the object id of the service principal of the ARO resource provider.\"\n  type        = string\n}"}]}
{"messages": [{"role": "user", "content": "Create a resource group in Azure using the specified name and location. Set up a User Assigned Managed Identity for the application and configure a federated identity credential using GitHub Actions. Assign the Contributor role to the managed identity at the resource group level and the AcrPush role at the Azure Container Registry. Deploy an Azure Container App within the created environment, specifying the desired resource configurations. Output essential information including client ID, subscription ID, tenant ID, and the URL of the container app."}, {"role": "assistant", "content": "\n#File: main.tf\ndata \"azurerm_client_config\" \"current\" {}\n\nresource \"azurerm_resource_group\" \"rg\" {\n  name     = var.resource_group_name\n  location = var.location\n}\n\n# Create User Assigned Managed Identity\nresource \"azurerm_user_assigned_identity\" \"app_identity\" {\n  name                = \"${var.app_name}-identity\"\n  resource_group_name = azurerm_resource_group.rg.name\n  location            = azurerm_resource_group.rg.location\n}\n\n# Configure federated identity credential for the managed identity\nresource \"azurerm_federated_identity_credential\" \"github_federated\" {\n  name                = \"github-actions-oidc\"\n  resource_group_name = azurerm_resource_group.rg.name\n  audience            = [\"api://AzureADTokenExchange\"]\n  issuer              = \"https://token.actions.githubusercontent.com\"\n  parent_id           = azurerm_user_assigned_identity.app_identity.id\n  subject             = \"repo:${var.github_repo}:ref:refs/heads/main\"\n}\n\n# Assign Contributor role to the Managed Identity at resource group level\nresource \"azurerm_role_assignment\" \"identity_role\" {\n  scope                = azurerm_resource_group.rg.id\n  role_definition_name = \"Contributor\"\n  principal_id         = azurerm_user_assigned_identity.app_identity.principal_id\n}\n\nresource \"azurerm_container_registry\" \"acr\" {\n  name                = var.acr_name\n  resource_group_name = azurerm_resource_group.rg.name\n  location            = azurerm_resource_group.rg.location\n  sku                = \"Basic\"\n  admin_enabled      = true\n}\n\n# Assign AcrPush role to the Managed Identity\nresource \"azurerm_role_assignment\" \"acr_push\" {\n  scope                = azurerm_container_registry.acr.id\n  role_definition_name = \"AcrPush\"\n  principal_id         = azurerm_user_assigned_identity.app_identity.principal_id\n}\n\n# Assign AcrPull role to the Container App's managed identity\nresource \"azurerm_role_assignment\" \"acr_pull\" {\n  scope                = azurerm_container_registry.acr.id\n  role_definition_name = \"AcrPull\"\n  principal_id         = azurerm_container_app.app.identity[0].principal_id\n}\n\nresource \"azurerm_container_app_environment\" \"env\" {\n  name                = var.env_name\n  resource_group_name = azurerm_resource_group.rg.name\n  location            = azurerm_resource_group.rg.location\n}\n\nresource \"azurerm_container_app\" \"app\" {\n  name                         = var.app_name\n  resource_group_name         = azurerm_resource_group.rg.name\n  container_app_environment_id = azurerm_container_app_environment.env.id\n  revision_mode               = \"Single\"\n  \n  identity {\n    type = \"SystemAssigned\"\n  }\n\n  registry {\n    server   = azurerm_container_registry.acr.login_server\n    identity = \"System\"\n  }\n  \n  template {\n    container {\n      name   = var.app_name\n      image  = \"nginx:latest\"  # Placeholder image\n      cpu    = \"0.5\"\n      memory = \"1.0Gi\"\n    }\n  }\n\n  ingress {\n      external_enabled = true\n      target_port     = 80\n      traffic_weight {\n        latest_revision = true\n        percentage     = 100\n      }\n  }\n}\n#File: outputs.tf\noutput \"AZURE_CLIENT_ID\" {\n  value = azurerm_user_assigned_identity.app_identity.client_id\n  description = \"The client ID of the managed identity. Store this as AZURE_CLIENT_ID in GitHub secrets.\"\n}\n\noutput \"AZURE_SUBSCRIPTION_ID\" {\n  value = data.azurerm_client_config.current.subscription_id\n  description = \"The Azure subscription ID. Store this as AZURE_SUBSCRIPTION_ID in GitHub secrets.\"\n}\n\noutput \"AZURE_TENANT_ID\" {\n  value = data.azurerm_client_config.current.tenant_id\n  description = \"The Azure tenant ID. Store this as AZURE_TENANT_ID in GitHub secrets.\"\n}\n\noutput \"ACR_LOGIN_SERVER\" {\n  value = azurerm_container_registry.acr.login_server\n  description = \"The ACR login server URL. Store this as ACR_LOGIN_SERVER in GitHub secrets.\"\n}\n\noutput \"ACR_NAME\" {\n  value = azurerm_container_registry.acr.name\n  description = \"The name of the Azure Container Registry. Store this as ACR_NAME in GitHub secrets.\"\n}\n\noutput \"RESOURCE_GROUP_NAME\" {\n  value = azurerm_resource_group.rg.name\n  description = \"The name of the resource group. Store this as RESOURCE_GROUP_NAME in GitHub secrets.\"\n}\n\noutput \"CONTAINER_APP_NAME\" {\n  value = azurerm_container_app.app.name\n  description = \"The name of the container app. Store this as CONTAINER_APP_NAME in GitHub secrets.\"\n}\n\noutput \"CONTAINER_APP_ENVIRONMENT\" {\n  value = azurerm_container_app_environment.env.name\n  description = \"The name of the container app environment. Store this as CONTAINER_APP_ENVIRONMENT in GitHub secrets.\"\n}\n\noutput \"CONTAINER_APP_URL\" {\n  value       = \"https://${azurerm_container_app.app.latest_revision_fqdn}\"\n  description = \"The URL of the container app. This URL should be used for the GitHub App configuration.\"\n}\n#File: providers.tf\nterraform {\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"4.22.0\"\n    }\n    azuread = {\n      source  = \"hashicorp/azuread\"\n      version = \"3.1.0\"\n    }\n  }\n}\n\nprovider \"azurerm\" {\n  features {}\n  subscription_id = var.subscription_id\n}\n\nprovider \"azuread\" {\n  use_oidc = true\n}\n#File: variables.tf\nvariable \"resource_group_name\" {\n  description = \"The name of the resource group\"\n  type        = string\n  default     = \"rg-github-copilot-extension\"\n}\n\nvariable \"location\" {\n  description = \"The Azure region to deploy resources\"\n  type        = string\n  default     = \"Germany West Central\"\n}\n\nvariable \"acr_name\" {\n  description = \"The name of the Azure Container Registry\"\n  type        = string\n  default     = \"acrgithubcopilotextension\"\n}\n\nvariable \"env_name\" {\n  description = \"The name of the Azure Container App Environment\"\n  type        = string\n  default     = \"envgithubcopilotextension\"\n}\n\nvariable \"app_name\" {\n  description = \"The name of the Azure Container App\"\n  type        = string\n  default     = \"appgithubcopilotextension\"\n}\n\nvariable \"identity_name\" {\n  description = \"The name of the managed identity\"\n  type        = string\n  default     = \"migithubcopilotextension\"\n}\n\nvariable \"subscription_id\" {\n  description = \"The subscription ID for the Azure account\"\n  type        = string\n}\n\nvariable \"github_repo\" {\n  description = \"The GitHub repository in format owner/repo\"\n  type        = string\n}"}]}
{"messages": [{"role":"user","content":"Set up a secure, scalable AWS environment with a VPC, private and public subnets, and an internet gateway. Provide a PostgreSQL RDS instance, an Application Load Balancer, and ECS Fargate services with autoscaling and proper IAM roles and policies. The setup also includes logging via CloudWatch and a public S3 bucket for assets, enabling a fully managed containerized application deployment."},{"role":"assistant","content":"provider \"aws\" {\r\n  region  = var.region\r\n}\r\n\r\nresource \"random_string\" \"password\" {\r\n  length  = 16\r\n  special = false\r\n}\r\n\r\nresource \"aws_db_subnet_group\" \"default\" {\r\n  name = \"dbsubnetgroup\"\r\n  subnet_ids = [\r\n    for subnet in aws_subnet.private :\r\n    subnet.id\r\n  ]\r\n\r\n  depends_on = [aws_subnet.private]\r\n}\r\n\r\nresource \"aws_db_instance\" \"default\" {\r\n  allocated_storage      = 20\r\n  storage_type           = \"gp2\"\r\n  engine                 = \"postgres\"\r\n  engine_version         = \"10.6\"\r\n  instance_class         = \"db.t2.micro\"\r\n  name                   = \"terraformdb\"\r\n  username               = \"terraformdb\"\r\n  password               = random_string.password.result\r\n  db_subnet_group_name   = aws_db_subnet_group.default.name\r\n  vpc_security_group_ids = [aws_security_group.db.id]\r\n}\r\n\r\nresource \"aws_security_group\" \"db\" {\r\n  name        = \"${var.name}-db\"\r\n  description = \"Allow traffic from ECS tasks\"\r\n  vpc_id      = aws_vpc.main.id\r\n\r\n  ingress {\r\n    from_port       = 5432\r\n    to_port         = 5432\r\n    protocol        = \"TCP\"\r\n    security_groups = [aws_security_group.ecs_tasks.id]\r\n  }\r\n\r\n  egress {\r\n    from_port   = 0\r\n    to_port     = 0\r\n    protocol    = \"-1\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n\r\n  depends_on = [aws_security_group.ecs_tasks]\r\n}\r\nresource \"aws_s3_bucket\" \"assets-bucket\" {\r\n  bucket = \"${var.name}-assets-s3-bucket\"\r\n  acl    = \"public-read\"\r\n}\r\n\r\nvariable \"region\" {\r\n  default = \"us-east-1\"\r\n}\r\n\r\nvariable \"az_count\" {\r\n  default = \"2\"\r\n}\r\n\r\nvariable \"name\" {\r\n  default = \"terraform-stack\"\r\n}\r\n\r\nvariable \"app_port\" {\r\n  default = \"3000\"\r\n}\r\n\r\nvariable \"fargate_cpu\" {\r\n  default = \"256\"\r\n}\r\n\r\nvariable \"fargate_memory\" {\r\n  default = \"512\"\r\n}\r\n\r\nvariable \"app_image\" {\r\n  default = \"085108115628.dkr.ecr.us-east-1.amazonaws.com/terraform-vs-cdk:latest\"\r\n}\r\n\r\nvariable \"app_count\" {\r\n  default = \"1\"\r\n}\r\n\r\ndata \"aws_availability_zones\" \"available\" {}\r\n\r\nresource \"aws_vpc\" \"main\" {\r\n  cidr_block = \"20.0.0.0/16\"\r\n}\r\n\r\nresource \"aws_internet_gateway\" \"gw\" {\r\n  vpc_id = aws_vpc.main.id\r\n}\r\n\r\nresource \"aws_subnet\" \"private\" {\r\n  count             = var.az_count\r\n  cidr_block        = cidrsubnet(aws_vpc.main.cidr_block, 8, count.index)\r\n  availability_zone = data.aws_availability_zones.available.names[count.index]\r\n  vpc_id            = aws_vpc.main.id\r\n}\r\n\r\nresource \"aws_subnet\" \"public\" {\r\n  count                   = var.az_count\r\n  cidr_block              = cidrsubnet(aws_vpc.main.cidr_block, 8, var.az_count + count.index)\r\n  availability_zone       = data.aws_availability_zones.available.names[count.index]\r\n  vpc_id                  = aws_vpc.main.id\r\n  map_public_ip_on_launch = true\r\n}\r\n\r\nresource \"aws_eip\" \"gw\" {\r\n  count      = var.az_count\r\n  vpc        = true\r\n  depends_on = [aws_internet_gateway.gw]\r\n}\r\n\r\nresource \"aws_nat_gateway\" \"gw\" {\r\n  count         = var.az_count\r\n  subnet_id     = element(aws_subnet.public.*.id, count.index)\r\n  allocation_id = element(aws_eip.gw.*.id, count.index)\r\n}\r\n\r\nresource \"aws_route_table\" \"private\" {\r\n  count  = var.az_count\r\n  vpc_id = aws_vpc.main.id\r\n\r\n  route {\r\n    cidr_block     = \"0.0.0.0/0\"\r\n    nat_gateway_id = element(aws_nat_gateway.gw.*.id, count.index)\r\n  }\r\n}\r\n\r\nresource \"aws_route_table_association\" \"private\" {\r\n  count          = var.az_count\r\n  subnet_id      = element(aws_subnet.private.*.id, count.index)\r\n  route_table_id = element(aws_route_table.private.*.id, count.index)\r\n}\r\n\r\nresource \"aws_route_table\" \"public\" {\r\n  vpc_id = aws_vpc.main.id\r\n\r\n  route {\r\n    cidr_block = \"0.0.0.0/0\"\r\n    gateway_id = aws_internet_gateway.gw.id\r\n  }\r\n}\r\n\r\nresource \"aws_route_table_association\" \"public\" {\r\n  count          = var.az_count\r\n  subnet_id      = element(aws_subnet.public.*.id, count.index)\r\n  route_table_id = aws_route_table.public.id\r\n}\r\n# ALB Security group\r\n# This is the group you need to edit if you want to restrict access to your application\r\n\r\nresource \"aws_security_group\" \"lb\" {\r\n  name        = \"${var.name}-ALB-SG\"\r\n  description = \"controls access to the ALB\"\r\n  vpc_id      = aws_vpc.main.id\r\n\r\n  ingress {\r\n    protocol    = \"tcp\"\r\n    from_port   = 80\r\n    to_port     = 80\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n\r\n  ingress {\r\n    protocol    = \"tcp\"\r\n    from_port   = 443\r\n    to_port     = 443\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n\r\n  egress {\r\n    from_port   = 0\r\n    to_port     = 0\r\n    protocol    = \"-1\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n}\r\n\r\nresource \"aws_alb\" \"main\" {\r\n  name = \"${var.name}-ALB\"\r\n  subnets = [\r\n    for subnet in aws_subnet.public :\r\n    subnet.id\r\n  ]\r\n  security_groups = [aws_security_group.lb.id]\r\n}\r\n\r\nresource \"aws_alb_target_group\" \"app\" {\r\n  name        = \"${var.name}-TG\"\r\n  port        = 80\r\n  protocol    = \"HTTP\"\r\n  vpc_id      = aws_vpc.main.id\r\n  target_type = \"ip\"\r\n}\r\n\r\nresource \"aws_alb_listener\" \"app\" {\r\n  load_balancer_arn = aws_alb.main.id\r\n  port              = \"80\"\r\n  protocol          = \"HTTP\"\r\n\r\n  default_action {\r\n    target_group_arn = aws_alb_target_group.app.id\r\n    type             = \"forward\"\r\n  }\r\n}\r\nresource \"aws_appautoscaling_target\" \"ecs_target\" {\r\n  max_capacity       = 4\r\n  min_capacity       = 1\r\n  resource_id        = \"service/${var.name}-Cluster/${var.name}-service\"\r\n  role_arn           = \"${aws_iam_role.ecs_scale_role.arn}\"\r\n  scalable_dimension = \"ecs:service:DesiredCount\"\r\n  service_namespace  = \"ecs\"\r\n}\r\n\r\nresource \"aws_appautoscaling_policy\" \"ecs_policy\" {\r\n  name               = \"${var.name}-target-tracking-policy\"\r\n  policy_type        = \"TargetTrackingScaling\"\r\n  resource_id        = \"${aws_appautoscaling_target.ecs_target.resource_id}\"\r\n  scalable_dimension = \"${aws_appautoscaling_target.ecs_target.scalable_dimension}\"\r\n  service_namespace  = \"${aws_appautoscaling_target.ecs_target.service_namespace}\"\r\n\r\n  target_tracking_scaling_policy_configuration {\r\n    target_value       = 50\r\n    scale_in_cooldown  = 60\r\n    scale_out_cooldown = 60\r\n\r\n    predefined_metric_specification {\r\n      predefined_metric_type = \"ECSServiceAverageCPUUtilization\"\r\n    }\r\n  }\r\n}\r\n\r\nresource \"aws_ecs_cluster\" \"main\" {\r\n  name = \"${var.name}-Cluster\"\r\n}\r\n\r\nresource \"aws_ecs_task_definition\" \"app\" {\r\n  family                   = var.name\r\n  network_mode             = \"awsvpc\"\r\n  requires_compatibilities = [\"FARGATE\"]\r\n  cpu                      = var.fargate_cpu\r\n  memory                   = var.fargate_memory\r\n  execution_role_arn       = aws_iam_role.ecs_execution_role.arn\r\n  task_role_arn            = aws_iam_role.ecs_task_role.arn\r\n\r\n  container_definitions = <<DEFINITION\r\n[\r\n  {\r\n    \"cpu\": ${var.fargate_cpu},\r\n    \"image\": \"${var.app_image}\",\r\n    \"memory\": ${var.fargate_memory},\r\n    \"name\": \"app\",\r\n    \"networkMode\": \"awsvpc\",\r\n    \"portMappings\": [\r\n      {\r\n        \"containerPort\": ${var.app_port},\r\n        \"hostPort\": ${var.app_port}\r\n      }\r\n    ],\r\n    \"environment\":[{\r\n      \"name\": \"ASSETS_BUCKET\",\r\n      \"value\": \"${aws_s3_bucket.assets-bucket.bucket}\"\r\n    }, {\r\n      \"name\": \"DB_ENDPOINT\",\r\n      \"value\": \"${aws_db_instance.default.address}\"\r\n    }, {\r\n      \"name\": \"DB_USERNAME\",\r\n      \"value\": \"terraformdb\"\r\n    }, {\r\n      \"name\": \"DB_PASSWORD\",\r\n      \"value\": \"${random_string.password.result}\"\r\n    }, {\r\n      \"name\": \"DB_NAME\",\r\n      \"value\": \"terraformdb\"\r\n    }],\r\n    \"logConfiguration\": {\r\n      \"logDriver\": \"awslogs\",\r\n      \"options\": {\r\n        \"awslogs-group\": \"${aws_cloudwatch_log_group.task_logs.name}\",\r\n        \"awslogs-region\": \"${var.region}\",\r\n        \"awslogs-stream-prefix\": \"${aws_cloudwatch_log_stream.task_stream.name}\"\r\n      }\r\n    }\r\n  }\r\n]\r\nDEFINITION\r\n}\r\n\r\nresource \"aws_ecs_service\" \"main\" {\r\n  name = \"${var.name}-service\"\r\n  cluster = aws_ecs_cluster.main.id\r\n  task_definition = aws_ecs_task_definition.app.arn\r\n  desired_count = var.app_count\r\n  launch_type = \"FARGATE\"\r\n\r\n  network_configuration {\r\n    security_groups = [aws_security_group.ecs_tasks.id]\r\n    subnets = [\r\n      for subnet in aws_subnet.private :\r\n      subnet.id\r\n    ]\r\n  }\r\n\r\n  load_balancer {\r\n    target_group_arn = aws_alb_target_group.app.id\r\n    container_name = \"app\"\r\n    container_port = var.app_port\r\n  }\r\n\r\n  depends_on = [\r\n    aws_alb_listener.app,\r\n    aws_subnet.private,\r\n  ]\r\n}\r\n\r\nresource \"aws_security_group\" \"ecs_tasks\" {\r\n  name = \"ecs_tasks\"\r\n  description = \"Allow traffic from the internet\"\r\n  vpc_id = aws_vpc.main.id\r\n\r\n  ingress {\r\n    from_port = 3000\r\n    to_port = 3000\r\n    protocol = \"TCP\"\r\n    security_groups = [aws_security_group.lb.id]\r\n  }\r\n\r\n  ingress {\r\n    from_port = 49153\r\n    to_port = 65535\r\n    protocol = \"TCP\"\r\n    security_groups = [aws_security_group.lb.id]\r\n  }\r\n\r\n  egress {\r\n    from_port = 0\r\n    to_port = 0\r\n    protocol = \"-1\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n}\r\n\r\nresource \"aws_cloudwatch_log_group\" \"task_logs\" {\r\n  name = \"${var.name}-logs\"\r\n\r\n  tags = {\r\n    Application = var.name\r\n  }\r\n}\r\n\r\nresource \"aws_cloudwatch_log_stream\" \"task_stream\" {\r\n  name           = var.name\r\n  log_group_name = aws_cloudwatch_log_group.task_logs.name\r\n}\r\nresource \"aws_iam_policy\" \"ecs_execution_policy\" {\r\n  name        = \"${var.name}-ecs-execution-policy\"\r\n  path        = \"/\"\r\n  description = \"${var.name} ECS Task Execution Policy\"\r\n\r\n  policy = <<EOF\r\n{\r\n  \"Version\": \"2012-10-17\",\r\n  \"Statement\": [\r\n    {\r\n      \"Action\": [\r\n        \"ecr:GetAuthorizationToken\",\r\n        \"ecr:BatchCheckLayerAvailability\",\r\n        \"ecr:GetDownloadUrlForLayer\",\r\n        \"ecr:BatchGetImage\",\r\n        \"logs:CreateLogStream\",\r\n        \"logs:PutLogEvents\"\r\n      ],\r\n      \"Effect\": \"Allow\",\r\n      \"Resource\": \"*\"\r\n    }\r\n  ]\r\n}\r\nEOF\r\n}\r\n\r\nresource \"aws_iam_policy\" \"ecs_task_policy\" {\r\n  name = \"${var.name}-ecs-task-policy\"\r\n  path = \"/\"\r\n  description = \"${var.name} ECS Task Policy\"\r\n\r\n  policy = <<EOF\r\n{\r\n  \"Version\": \"2012-10-17\",\r\n  \"Statement\": [\r\n    {\r\n      \"Action\": [\r\n         \"s3:*\"\r\n      ],\r\n      \"Effect\": \"Allow\",\r\n      \"Resource\": \"*\"\r\n    }\r\n  ]\r\n}\r\nEOF\r\n}\r\n\r\nresource \"aws_iam_role\" \"ecs_execution_role\" {\r\n  name = \"${var.name}-ecs-exec-role\"\r\n\r\n  assume_role_policy = <<EOF\r\n{\r\n    \"Version\": \"2012-10-17\",\r\n    \"Statement\": [\r\n        {\r\n            \"Action\": \"sts:AssumeRole\",\r\n            \"Principal\": {\r\n            \"Service\": [\r\n                \"ecs-tasks.amazonaws.com\"\r\n            ]\r\n            },\r\n            \"Effect\": \"Allow\"\r\n        }\r\n    ]\r\n}\r\nEOF\r\n}\r\n\r\nresource \"aws_iam_role_policy_attachment\" \"ecs_exec_attachment\" {\r\n    role = aws_iam_role.ecs_execution_role.name\r\n    policy_arn = aws_iam_policy.ecs_execution_policy.arn\r\n}\r\n\r\nresource \"aws_iam_role\" \"ecs_task_role\" {\r\n  name = \"${var.name}-ecs-task-role\"\r\n\r\n  assume_role_policy = <<EOF\r\n{\r\n    \"Version\": \"2012-10-17\",\r\n    \"Statement\": [\r\n        {\r\n            \"Action\": \"sts:AssumeRole\",\r\n            \"Principal\": {\r\n            \"Service\": [\r\n                \"ecs-tasks.amazonaws.com\"\r\n            ]\r\n            },\r\n            \"Effect\": \"Allow\"\r\n        }\r\n    ]\r\n}\r\nEOF\r\n}\r\n\r\nresource \"aws_iam_role_policy_attachment\" \"ecs_task_attachment\" {\r\n  role       = aws_iam_role.ecs_task_role.name\r\n  policy_arn = aws_iam_policy.ecs_task_policy.arn\r\n}\r\n\r\n\r\nresource \"aws_iam_role\" \"ecs_scale_role\" {\r\n  name = \"${var.name}-ecs-scale-role\"\r\n\r\n  assume_role_policy = <<EOF\r\n{\r\n    \"Version\": \"2012-10-17\",\r\n    \"Statement\": [\r\n        {\r\n            \"Action\": \"sts:AssumeRole\",\r\n            \"Principal\": {\r\n            \"Service\": [\r\n                \"ecs-tasks.amazonaws.com\"\r\n            ]\r\n            },\r\n            \"Effect\": \"Allow\"\r\n        }\r\n    ]\r\n}\r\nEOF\r\n}\r\n\r\nresource \"aws_iam_policy\" \"ecs_scale_policy\" {\r\n  name = \"${var.name}-ecs-scale-policy\"\r\n  path = \"/\"\r\n  description = \"${var.name} ECS Scale Policy\"\r\n\r\n  policy = <<EOF\r\n{\r\n  \"Version\": \"2012-10-17\",\r\n  \"Statement\": [\r\n    {\r\n      \"Action\": [\r\n        \"ecs:DescribeServices\",\r\n        \"ecs:UpdateService\",\r\n        \"cloudwatch:DescribeAlarms\",\r\n        \"cloudwatch:PutMetricAlarm\"\r\n      ],\r\n      \"Effect\": \"Allow\",\r\n      \"Resource\": \"*\"\r\n    }\r\n  ]\r\n}\r\nEOF\r\n}\r\n\r\nresource \"aws_iam_role_policy_attachment\" \"ecs_scale_attachment\" {\r\n  role       = aws_iam_role.ecs_scale_role.name\r\n  policy_arn = aws_iam_policy.ecs_scale_policy.arn\r\n}\r\n"}]}
{"messages": [{"role": "user", "content": "Create a Google Cloud provider configuration in Terraform with the project ID \"replix-394315\" and region set to \"us-central1\". Allocate a reserved external IP address named \"static-ip\" in the same region. Create a Compute Engine instance named \"awesome-instance\" with the machine type \"e2-micro\" and boot it using the latest Ubuntu LTS image. Attach the reserved static IP to the instance's network interface and apply necessary tags for HTTP and HTTPS servers. Output the instance's external IP address after deployment."}, {"role": "assistant", "content": "\n#File: main.tf\nterraform {\n  required_providers {\n    google = {\n      source = \"hashicorp/google\"\n      version = \"6.16.0\" # Replace with the latest version\n    }\n  }\n}\n\n# Configure the Google Cloud provider\nprovider \"google\" {\n  project = \"replix-394315\"  # Replace with your project ID\n  region  = \"us-central1\"\n  zone    = \"us-central1-c\"\n}\n\n\n# Use the reserved external IP address\nresource \"google_compute_address\" \"static_ip\" {\n  name   = \"static-ip\"\n  region = \"us-central1\"\n}\n\n# Create a Compute Engine instance\nresource \"google_compute_instance\" \"default\" {\n  name         = \"awesome-instance\"\n  machine_type = \"e2-micro\"  # Free Tier eligible machine type\n  zone         = \"us-central1-a\"\n\n  tags = [\"http-server\", \"https-server\"]  \n\n  boot_disk {\n    initialize_params {\n      image = \"ubuntu-minimal-2004-lts\"  # Latest Ubuntu LTS image\n    }\n  }\n\n  network_interface {\n    network = \"default\"\n\n    access_config {\n      nat_ip = google_compute_address.static_ip.address\n      # Uncomment this if you want to use a static IP address\n      # nat_ip = \"35.208.129.42\"\n      network_tier = \"STANDARD\"\n    }\n  }\n\n  service_account {\n    scopes = [\"https://www.googleapis.com/auth/cloud-platform\"]\n  }\n\n  scheduling {\n    preemptible       = false\n    automatic_restart = true\n  }\n\n  labels = {\n    environment = \"free-tier\"\n  }\n}\n\noutput \"instance_ip\" {\n  value = google_compute_instance.default.network_interface[0].access_config[0].nat_ip\n}"}]}
{"messages": [{"role": "user", "content": "Create a resource group named \"factorio\" in the \"westeurope\" region. Set up a storage account called \"factoriodata\" with a Standard tier and LRS replication. Establish a storage share named \"gamedata\" within the storage account. Launch a container group named \"factorio-gameserver\" configured for Linux with specific CPU and memory requirements, exposing necessary ports for UDP and TCP. Finally, create a Function App tied to the app service plan, incorporating various app settings for deployment."}, {"role": "assistant", "content": "\n#File: control-function.tf\n\ndata \"azurerm_role_definition\" \"contributor\" {\n  name = \"Contributor\"\n}\n\nresource \"azurerm_role_assignment\" \"fn-contributor-access\" {\n  scope              = azurerm_container_group.gameserv.id\n  role_definition_id = \"${azurerm_container_group.gameserv.id}${data.azurerm_role_definition.contributor.id}\"\n  principal_id       = azurerm_function_app.control.identity[0].principal_id\n}\n\nresource \"azurerm_app_service_plan\" \"control-plan\" {\n  name                = \"azure-functions-test-service-plan\"\n  location            = azurerm_resource_group.main.location\n  resource_group_name = azurerm_resource_group.main.name\n  kind                = \"FunctionApp\"\n\n  sku {\n    tier = \"Dynamic\"\n    size = \"Y1\"\n  }\n}\n\nresource \"azurerm_function_app\" \"control\" {\n  name                      = \"${var.dns_label}-ctrl\"\n  location                  = azurerm_resource_group.main.location\n  resource_group_name       = azurerm_resource_group.main.name\n  app_service_plan_id       = azurerm_app_service_plan.control-plan.id\n  storage_connection_string = azurerm_storage_account.data.primary_connection_string\n  version                   = \"~3\"\n  app_settings = {\n    FUNCTIONS_EXTENSION_VERSION = \"~3\"\n    WEBSITE_RUN_FROM_PACKAGE    = var.package_deploy_url\n    FUNCTIONS_WORKER_RUNTIME    = \"dotnet\"\n    https_only                  = \"true\"\n    FUNCTION_APP_EDIT_MODE      = \"readonly\"\n    ACI_NAME                    = azurerm_container_group.gameserv.name\n    ACI_RESOURCE_GROUP          = azurerm_resource_group.main.name\n    AzureWebJobsDisableHomepage = \"true\"\n  }\n  identity {\n    type = \"SystemAssigned\"\n  }\n}\n\n#File: main.tf\nvariable REGION {\n  default = \"westeurope\"\n}\n\nvariable n_cores {\n  default = 2\n}\n\nvariable mem_gb {\n  default = 4\n}\n\nvariable package_deploy_url {\n  default = \"https://github.com/celaus/fn-manage-aci/releases/download/tag-7287778cb03583625477550ab8eb6fcabe5a7120/aci-manage.zip\"\n}\n\nvariable RESOURCE_GROUP_NAME {\n  default = \"factorio\"\n}\n\nvariable factorio_server_version {\n  default = \"0.18.21\"\n}\n\nvariable dns_label {}\nvariable tenantid {}\nvariable subid {}\n\nprovider \"azurerm\" {\n  version = \"~>2.2.0\"\n  features {}\n\n  subscription_id = var.subid\n  tenant_id       = var.tenantid\n}\n\nresource \"azurerm_resource_group\" \"main\" {\n  name     = var.RESOURCE_GROUP_NAME\n  location = var.REGION\n}\n\nresource \"azurerm_storage_account\" \"data\" {\n  name                     = \"factoriodata\"\n  resource_group_name      = azurerm_resource_group.main.name\n  location                 = azurerm_resource_group.main.location\n  account_tier             = \"Standard\"\n  account_replication_type = \"LRS\"\n}\n\n\n\nresource \"azurerm_storage_share\" \"gamedata\" {\n  name                 = \"gamedata\"\n  storage_account_name = azurerm_storage_account.data.name\n  quota                = 50\n}\n\n\nresource \"azurerm_container_group\" \"gameserv\" {\n  name                = \"factorio-gameserver\"\n  location            = azurerm_resource_group.main.location\n  resource_group_name = azurerm_resource_group.main.name\n  ip_address_type     = \"public\"\n  dns_name_label      = var.dns_label\n  os_type             = \"Linux\"\n\n  container {\n    name   = \"factoriogame\"\n    image  = \"factoriotools/factorio:${var.factorio_server_version}\"\n    cpu    = var.n_cores\n    memory = var.mem_gb\n\n    ports {\n      port     = 34197\n      protocol = \"UDP\"\n    }\n    ports {\n      port     = 27015\n      protocol = \"TCP\"\n    }\n\n    volume {\n      name                 = \"gamedatamount\"\n      mount_path           = \"/factorio\"\n      storage_account_name = azurerm_storage_account.data.name\n      storage_account_key  = azurerm_storage_account.data.primary_access_key\n      share_name           = azurerm_storage_share.gamedata.name\n    }\n  }\n}\n"}]}
{"messages": [{"role": "user", "content": "Create a DEV environment using the specified Git module, setting the prefix, Let's Encrypt email, and location variables. Create a PROD environment with the same module, using the appropriate configurations for production. Initialize a Spinnaker module that utilizes both DEV and PROD environments while maintaining proper prefixes and locations. Configure the necessary providers for Azure, Kubernetes, and Helm as defined in the providers file. Output the dashboard URLs for both DEV and PROD environments."}, {"role": "assistant", "content": "\n#File: main.tf\nmodule \"DEV\" {\n  source            = \"git::https://github.com/DevOpsDemoTF/DevOpsDemo-k8s?ref=v0.1.2\"\n  prefix            = var.prefix\n  letsencrypt_email = var.letsencrypt_email\n  environment       = \"DEV\"\n  k8s_agent_count   = \"1\"\n  k8s_agent_size    = \"Standard_E2s_v3\"\n  location          = var.location\n}\n\nmodule \"PROD\" {\n  source            = \"git::https://github.com/DevOpsDemoTF/DevOpsDemo-k8s?ref=v0.1.2\"\n  prefix            = var.prefix\n  letsencrypt_email = var.letsencrypt_email\n  environment       = \"PROD\"\n  k8s_agent_count   = \"1\"\n  k8s_agent_size    = \"Standard_D1_v2\"\n  location          = var.location\n}\n\nmodule \"Spinnaker\" {\n  source       = \"git::https://github.com/DevOpsDemoTF/DevOpsDemo-Spinnaker?ref=v0.1.1\"\n  environments = [module.DEV.environment, module.PROD.environment]\n\n  prefix   = var.prefix\n  location = var.location\n  domain   = module.DEV.fqdn\n\n  providers = {\n    kubernetes = kubernetes.kubernetes_dev\n    helm       = helm.helm_dev\n  }\n}\n\noutput \"dashboards\" {\n  value = {\n    \"DEV\": module.DEV.dashboard_url\n    \"PROD\": module.PROD.dashboard_url\n  }\n}\n\n#File: providers.tf\nprovider \"azurerm\" {\n  version = \"~>1.33\"\n}\n\nprovider \"azuread\" {\n  version = \"~>0.3\"\n}\n\nprovider \"local\" {\n  version = \"~>1.3\"\n}\n\nprovider \"random\" {\n  version = \"~>2.2\"\n}\n\nprovider \"template\" {\n  version = \"~>2.1\"\n}\n\nprovider \"null\" {\n  version = \"~>2.1\"\n}\n\nprovider \"kubernetes\" {\n  version = \"~>1.8\"\n  alias   = \"kubernetes_dev\"\n  host    = module.DEV.login.host\n\n  client_certificate     = base64decode(module.DEV.login.client_certificate)\n  client_key             = base64decode(module.DEV.login.client_key)\n  cluster_ca_certificate = base64decode(module.DEV.login.cluster_ca_certificate)\n}\n\nprovider \"helm\" {\n  version         = \"~>0.10\"\n  alias           = \"helm_dev\"\n  namespace       = module.DEV.helm.tiller_namespace\n  service_account = module.DEV.helm.tiller_name\n\n  kubernetes {\n    host = module.DEV.login.host\n\n    client_certificate     = base64decode(module.DEV.login.client_certificate)\n    client_key             = base64decode(module.DEV.login.client_key)\n    cluster_ca_certificate = base64decode(module.DEV.login.cluster_ca_certificate)\n  }\n}\n\n#File: variables.tf\nvariable \"prefix\" {\n  default = \"DevOpsDemo\"\n}\n\nvariable \"letsencrypt_email\" {}\n\nvariable \"location\" {\n  default = \"East US\"\n}"}]}
{"messages": [{"role":"user","content":"Create a Terraform module that manages both Gateway and Interface VPC Endpoints within a specified VPC, dynamically creating endpoints based on input maps and associating them with route tables, subnets, and security groups. Use local variables to flatten and map input data structures for flexible resource creation and handles special cases like replacing the default security group association. Additionally,leverages external label modules for consistent tagging and supports conditional resource creation based on an enabled flag."},{"role":"assistant","content":"locals {\r\n  enabled = module.this.enabled && (length(var.gateway_vpc_endpoints) + length(var.interface_vpc_endpoints) > 0)\r\n\r\n  # Because route table ID may not be known at plan time, we cannot use it as a key\r\n  route_table_associations_list = flatten([for k, v in var.gateway_vpc_endpoints : [\r\n    for i, r in v.route_table_ids : {\r\n      key            = \"${k}[${i}]\"\r\n      gateway        = k\r\n      route_table_id = r\r\n    }\r\n  ]])\r\n\r\n  route_table_associations_map = { for v in local.route_table_associations_list : v.key => v }\r\n\r\n  # Because subnet ID may not be known at plan time, we cannot use it as a key\r\n  subnet_associations_list = flatten([for k, v in var.interface_vpc_endpoints : [\r\n    for i, s in v.subnet_ids : {\r\n      key       = \"${k}[${i}]\"\r\n      interface = k\r\n      subnet_id = s\r\n    }\r\n  ]])\r\n\r\n  subnet_associations_map = { for v in local.subnet_associations_list : v.key => v }\r\n\r\n  # Because security group ID may not be known at plan time, we cannot use it as a key\r\n  security_group_associations_list = flatten([for k, v in var.interface_vpc_endpoints : [\r\n    for i, s in v.security_group_ids : {\r\n      key               = \"${k}[${i}]\"\r\n      index             = i\r\n      interface         = k\r\n      security_group_id = s\r\n    }\r\n  ]])\r\n\r\n  security_group_associations_map = { for v in local.security_group_associations_list : v.key => v }\r\n}\r\n\r\n# Unfortunately, the AWS provider makes us jump through hoops to deal with the\r\n# association of an endpoint interface with the default VPC security group.\r\n# See https://github.com/hashicorp/terraform-provider-aws/issues/27100\r\ndata \"aws_security_group\" \"default\" {\r\n  count = local.enabled ? 1 : 0\r\n\r\n  filter {\r\n    name   = \"group-name\"\r\n    values = [\"default\"]\r\n  }\r\n\r\n  filter {\r\n    name   = \"vpc-id\"\r\n    values = [var.vpc_id]\r\n  }\r\n}\r\n\r\ndata \"aws_vpc_endpoint_service\" \"gateway_endpoint_service\" {\r\n  for_each     = local.enabled ? var.gateway_vpc_endpoints : {}\r\n  service      = var.gateway_vpc_endpoints[each.key].name\r\n  service_type = \"Gateway\"\r\n}\r\n\r\ndata \"aws_vpc_endpoint_service\" \"interface_endpoint_service\" {\r\n  for_each     = local.enabled ? var.interface_vpc_endpoints : {}\r\n  service      = var.interface_vpc_endpoints[each.key].name\r\n  service_type = \"Interface\"\r\n}\r\n\r\nmodule \"gateway_endpoint_label\" {\r\n  source  = \"cloudposse/label/null\"\r\n  version = \"0.25.0\"\r\n\r\n  for_each   = local.enabled ? data.aws_vpc_endpoint_service.gateway_endpoint_service : {}\r\n  attributes = [each.key]\r\n\r\n  context = module.this.context\r\n}\r\n\r\nmodule \"interface_endpoint_label\" {\r\n  source  = \"cloudposse/label/null\"\r\n  version = \"0.25.0\"\r\n\r\n  for_each   = local.enabled ? data.aws_vpc_endpoint_service.interface_endpoint_service : {}\r\n  attributes = [each.key]\r\n\r\n  context = module.this.context\r\n}\r\n\r\nresource \"aws_vpc_endpoint\" \"gateway_endpoint\" {\r\n  for_each          = local.enabled ? data.aws_vpc_endpoint_service.gateway_endpoint_service : {}\r\n  service_name      = data.aws_vpc_endpoint_service.gateway_endpoint_service[each.key].service_name\r\n  policy            = var.gateway_vpc_endpoints[each.key].policy\r\n  vpc_endpoint_type = data.aws_vpc_endpoint_service.gateway_endpoint_service[each.key].service_type\r\n  vpc_id            = var.vpc_id\r\n\r\n  tags = module.gateway_endpoint_label[each.key].tags\r\n}\r\n\r\nresource \"aws_vpc_endpoint_route_table_association\" \"gateway\" {\r\n  for_each = local.enabled ? local.route_table_associations_map : {}\r\n\r\n  route_table_id  = each.value.route_table_id\r\n  vpc_endpoint_id = aws_vpc_endpoint.gateway_endpoint[each.value.gateway].id\r\n}\r\n\r\nresource \"aws_vpc_endpoint\" \"interface_endpoint\" {\r\n  for_each            = local.enabled ? data.aws_vpc_endpoint_service.interface_endpoint_service : {}\r\n  service_name        = data.aws_vpc_endpoint_service.interface_endpoint_service[each.key].service_name\r\n  policy              = var.interface_vpc_endpoints[each.key].policy\r\n  vpc_endpoint_type   = data.aws_vpc_endpoint_service.interface_endpoint_service[each.key].service_type\r\n  vpc_id              = var.vpc_id\r\n  private_dns_enabled = var.interface_vpc_endpoints[each.key].private_dns_enabled\r\n\r\n  tags = module.interface_endpoint_label[each.key].tags\r\n}\r\n\r\nresource \"aws_vpc_endpoint_subnet_association\" \"interface\" {\r\n  for_each = local.enabled ? local.subnet_associations_map : {}\r\n\r\n  subnet_id       = each.value.subnet_id\r\n  vpc_endpoint_id = aws_vpc_endpoint.interface_endpoint[each.value.interface].id\r\n}\r\n\r\nresource \"aws_vpc_endpoint_security_group_association\" \"interface\" {\r\n  for_each = local.enabled ? local.security_group_associations_map : {}\r\n\r\n  # It is an error to replace the default association with the default security group\r\n  # See https://github.com/hashicorp/terraform-provider-aws/issues/27100\r\n  replace_default_association = each.value.index == 0 && each.value.security_group_id != data.aws_security_group.default[0].id\r\n\r\n  security_group_id = each.value.security_group_id\r\n  vpc_endpoint_id   = aws_vpc_endpoint.interface_endpoint[each.value.interface].id\r\n\r\n  depends_on = [aws_vpc_endpoint_subnet_association.interface]\r\n}\r\nvariable \"vpc_id\" {\r\n  type        = string\r\n  description = \"VPC ID where the VPC Endpoints will be created (e.g. `vpc-aceb2723`)\"\r\n}\r\n\r\nvariable \"gateway_vpc_endpoints\" {\r\n  type = map(object({\r\n    name            = string\r\n    policy          = string\r\n    route_table_ids = list(string)\r\n  }))\r\n  description = <<-EOT\r\n    A map of Gateway VPC Endpoints to provision into the VPC. This is a map of objects with the following attributes:\r\n    - `name`: Short service name (either \"s3\" or \"dynamodb\")\r\n    - `policy` = A policy (as JSON string) to attach to the endpoint that controls access to the service. May be `null` for full access.\r\n    - `route_table_ids`: List of route tables to associate the gateway with. Routes to the gateway\r\n      will be automatically added to these route tables.\r\n    EOT\r\n  default     = {}\r\n}\r\n\r\nvariable \"interface_vpc_endpoints\" {\r\n  type = map(object({\r\n    name                = string\r\n    policy              = string\r\n    private_dns_enabled = bool\r\n    security_group_ids  = list(string)\r\n    subnet_ids          = list(string)\r\n  }))\r\n  description = <<-EOT\r\n    A map of Interface VPC Endpoints to provision into the VPC.\r\n    This is a map of objects with the following attributes:\r\n    - `name`: Simple name of the service, like \"ec2\" or \"redshift\"\r\n    - `policy`: A policy (as JSON string) to attach to the endpoint that controls access to the service. May be `null` for full access.\r\n    - `private_dns_enabled`: Set `true` to associate a private hosted zone with the specified VPC\r\n    - `security_group_ids`: The ID of one or more security groups to associate with the network interface. The first\r\n      security group will replace the default association with the VPC's default security group. If you want\r\n      to maintain the association with the default security group, either leave `security_group_ids` empty or\r\n      include the default security group ID in the list.\r\n    - `subnet_ids`: List of subnet in which to install the endpoints.\r\n   EOT\r\n  default     = {}\r\n}\r\n\r\nvariable \"post_creation_refresh_delay\" {\r\n  type        = string\r\n  description = <<-EOT\r\n    After endpoints are created via Terraform, some additional resources are provisioned by AWS\r\n    that do not immediately appear in the resource, and therefore would not appear in the output\r\n    of the resources attributes. Examples include private DNS entries and Network Interface IDs.\r\n    This input (in `go` duration format) sets a time delay to allow for such activity, after which\r\n    the endpoint data is fetched via data sources for output.\r\n    EOT\r\n  default     = \"30s\"\r\n}\r\n\r\nmodule \"this\" {\r\n  source  = \"cloudposse/label/null\"\r\n  version = \"0.25.0\" # requires Terraform >= 0.13.0\r\n\r\n  enabled             = var.enabled\r\n  namespace           = var.namespace\r\n  tenant              = var.tenant\r\n  environment         = var.environment\r\n  stage               = var.stage\r\n  name                = var.name\r\n  delimiter           = var.delimiter\r\n  attributes          = var.attributes\r\n  tags                = var.tags\r\n  additional_tag_map  = var.additional_tag_map\r\n  label_order         = var.label_order\r\n  regex_replace_chars = var.regex_replace_chars\r\n  id_length_limit     = var.id_length_limit\r\n  label_key_case      = var.label_key_case\r\n  label_value_case    = var.label_value_case\r\n  descriptor_formats  = var.descriptor_formats\r\n  labels_as_tags      = var.labels_as_tags\r\n\r\n  context = var.context\r\n}\r\n\r\n# Copy contents of cloudposse/terraform-null-label/variables.tf here\r\n\r\nvariable \"context\" {\r\n  type = any\r\n  default = {\r\n    enabled             = true\r\n    namespace           = null\r\n    tenant              = null\r\n    environment         = null\r\n    stage               = null\r\n    name                = null\r\n    delimiter           = null\r\n    attributes          = []\r\n    tags                = {}\r\n    additional_tag_map  = {}\r\n    regex_replace_chars = null\r\n    label_order         = []\r\n    id_length_limit     = null\r\n    label_key_case      = null\r\n    label_value_case    = null\r\n    descriptor_formats  = {}\r\n    # Note: we have to use [] instead of null for unset lists due to\r\n    # https://github.com/hashicorp/terraform/issues/28137\r\n    # which was not fixed until Terraform 1.0.0,\r\n    # but we want the default to be all the labels in `label_order`\r\n    # and we want users to be able to prevent all tag generation\r\n    # by setting `labels_as_tags` to `[]`, so we need\r\n    # a different sentinel to indicate \"default\"\r\n    labels_as_tags = [\"unset\"]\r\n  }\r\n  description = <<-EOT\r\n    Single object for setting entire context at once.\r\n    See description of individual variables for details.\r\n    Leave string and numeric variables as `null` to use default value.\r\n    Individual variable settings (non-null) override settings in context object,\r\n    except for attributes, tags, and additional_tag_map, which are merged.\r\n  EOT\r\n\r\n  validation {\r\n    condition     = lookup(var.context, \"label_key_case\", null) == null ? true : contains([\"lower\", \"title\", \"upper\"], var.context[\"label_key_case\"])\r\n    error_message = \"Allowed values: `lower`, `title`, `upper`.\"\r\n  }\r\n\r\n  validation {\r\n    condition     = lookup(var.context, \"label_value_case\", null) == null ? true : contains([\"lower\", \"title\", \"upper\", \"none\"], var.context[\"label_value_case\"])\r\n    error_message = \"Allowed values: `lower`, `title`, `upper`, `none`.\"\r\n  }\r\n}\r\n\r\nvariable \"enabled\" {\r\n  type        = bool\r\n  default     = null\r\n  description = \"Set to false to prevent the module from creating any resources\"\r\n}\r\n\r\nvariable \"namespace\" {\r\n  type        = string\r\n  default     = null\r\n  description = \"ID element. Usually an abbreviation of your organization name, e.g. 'eg' or 'cp', to help ensure generated IDs are globally unique\"\r\n}\r\n\r\nvariable \"tenant\" {\r\n  type        = string\r\n  default     = null\r\n  description = \"ID element _(Rarely used, not included by default)_. A customer identifier, indicating who this instance of a resource is for\"\r\n}\r\n\r\nvariable \"environment\" {\r\n  type        = string\r\n  default     = null\r\n  description = \"ID element. Usually used for region e.g. 'uw2', 'us-west-2', OR role 'prod', 'staging', 'dev', 'UAT'\"\r\n}\r\n\r\nvariable \"stage\" {\r\n  type        = string\r\n  default     = null\r\n  description = \"ID element. Usually used to indicate role, e.g. 'prod', 'staging', 'source', 'build', 'test', 'deploy', 'release'\"\r\n}\r\n\r\nvariable \"name\" {\r\n  type        = string\r\n  default     = null\r\n  description = <<-EOT\r\n    ID element. Usually the component or solution name, e.g. 'app' or 'jenkins'.\r\n    This is the only ID element not also included as a `tag`.\r\n    The \"name\" tag is set to the full `id` string. There is no tag with the value of the `name` input.\r\n    EOT\r\n}\r\n\r\nvariable \"delimiter\" {\r\n  type        = string\r\n  default     = null\r\n  description = <<-EOT\r\n    Delimiter to be used between ID elements.\r\n    Defaults to `-` (hyphen). Set to `\"\"` to use no delimiter at all.\r\n  EOT\r\n}\r\n\r\nvariable \"attributes\" {\r\n  type        = list(string)\r\n  default     = []\r\n  description = <<-EOT\r\n    ID element. Additional attributes (e.g. `workers` or `cluster`) to add to `id`,\r\n    in the order they appear in the list. New attributes are appended to the\r\n    end of the list. The elements of the list are joined by the `delimiter`\r\n    and treated as a single ID element.\r\n    EOT\r\n}\r\n\r\nvariable \"labels_as_tags\" {\r\n  type        = set(string)\r\n  default     = [\"default\"]\r\n  description = <<-EOT\r\n    Set of labels (ID elements) to include as tags in the `tags` output.\r\n    Default is to include all labels.\r\n    Tags with empty values will not be included in the `tags` output.\r\n    Set to `[]` to suppress all generated tags.\r\n    **Notes:**\r\n      The value of the `name` tag, if included, will be the `id`, not the `name`.\r\n      Unlike other `null-label` inputs, the initial setting of `labels_as_tags` cannot be\r\n      changed in later chained modules. Attempts to change it will be silently ignored.\r\n    EOT\r\n}\r\n\r\nvariable \"tags\" {\r\n  type        = map(string)\r\n  default     = {}\r\n  description = <<-EOT\r\n    Additional tags (e.g. `{'BusinessUnit': 'XYZ'}`).\r\n    Neither the tag keys nor the tag values will be modified by this module.\r\n    EOT\r\n}\r\n\r\nvariable \"additional_tag_map\" {\r\n  type        = map(string)\r\n  default     = {}\r\n  description = <<-EOT\r\n    Additional key-value pairs to add to each map in `tags_as_list_of_maps`. Not added to `tags` or `id`.\r\n    This is for some rare cases where resources want additional configuration of tags\r\n    and therefore take a list of maps with tag key, value, and additional configuration.\r\n    EOT\r\n}\r\n\r\nvariable \"label_order\" {\r\n  type        = list(string)\r\n  default     = null\r\n  description = <<-EOT\r\n    The order in which the labels (ID elements) appear in the `id`.\r\n    Defaults to [\"namespace\", \"environment\", \"stage\", \"name\", \"attributes\"].\r\n    You can omit any of the 6 labels (\"tenant\" is the 6th), but at least one must be present.\r\n    EOT\r\n}\r\n\r\nvariable \"regex_replace_chars\" {\r\n  type        = string\r\n  default     = null\r\n  description = <<-EOT\r\n    Terraform regular expression (regex) string.\r\n    Characters matching the regex will be removed from the ID elements.\r\n    If not set, `\"/[^a-zA-Z0-9-]/\"` is used to remove all characters other than hyphens, letters and digits.\r\n  EOT\r\n}\r\n\r\nvariable \"id_length_limit\" {\r\n  type        = number\r\n  default     = null\r\n  description = <<-EOT\r\n    Limit `id` to this many characters (minimum 6).\r\n    Set to `0` for unlimited length.\r\n    Set to `null` for keep the existing setting, which defaults to `0`.\r\n    Does not affect `id_full`.\r\n  EOT\r\n  validation {\r\n    condition     = var.id_length_limit == null ? true : var.id_length_limit >= 6 || var.id_length_limit == 0\r\n    error_message = \"The id_length_limit must be >= 6 if supplied (not null), or 0 for unlimited length.\"\r\n  }\r\n}\r\n\r\nvariable \"label_key_case\" {\r\n  type        = string\r\n  default     = null\r\n  description = <<-EOT\r\n    Controls the letter case of the `tags` keys (label names) for tags generated by this module.\r\n    Does not affect keys of tags passed in via the `tags` input.\r\n    Possible values: `lower`, `title`, `upper`.\r\n    Default value: `title`.\r\n  EOT\r\n\r\n  validation {\r\n    condition     = var.label_key_case == null ? true : contains([\"lower\", \"title\", \"upper\"], var.label_key_case)\r\n    error_message = \"Allowed values: `lower`, `title`, `upper`.\"\r\n  }\r\n}\r\n\r\nvariable \"label_value_case\" {\r\n  type        = string\r\n  default     = null\r\n  description = <<-EOT\r\n    Controls the letter case of ID elements (labels) as included in `id`,\r\n    set as tag values, and output by this module individually.\r\n    Does not affect values of tags passed in via the `tags` input.\r\n    Possible values: `lower`, `title`, `upper` and `none` (no transformation).\r\n    Set this to `title` and set `delimiter` to `\"\"` to yield Pascal Case IDs.\r\n    Default value: `lower`.\r\n  EOT\r\n\r\n  validation {\r\n    condition     = var.label_value_case == null ? true : contains([\"lower\", \"title\", \"upper\", \"none\"], var.label_value_case)\r\n    error_message = \"Allowed values: `lower`, `title`, `upper`, `none`.\"\r\n  }\r\n}\r\n\r\nvariable \"descriptor_formats\" {\r\n  type        = any\r\n  default     = {}\r\n  description = <<-EOT\r\n    Describe additional descriptors to be output in the `descriptors` output map.\r\n    Map of maps. Keys are names of descriptors. Values are maps of the form\r\n    `{\r\n       format = string\r\n       labels = list(string)\r\n    }`\r\n    (Type is `any` so the map values can later be enhanced to provide additional options.)\r\n    `format` is a Terraform format string to be passed to the `format()` function.\r\n    `labels` is a list of labels, in order, to pass to `format()` function.\r\n    Label values will be normalized before being passed to `format()` so they will be\r\n    identical to how they appear in `id`.\r\n    Default is `{}` (`descriptors` output will be empty).\r\n    EOT\r\n}\r\n"}]}
{"messages": [{"role": "user", "content": "Create a Google Compute Network using the specified network name. Define a Google Compute Subnetwork using the provided subnet name. Set up a Google Compute Router with the designated router name and associate it with the created network. Establish a NAT configuration for the router, enabling logging to capture error events only. Output the project ID, network ID, subnet name, router name, and NAT name for verification."}, {"role": "assistant", "content": "\n#File: main.tf\nterraform {\n  required_providers {\n    google = {\n      source  = \"hashicorp/google\"\n      version = \"3.5.0\"\n    }\n  }\n}\n\nprovider \"google\" {\n  // TODO: Add your GCP credentials, if outside Cloud Shell\n}\n\ndata \"google_client_config\" \"this\" {}\n\ndata \"google_compute_network\" \"net\" {\n  project = data.google_client_config.this.project\n  name    = var.network_name\n}\n\ndata \"google_compute_subnetwork\" \"subnet\" {\n  name = var.subnet_name\n}\n\nresource \"google_compute_router\" \"router\" {\n  name    = var.router_name\n  region  = data.google_compute_subnetwork.subnet.region\n  network = data.google_compute_network.net.id\n}\n\nresource \"google_compute_router_nat\" \"nat\" {\n  name                               = var.nat_name\n  router                             = google_compute_router.router.name\n  region                             = google_compute_router.router.region\n  nat_ip_allocate_option             = \"AUTO_ONLY\"\n  source_subnetwork_ip_ranges_to_nat = \"ALL_SUBNETWORKS_ALL_IP_RANGES\"\n\n  log_config {\n    enable = true\n    filter = \"ERRORS_ONLY\"\n  }\n}\n\noutput \"project\" {\n  value = data.google_client_config.this.project\n}\n\noutput \"network_id\" {\n  value = data.google_compute_network.net.id\n}\n\noutput \"subnet_name\" {\n  value = data.google_compute_subnetwork.subnet.name\n}\n\noutput \"router_name\" {\n  value = google_compute_router.router.name\n}\n\noutput \"nat_name\" {\n  value = google_compute_router_nat.nat.name\n}\n\n#File: variables.tf\nvariable \"network_name\" {\n  default = \"csp-vpc1\"\n}\n\nvariable \"subnet_name\" {\n  default = \"csp-vpc1-subnet\"\n}\n\nvariable \"router_name\" {\n  default = \"csp-vpc1-nat-router\"\n}\n\nvariable \"nat_name\" {\n  default = \"csp-vpc1-nat\"\n}\n"}]}
{"messages": [{"role": "user", "content": "Create a Google Organization Policy to prevent public access to Cloud Storage buckets. Enforce restrictions on resource locations to specific geographic areas. Disable external IP access for virtual machines to enhance security. Require OS Login for virtual machine management. Prevent the creation of service account keys for better credential handling and restrict IP forwarding to designated projects."}, {"role": "assistant", "content": "\n#File: main.tf\n# Prevent public access to GCS buckets\n# This policy enforces uniform bucket-level access and prevents public access to Cloud Storage data\n# It helps prevent data exposure through misconfigured bucket permissions\n# Doc: https://cloud.google.com/storage/docs/public-access-prevention\nresource \"google_org_policy_policy\" \"storage_public_access_prevention\" {\n  name   = \"organizations/${var.organization_id}/policies/storage.publicAccessPrevention\"\n  parent = \"organizations/${var.organization_id}\"\n\n  spec {\n    rules {\n      enforce = true\n    }\n  }\n}\n\n# Restrict resource location to specific regions\n# This policy ensures that GCP resources are only created in approved geographic locations\n# Useful for data residency requirements and compliance with regulations like GDPR\n# You can specify locations using:\n# - Individual regions (us-central1)\n# - Multi-regions (us-locations)\n# - Custom locations\n# Doc: https://cloud.google.com/resource-manager/docs/organization-policy/defining-locations\nresource \"google_org_policy_policy\" \"resource_location\" {\n  name   = \"organizations/${var.organization_id}/policies/gcp.resourceLocations\"\n  parent = \"organizations/${var.organization_id}\"\n\n  spec {\n    rules {\n      values {\n        allowed_values = [\n          \"in:us-locations\",\n          \"in:europe-locations\"\n        ]\n      }\n    }\n  }\n}\n\n# Restrict VM external IP access\n# This policy prevents VMs from being assigned external IP addresses\n# Forces the use of Cloud NAT or VPN for internet access, improving security\n# Best practice is to use internal IPs and control internet access through centralized egress points\n# Doc: https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address#disableexternalip\nresource \"google_org_policy_policy\" \"vm_external_ip_access\" {\n  name   = \"organizations/${var.organization_id}/policies/compute.vmExternalIpAccess\"\n  parent = \"organizations/${var.organization_id}\"\n\n  spec {\n    rules {\n      deny_all = true\n    }\n  }\n}\n\n\n# Require OS Login\n# This policy enforces the use of OS Login for all VMs\n# OS Login provides:\n# - Automated SSH key management\n# - Fine-grained IAM roles for SSH access\n# - Centralized user management\n# - Integration with Cloud Audit Logs\n# Doc: https://cloud.google.com/compute/docs/oslogin\nresource \"google_org_policy_policy\" \"require_os_login\" {\n  name   = \"organizations/${var.organization_id}/policies/compute.requireOsLogin\"\n  parent = \"organizations/${var.organization_id}\"\n\n  spec {\n    rules {\n      enforce = true\n    }\n  }\n}\n\n# Restrict Shared VPC hosting to specific projects\n# This policy controls which projects can host Shared VPCs\n# Shared VPC allows organizations to:\n# - Centralize network management\n# - Share network resources across projects\n# - Implement hub-and-spoke network architectures\n# Best practice is to limit this capability to dedicated network admin projects\n# Doc: https://cloud.google.com/vpc/docs/shared-vpc\nresource \"google_org_policy_policy\" \"shared_vpc_hosting\" {\n  name   = \"organizations/${var.organization_id}/policies/compute.restrictSharedVpcHostProjects\"\n  parent = \"organizations/${var.organization_id}\"\n\n  spec {\n    rules {\n      values {\n        allowed_values = var.allowed_shared_vpc_host_projects\n      }\n    }\n  }\n}\n\n# Disable service account key creation\n# This policy prevents the creation of service account keys\n# Service account keys are long-term credentials that pose security risks:\n# - They can be copied and used outside of GCP\n# - They don't expire by default\n# - They're harder to audit and rotate\n# Instead, use:\n# - Workload Identity for GKE\n# - Service Account Impersonation\n# - Cloud Run and Cloud Functions built-in service accounts\n# Doc: https://cloud.google.com/iam/docs/best-practices-for-managing-service-account-keys\nresource \"google_org_policy_policy\" \"disable_sa_key_creation\" {\n  name   = \"organizations/${var.organization_id}/policies/iam.disableServiceAccountKeyCreation\"\n  parent = \"organizations/${var.organization_id}\"\n\n  spec {\n    rules {\n      enforce = true\n    }\n  }\n}\n\n# Restrict IP forwarding to specific projects\n# This policy controls which projects can create instances that forward IP packets\n# IP forwarding is needed for:\n# - Network virtual appliances\n# - Load balancers\n# - NAT gateways\n# Best practice is to limit this capability to networking admin projects\n# Doc: https://cloud.google.com/vpc/docs/using-routes#canipforward\nresource \"google_org_policy_policy\" \"vm_can_ip_forward\" {\n  name   = \"organizations/${var.organization_id}/policies/compute.vmCanIpForward\"\n  parent = \"organizations/${var.organization_id}\"\n\n  spec {\n    rules {\n      values {\n        allowed_values = var.allowed_ip_forwarding_projects\n      }\n    }\n  }\n} \n#File: outputs.tf\noutput \"enabled_policies\" {\n  description = \"List of enabled organizational policies\"\n  value = [\n    \"storage.publicAccessPrevention\",\n    \"gcp.resourceLocations\",\n    \"compute.vmExternalIpAccess\",\n    \"compute.requireOsLogin\",\n    \"compute.restrictSharedVpcHostProjects\",\n    \"iam.disableServiceAccountKeyCreation\",\n    \"compute.vmCanIpForward\"\n  ]\n} \n#File: variables.tf\nvariable \"organization_id\" {\n  description = \"The organization ID to apply policies to\"\n  type        = string\n}\n\nvariable \"allowed_shared_vpc_host_projects\" {\n  description = \"List of projects allowed to be Shared VPC hosts\"\n  type        = list(string)\n  default     = []\n}\n\nvariable \"allowed_ip_forwarding_projects\" {\n  description = \"List of projects allowed to use IP forwarding\"\n  type        = list(string)\n  default     = []\n} \n#File: versions.tf\nterraform {\n  required_version = \">= 1.0.0\"\n  required_providers {\n    google = {\n      source  = \"hashicorp/google\"\n      version = \">= 4.0.0\"\n    }\n    google-beta = {\n      source  = \"hashicorp/google-beta\"\n      version = \">= 4.0.0\"\n    }\n  }\n} "}]}
{"messages": [{"role":"user","content":"Generate a Terraform policy of type AISERVICES_OPT_OUT_POLICY that opts out my entire AWS Organization from using all supported Amazon AI services. Include the JSON structure and Terraform resources to attach the policy to the organization root."},{"role":"assistant","content":"provider \"aws\" {\r\n}\r\n\r\nvariable \"additional_enable_policy_types\" {\r\n  type        = list(string)\r\n  description = \"List of policy types to enable in addition to AISERVICES_OPT_OUT_POLICY, which is always enabled.\"\r\n  default     = []\r\n}\r\n\r\nvariable \"aws_service_access_principals\" {\r\n  type        = set(string)\r\n  default     = []\r\n  description = \"List of AWS service principal names for which you want to enable integration with your organization. Has no effect if create_organization is false.\"\r\n}\r\n\r\nvariable \"create_organization\" {\r\n  type        = bool\r\n  default     = false\r\n  description = \"Whether or not to use this module to create your AWS organization.\"\r\n}\r\n\r\nvariable \"python_interpreter\" {\r\n  type        = string\r\n  default     = \"env python3\"\r\n  description = \"The python interpreter to use for running the provisioner script\"\r\n}\r\nresource \"aws_organizations_organization\" \"organization\" {\r\n  count                         = var.create_organization ? 1 : 0\r\n  enabled_policy_types          = flatten([\"AISERVICES_OPT_OUT_POLICY\", var.additional_enable_policy_types])\r\n  aws_service_access_principals = var.aws_service_access_principals\r\n  # The above features require feature_set to be set to ALL.\r\n  feature_set = \"ALL\"\r\n}\r\n\r\ndata \"aws_organizations_organization\" \"my_organization\" {\r\n  count = var.create_organization ? 0 : 1\r\n}\r\n\r\nresource \"null_resource\" \"enabled_policies\" {\r\n  count = var.create_organization ? 0 : 1\r\n\r\n  triggers = {\r\n    my_organization_root_id = local.my_organization_root\r\n    enabled_policy_types    = join(\" \", flatten([\"AISERVICES_OPT_OUT_POLICY\", var.additional_enable_policy_types]))\r\n    python                  = var.python_interpreter\r\n  }\r\n\r\n  provisioner \"local-exec\" {\r\n    command = \"${self.triggers.python} ${path.module}/local-exec/aws_organizations_organization_enabled_policies.py enable ${self.triggers.my_organization_root_id} ${self.triggers.enabled_policy_types}\"\r\n  }\r\n}\r\nlocals {\r\n  optOutPolicy = {\r\n    services = {\r\n      default = {\r\n        opt_out_policy = {\r\n          \"@@assign\" = \"optOut\"\r\n        }\r\n      }\r\n    }\r\n  }\r\n  my_organization_root = var.create_organization ? \"UNUSED\" : data.aws_organizations_organization.my_organization[0].roots == null ? \"NO-ORGANIZATION-FOUND\" : data.aws_organizations_organization.my_organization[0].roots[0].id\r\n}\r\n\r\nresource \"aws_organizations_policy\" \"org-policy\" {\r\n  content     = jsonencode(local.optOutPolicy)\r\n  name        = \"OptOutOfAllAIServicesPolicy\"\r\n  type        = \"AISERVICES_OPT_OUT_POLICY\"\r\n  description = \"Opt out of all Amazon AI services at an organization level\"\r\n}\r\n\r\nresource \"aws_organizations_policy_attachment\" \"org-policy-attachment\" {\r\n  count     = var.create_organization ? 1 : 0\r\n  policy_id = aws_organizations_policy.org-policy.id\r\n  target_id = aws_organizations_organization.organization[0].roots[0].id\r\n}\r\n\r\nresource \"aws_organizations_policy_attachment\" \"my-org-policy-attachment\" {\r\n  count     = var.create_organization ? 0 : 1\r\n  policy_id = aws_organizations_policy.org-policy.id\r\n  target_id = local.my_organization_root\r\n}"}]}
{"messages": [{"role": "user", "content": "Create a resource group named \"rg-provisioning-demo\" in the West Europe location. Create a storage account named \"stsftprovdev\" with standard tier and LRS replication within the resource group. Create a storage container named \"container\" in the created storage account. Enable SFTP for the storage account by executing an external script and create a local user. Ensure the SFTP and local user are disabled when the resource is destroyed using another script."}, {"role": "assistant", "content": "\n#File: main.tf\nlocals {\n    resource_group_name = \"rg-provisioning-demo\"\n    storage_account_name = \"stsftprovdev\"\n}\n\n## Create Resource Group\nresource \"azurerm_resource_group\" \"rg_demo\" {\n    name      = local.resource_group_name\n    location  = \"West Europe\"\n}\n\n## Create Storage Account\nresource \"azurerm_storage_account\" \"sftp_storage_acct\" {\n    name                        = local.storage_account_name\n    location                    = azurerm_resource_group.rg_demo.location\n    resource_group_name         = azurerm_resource_group.rg_demo.name\n    account_tier                = \"Standard\"\n    account_replication_type    = \"LRS\"\n    min_tls_version             = \"TLS1_2\"\n    is_hns_enabled           = true\n}\n\n# Create container\nresource \"azurerm_storage_container\" \"azurerm_storage_container\" {\n  name                  = \"container\"\n  storage_account_name  = azurerm_storage_account.sftp_storage_acct.name\n}\n\n\n## Enable SFTP and create SFTP local users using an external script\nresource \"null_resource\" \"sftp_enable\" {\n    triggers = {\n        storage_account_name = local.storage_account_name\n        res_group_name = local.resource_group_name\n        sftp_user = \"ftpuser\"\n    }\n    provisioner \"local-exec\" {\n        command = \"./enable_sftp_create_localuser.sh ${self.triggers.storage_account_name} ${self.triggers.res_group_name} ${self.triggers.sftp_user}\"\n        interpreter = [\"bash\", \"-c\"]\n    }\n\n    provisioner \"local-exec\" {\n        when = destroy\n        command = \"./disable_sftp_and_localuser.sh ${self.triggers.storage_account_name} ${self.triggers.res_group_name} ${self.triggers.sftp_user}\" \n        interpreter = [\"bash\", \"-c\"]\n    }\n\n    depends_on = [\n        azurerm_storage_container.azurerm_storage_container\n    ]\n}\n#File: provider.tf\nterraform {\n  backend \"local\" {\n  }\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \">3.0.0\"\n    }\n  }\n}\n\nprovider \"azurerm\" {\n  features {}\n}\n\n"}]}
{"messages": [{"role": "user", "content": "Create a Terraform configuration for a GCP environment. Define variables for the company name, application name, domain name, and environment. Create a VPC and a public subnet with specified CIDR ranges. Launch a Google Compute Engine instance with a specified Fedora image and configure it to allow HTTP, HTTPS, SSH, and RDP traffic. Output the instance name and its external and internal IP addresses."}, {"role": "assistant", "content": "\n#File: app-variables.tf\n#############################\n## Application - Variables ##\n#############################\n\n# company name \nvariable \"company\" {\n  type        = string\n  description = \"This variable defines the company name used to build resources\"\n}\n\n# application name \nvariable \"app_name\" {\n  type        = string\n  description = \"This variable defines the application name used to build resources\"\n}\n\n# domain name \nvariable \"app_domain\" {\n  type        = string\n  description = \"This variable defines the domain name used to build resources\"\n}\n\n# environment\nvariable \"environment\" {\n  type        = string\n  description = \"This variable defines the environment to be built\"\n}\n\n\n#File: fedora-versions.tf\n#####################\n## Fedora Versions ##\n#####################\n\nvariable \"fedora_35_sku\" {\n  type        = string\n  description = \"SKU for Fedora 35\"\n  default     = \"fedora-cloud/fedora-cloud-35\"\n}\n\nvariable \"fedora_34_sku\" {\n  type        = string\n  description = \"SKU for Fedora 34\"\n  default     = \"fedora-cloud/fedora-cloud-34\"\n}\n\nvariable \"fedora_33_sku\" {\n  type        = string\n  description = \"SKU for Fedora 33\"\n  default     = \"fedora-cloud/fedora-cloud-33\"\n}\n\nvariable \"fedora_coreos_sku\" {\n  type        = string\n  description = \"SKU for Fedora CoreOS\"\n  default     = \"fedora-coreos-cloud/fedora-coreos-stable\"\n}\n\n#File: linux-vm-main.tf\n#########################\n## GCP Linux VM - Main ##\n#########################\n\n# Terraform plugin for creating random ids\nresource \"random_id\" \"instance_id\" {\n  byte_length = 4\n}\n\n# Create VM\nresource \"google_compute_instance\" \"vm_instance_public\" {\n  name         = \"${lower(var.company)}-${lower(var.app_name)}-${var.environment}-vm${random_id.instance_id.hex}\"\n  machine_type = var.linux_instance_type\n  zone         = var.gcp_zone\n  hostname     = \"${var.app_name}-vm${random_id.instance_id.hex}.${var.app_domain}\"\n  tags         = [\"ssh\",\"http\"]\n\n  boot_disk {\n    initialize_params {\n      image = var.fedora_35_sku\n    }\n  }\n\n  network_interface {\n    network       = google_compute_network.vpc.name\n    subnetwork    = google_compute_subnetwork.network_subnet.name\n    access_config { }\n  }\n} \n\n#File: linux-vm-output.tf\n###########################\n## GCP Linux VM - Output ##\n###########################\n\noutput \"vm-name\" {\n  value = google_compute_instance.vm_instance_public.name\n}\n\noutput \"vm-external-ip\" {\n  value = google_compute_instance.vm_instance_public.network_interface.0.access_config.0.nat_ip\n}\n\noutput \"vm-internal-ip\" {\n  value = google_compute_instance.vm_instance_public.network_interface.0.network_ip\n}\n\n#File: linux-vm-variables.tf\n##############################\n## GCP Linux VM - Variables ##\n##############################\n\nvariable \"linux_instance_type\" {\n  type        = string\n  description = \"VM instance type\"\n  default     = \"f1-micro\"\n}\n\n#File: network-firewall.tf\n###################################\n## Network Firewall Rules - Main ##\n###################################\n\n# Allow http\nresource \"google_compute_firewall\" \"allow-http\" {\n  name    = \"${var.app_name}-${var.environment}-fw-allow-http\"\n  network = google_compute_network.vpc.name\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"80\"]\n  }\n  \n  source_ranges = [\"0.0.0.0/0\"]\n  target_tags = [\"http\"] \n}\n\n# allow https\nresource \"google_compute_firewall\" \"allow-https\" {\n  name    = \"${var.app_name}-${var.environment}-fw-allow-https\"\n  network = google_compute_network.vpc.name\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"443\"]\n  }\n\n  source_ranges = [\"0.0.0.0/0\"]\n  target_tags = [\"https\"] \n}\n\n# allow ssh\nresource \"google_compute_firewall\" \"allow-ssh\" {\n  name    = \"${var.app_name}-${var.environment}-fw-allow-ssh\"\n  network = google_compute_network.vpc.name\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"22\"]\n  }\n\n  source_ranges = [\"0.0.0.0/0\"]\n  target_tags = [\"ssh\"]\n}\n\n# allow rdp\nresource \"google_compute_firewall\" \"allow-rdp\" {\n  name    = \"${var.app_name}-${var.environment}-fw-allow-rdp\"\n  network = google_compute_network.vpc.name\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"3389\"]\n  }\n\n  source_ranges = [\"0.0.0.0/0\"]\n  target_tags = [\"rdp\"]\n}\n\n#File: network-main.tf\n####################\n## Network - Main ##\n####################\n\n# create VPC\nresource \"google_compute_network\" \"vpc\" {\n  name                    = \"${lower(var.company)}-${lower(var.app_name)}-${var.environment}-vpc\"\n  auto_create_subnetworks = \"false\"\n  routing_mode            = \"GLOBAL\"\n}\n\n# create public subnet\nresource \"google_compute_subnetwork\" \"network_subnet\" {\n  name          = \"${lower(var.company)}-${lower(var.app_name)}-${var.environment}-subnet\"\n  ip_cidr_range = var.network-subnet-cidr\n  network       = google_compute_network.vpc.name\n  region        = var.gcp_region\n}\n\n#File: network-variables.tf\n#########################\n## Network - Variables ##\n#########################\n\nvariable \"network-subnet-cidr\" {\n  type        = string\n  description = \"The CIDR for the network subnet\"\n}\n#File: provider-main.tf\n#########################\n## GCP Provider - Main ##\n#########################\n\n# Define Terraform provider\nterraform {\n  required_version = \"~> 1.0\"\n\n  required_providers {\n    google = {\n      source = \"hashicorp/google\"\n      // version = \"4.11.0\" # pinning version\n    }\n  }\n}\n\nprovider \"google\" {\n  credentials = file(var.gcp_auth_file)\n  project     = var.gcp_project\n  region      = var.gcp_region\n  zone        = var.gcp_zone\n}\n\n#File: provider-variables.tf\n##############################\n## GCP Provider - Variables ##\n##############################\n\n# GCP authentication file\nvariable \"gcp_auth_file\" {\n  type        = string\n  description = \"GCP authentication file\"\n}\n\n# define GCP project name\nvariable \"gcp_project\" {\n  type        = string\n  description = \"GCP project name\"\n}\n\n# define GCP region\nvariable \"gcp_region\" {\n  type        = string\n  description = \"GCP region\"\n}\n\n# define GCP region\nvariable \"gcp_zone\" {\n  type        = string\n  description = \"GCP zone\"\n}\n"}]}
{"messages": [{"role": "user", "content": "Create a Terraform configuration for a Google Cloud subnetwork. Define variables for the subnet's name, project, description, IP CIDR range, network, and region. Set up a local backend to store the state file. Create both a basic subnetwork and a subnetwork with optional secondary ranges based on a variable condition. Output the subnetwork details such as name, gateway address, and self link."}, {"role": "assistant", "content": "\n#File: main.tf\n\n# *Main Providers and pre-requisites\ndata \"google_client_config\" \"default\" {}\n\nterraform {\n  \n  required_version = \">= 0.15.0\"\n\n  required_providers {\n    google = {\n      source  = \"hashicorp/google\"\n      version = \"~> 3.67\"\n    } # https://github.com/terraform-providers/terraform-provider-google-beta/releases\n  }\n\n  # # GCS Backend Exemple: State module_exemple\n  # backend \"gcs\" {\n  #   bucket = \"tf_states-modules\"\n  #   path   = \"modules/module-exemple.tfstate\"\n  # }\n\n  # Local Backend Exemple: State module_exemple\n  backend \"local\" {\n    path = \"./tfstate_local.tfstate\"\n  }\n\n}\n\n# Official Google Cloud Provider for Beta Resources & Features\nprovider \"google-beta\" {\n\n  project = var.gcp_project_id\n  region  = var.region\n\n}\n\n#File: outputs.tf\noutput \"name\" {\n  value       = local.name_output[local.subnetwork_type]\n  description = \"Subnetwork name.\"\n}\n\noutput \"gateway_address\" {\n  value       = local.gateway_address\n  description = \"The IP address of the gateway.\"\n}\n\noutput \"self_link\" {\n  value       = local.self_link\n  description = \"The URI of the created resource.\"\n}\n\noutput \"ip_cidr_range\" {\n  value       = local.ip_cidr_range\n  description = \"The IP address range that machines in this network are assigned to, represented as a CIDR block.\"\n}\n\noutput \"secondary_range\" {\n  value       = local.secondary_range\n  description = \"List of names for the secondary ranges created.\"\n}\n\n\n#File: resources.tf\nresource \"null_resource\" \"example\" {}\n\n#File: variables.tf\nvariable \"name\" {\n  type        = string\n  description = \"Name of subnet.\"\n}\n\nvariable \"project\" {\n  type        = string\n  description = \"Network project name\"\n}\n\nvariable \"description\" {\n  type        = string\n  description = \"Description usage of subnet\"\n  default     = \"\"\n}\n\nvariable \"ip_cidr_range\" {\n  type        = string\n  description = \"IP range in CIDR format of the subnet\"\n}\n\nvariable \"network\" {\n  type        = string\n  description = \"Name of self-link to the VPC this subnet will be linked to. Defaults to 'default' network\"\n}\n\nvariable \"region\" {\n  type        = string\n  description = \"Region in which subnet will be created. Defaults to the region in the terraform provider\"\n  default     = \"\"\n}\n\nvariable \"create_secondary_ranges\" {\n  default     = false\n  description = \"Enable secondary ip ranges to be used with 'secondary_ranges' variable\"\n}\n\nvariable \"secondary_ranges\" {\n  type        = list(any)\n  default     = []\n  description = \"Create up to 5 alternative CIDR range to represent this subnetwork\"\n}\n\n/******************************************\n  Define local variables for use in outputs\n *****************************************/\n\nlocals {\n\n  subnetwork_type = var.create_secondary_ranges ? \"secondary_range\" : \"normal\"\n\n  name_output = {\n    secondary_range = element(concat(google_compute_subnetwork.ranged.*.name, [\"\"]), 0)\n    normal          = element(concat(google_compute_subnetwork.basic.*.name, [\"\"]), 0)\n  }\n\n  gateway_address_output = {\n    secondary_range = element(\n      concat(google_compute_subnetwork.ranged.*.gateway_address, [\"\"]),\n      0,\n    )\n    normal = element(\n      concat(google_compute_subnetwork.basic.*.gateway_address, [\"\"]),\n      0,\n    )\n  }\n\n  self_link_output = {\n    secondary_range = element(\n      concat(google_compute_subnetwork.ranged.*.self_link, [\"\"]), 0,\n    )\n    normal = element(concat(google_compute_subnetwork.basic.*.self_link, [\"\"]), 0)\n  }\n\n  ip_cidr_range_output = {\n    secondary_range = element(\n      concat(google_compute_subnetwork.ranged.*.ip_cidr_range, [\"\"]), 0,\n    )\n    normal = element(\n      concat(google_compute_subnetwork.basic.*.ip_cidr_range, [\"\"]), 0,\n    )\n  }\n\n  name            = local.name_output[local.subnetwork_type]\n  description     = \"${var.name} subnetwork\"\n  gateway_address = local.gateway_address_output[local.subnetwork_type]\n  self_link       = local.self_link_output[local.subnetwork_type]\n  ip_cidr_range   = local.ip_cidr_range_output[local.subnetwork_type]\n  secondary_range = var.secondary_ranges\n}\n\n\n#File: subnets.tf\n/******************************************\n  Create subnetwork without secondary_range\n *****************************************/\n\nresource \"google_compute_subnetwork\" \"basic\" {\n  count = var.create_secondary_ranges ? 0 : 1\n\n  name                     = var.name\n  description              = var.description != \"\" ? var.description : local.description\n  region                   = var.region\n  ip_cidr_range            = var.ip_cidr_range\n  network                  = var.network\n  project                  = var.project\n  private_ip_google_access = true\n}\n\n/******************************************\n  Create subnetwork with secondary_range\n *****************************************/\n\nresource \"google_compute_subnetwork\" \"ranged\" {\n  count = var.create_secondary_ranges ? 1 : 0\n\n  name          = var.name\n  description   = var.description != \"\" ? var.description : local.description\n  region        = var.region\n  ip_cidr_range = var.ip_cidr_range\n  network       = var.network\n\n  dynamic \"secondary_ip_range\" {\n    for_each = var.secondary_ranges\n    content {\n      ip_cidr_range = lookup(secondary_ip_range.value, \"ip_cidr_range\", null)\n      range_name    = lookup(secondary_ip_range.value, \"range_name\", null)\n    }\n  }\n\n  project                  = var.project\n  private_ip_google_access = true\n}"}]}
{"messages": [{"role":"user","content":"Create an AWS VPC with public subnets and sets up an ECS cluster running a Minecraft server container on Fargate, exposing port 25565 to the internet. Define a security group allowing inbound Minecraft traffic, a task definition specifying container settings including environment variables and logging to CloudWatch, and an ECS service to manage the container instances. Additionally, configure IAM roles and policies for ECS task execution and CloudWatch log access, with a CloudWatch log group to store the server logs."},{"role":"assistant","content":"provider \"aws\" {\r\n  region = \"us-east-1\"\r\n}\r\n\r\nmodule \"vpc\" {\r\n  source = \"terraform-aws-modules/vpc/aws\"\r\n  name = \"minecraft_vpc\"\r\n  cidr = \"10.0.0.0/16\"\r\n  azs            = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\r\n  public_subnets = [\"10.0.101.0/24\", \"10.0.102.0/24\", \"10.0.103.0/24\"]\r\n}\r\n\r\nresource \"aws_ecs_cluster\" \"minecraft_server\" {\r\n  name = \"minecraft_server\"\r\n}\r\n\r\nresource \"aws_security_group\" \"minecraft_server\" {\r\n  name        = \"minecraft_server\"\r\n  description = \"minecraft_server\"\r\n  vpc_id      =  module.vpc.vpc_id\r\n \r\n  ingress {\r\n    description = \"minecraft_server\"\r\n    from_port   = 25565\r\n    to_port     = 25565\r\n    protocol    = \"tcp\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n \r\n  egress {\r\n    from_port        = 0\r\n    to_port          = 0\r\n    protocol         = \"-1\"\r\n    cidr_blocks      = [\"0.0.0.0/0\"]\r\n    ipv6_cidr_blocks = [\"::/0\"]\r\n  }\r\n}\r\n\r\nresource \"aws_ecs_task_definition\" \"minecraft_server\" {\r\n  cpu                      = \"4096\"\r\n  memory                   = \"8192\"\r\n  family                   = \"minecraft-server\"\r\n  network_mode             = \"awsvpc\"\r\n  requires_compatibilities = [\"FARGATE\"]\r\n  execution_role_arn = aws_iam_role.ecs_tasks_execution_role.arn\r\n  container_definitions = jsonencode([\r\n    {\r\n      name          = \"minecraft-server\"\r\n      image         = \"itzg/minecraft-server\"\r\n      essential     = true\r\n      tty           = true\r\n      stdin_open    = true\r\n      restart       = \"unless-stopped\"\r\n      portMappings  = [\r\n        {\r\n          containerPort = 25565\r\n          hostPort      = 25565\r\n          protocol      = \"tcp\"\r\n        }\r\n      ]\r\n      environment   = [\r\n        {\r\n          name  = \"EULA\"\r\n          value = \"TRUE\"\r\n        },\r\n        {\r\n          \"name\": \"VERSION\",\r\n          \"value\": \"1.21.3\"\r\n        }\r\n      ]\r\n      mountPoints   = [\r\n        {\r\n          containerPath = \"/data\"\r\n          sourceVolume  = \"minecraft-data\"\r\n        }\r\n      ]\r\n      logConfiguration = {\r\n        logDriver = \"awslogs\"\r\n        options = {\r\n          awslogs-group         = \"/ecs/minecraft-server\"\r\n          awslogs-region        = \"eu-north-1\"\r\n          awslogs-stream-prefix = \"ecs\"\r\n        }\r\n      }\r\n    }\r\n  ])\r\n  volume {\r\n    name = \"minecraft-data\"\r\n  }\r\n}\r\n\r\nresource \"aws_ecs_service\" \"minecraft_server\" {\r\n  name            = \"minecraft_server\"\r\n  cluster         = aws_ecs_cluster.minecraft_server.id\r\n  task_definition = aws_ecs_task_definition.minecraft_server.arn\r\n  desired_count   = 1\r\n  network_configuration {\r\n    subnets          = module.vpc.public_subnets\r\n    security_groups  = [aws_security_group.minecraft_server.id]\r\n    assign_public_ip = true\r\n  }\r\n  launch_type = \"FARGATE\"\r\n}\r\n\r\ndata \"aws_iam_policy_document\" \"ecs_tasks_execution_role\" {\r\n  statement {\r\n    actions = [\"sts:AssumeRole\"]\r\n\r\n    principals {\r\n      type        = \"Service\"\r\n      identifiers = [\"ecs-tasks.amazonaws.com\"]\r\n    }\r\n  }\r\n}\r\n\r\nresource \"aws_iam_role\" \"ecs_tasks_execution_role\" {\r\n  name               = \"ecs-task-execution-role\"\r\n  assume_role_policy = \"${data.aws_iam_policy_document.ecs_tasks_execution_role.json}\"\r\n}\r\n\r\nresource \"aws_iam_role_policy_attachment\" \"ecs_tasks_execution_role\" {\r\n  role       = \"${aws_iam_role.ecs_tasks_execution_role.name}\"\r\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\"\r\n}\r\n\r\nresource \"aws_iam_role_policy_attachment\" \"ecs_task_log_execution_policy\" {\r\n  role       = \"${aws_iam_role.ecs_tasks_execution_role.name}\"\r\n  policy_arn = \"arn:aws:iam::aws:policy/CloudWatchLogsFullAccess\"\r\n}\r\n\r\nresource \"aws_cloudwatch_log_group\" \"minecraft_log_group\" {\r\n  name              = \"/ecs/minecraft-server\"\r\n  retention_in_days = 14\r\n}\r\n"}]}
{"messages": [{"role": "user", "content": "Create a Google Cloud provider configuration for the project \"terraform-projects-337900\" in the \"us-central1\" region. Set up a VPC network named \"terraform-network\" without auto-created sub-networks. Create a public subnetwork named \"terraform-subnetwork\" with an IP CIDR range of \"10.120.0.0/24\". Launch a Google Compute Engine instance named \"terraform-vm\" with the \"f1-micro\" machine type and configure it to use an internal IP address of \"10.120.0.10\". Implement a firewall rule named \"terraform-firewall\" to allow SSH and RDP access from the specified source range."}, {"role": "assistant", "content": "\n#File: main.tf\nprovider \"google\" {\n  project = \"terraform-projects-337900\"\n  region  = \"us-central1\"\n  zone    = \"us-central1-c\"\n}\n\nresource \"google_compute_network\" \"vpc_network\" {\n  name                    = \"terraform-network\"\n  auto_create_subnetworks = false\n}\n\nresource \"google_compute_subnetwork\" \"public-subnetwork\" {\n  name          = \"terraform-subnetwork\"\n  ip_cidr_range = \"10.120.0.0/24\"\n  region        = \"us-central1\"\n  network       = google_compute_network.vpc_network.id\n}\n\nresource \"google_compute_address\" \"internal_address\" {\n  name         = \"terraform-internal-ip\"\n  region       = \"us-central1\"\n  address_type = \"INTERNAL\"\n  address      = \"10.120.0.10\"\n  subnetwork   = google_compute_subnetwork.public-subnetwork.id\n}\n\nresource \"google_compute_instance\" \"vm_instance\" {\n  name         = \"terraform-vm\"\n  machine_type = \"f1-micro\"\n  zone         = \"us-central1-a\"\n\n  tags = [\"terraform\", \"vm\"]\n\n  boot_disk {\n    initialize_params {\n      image = \"debian-cloud/debian-9\"\n    }\n  }\n\n  network_interface {\n    network    = google_compute_network.vpc_network.id\n    subnetwork = google_compute_subnetwork.public-subnetwork.id\n    network_ip = google_compute_address.internal_address.address\n\n    access_config {\n      // Ephemeral public IP\n    }\n\n  }\n\n}\n\nresource \"google_compute_firewall\" \"poc-allow-ssh\" {\n  name    = \"terraform-firewall\"\n  network = google_compute_network.vpc_network.name\n\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"22\", \"3389\"]\n  }\n\n  source_ranges = [\"35.235.240.0/20\"]\n}"}]}
{"messages": [{"role": "user", "content": "Create a Hetzner Cloud network with a specified IP range. Set up a subnet within that network for virtual machines. Create and configure multiple firewalls for SSH, internal communication, and external access based on the provided variables. Generate an SSH key pair and save the private key to a specified path. Launch the virtual machines with cloud-init configurations and attach the necessary firewalls to ensure proper security."}, {"role": "assistant", "content": "\n#File: main.tf\nterraform {\n  required_providers {\n    hcloud = {\n      source  = \"hetznercloud/hcloud\"\n      version = \"1.45.0\"\n    }\n    tls = {\n      source  = \"hashicorp/tls\"\n      version = \"4.0.5\"\n    }\n  }\n\n  required_version = \">= 1.7.5\"\n}\n\nprovider \"hcloud\" {\n  token = var.hcloud_token\n}\n\n############### Network ###############\n# Private Network\nresource \"hcloud_network\" \"pcpc\" {\n  name     = \"${var.name}-network\"\n  ip_range = \"10.0.0.0/16\"\n}\n\n# subnet\nresource \"hcloud_network_subnet\" \"vm\" {\n  network_id   = hcloud_network.pcpc.id\n  type         = \"cloud\"\n  network_zone = var.network-zone\n  ip_range     = \"10.0.2.0/24\"\n}\n\n####### Firewall #########\n# SSH\nresource \"hcloud_firewall\" \"ssh\" {\n  count = var.firewall-ssh ? 1 : 0\n\n  name = \"allow-ssh\"\n  rule {\n    direction = \"in\"\n    protocol  = \"tcp\"\n    port      = \"22\"\n    source_ips = [\n      \"0.0.0.0/0\",\n      \"::/0\"\n    ]\n  }\n}\n\n# Internal\nresource \"hcloud_firewall\" \"internal\" {\n  count = var.firewall-internal ? 1 : 0\n\n  name = \"allow-internal\"\n\n  dynamic \"rule\" {\n    for_each = [\"tcp\", \"udp\", \"icmp\"]\n\n    content {\n      direction  = \"in\"\n      protocol   = rule.value\n      source_ips = [hcloud_network_subnet.vm.ip_range]\n      port       = rule.value != \"icmp\" ? \"any\" : null\n    }\n  }\n}\n\n# External\nresource \"hcloud_firewall\" \"external\" {\n  count = length(var.firewall-external) == 0 ? 0 : 1\n\n  name = \"allow-external\"\n\n  dynamic \"rule\" {\n    for_each = var.firewall-external\n\n    content {\n      direction = \"in\"\n      port      = rule.value.port\n      protocol  = rule.value.protocol\n      source_ips = [\n        \"0.0.0.0/0\",\n        \"::/0\"\n      ]\n    }\n  }\n}\n\n################# SSH Keys #######################\n# ssh key\nresource \"tls_private_key\" \"ssh\" {\n  algorithm = \"RSA\"\n  rsa_bits  = \"4096\"\n}\n\n# save ssh private key\nresource \"local_file\" \"private_key\" {\n  content         = tls_private_key.ssh.private_key_pem\n  filename        = var.ssh-pk-save-path\n  file_permission = \"0600\"\n}\n\n# Save SSH key to Hetzner\nresource \"hcloud_ssh_key\" \"default\" {\n  name       = \"default\"\n  public_key = chomp(tls_private_key.ssh.public_key_openssh)\n}\n\n########## VM ####################\n# cloud-init\n# run \"cloud-init status --wait\" in the SSH to check when it is done\n# run \"tail -f /var/log/cloud-init-output.log\" to see what it is doing\ndata \"cloudinit_config\" \"conf\" {\n  gzip          = false\n  base64_encode = false\n\n  part {\n    content_type = \"text/cloud-config\"\n    content      = file(var.cloud-init-file)\n    filename     = \"conf.yaml\"\n  }\n}\n\n# VM\nresource \"hcloud_server\" \"vm\" {\n  count = var.machines-count\n\n  name        = \"${var.name}-${count.index}\"\n  server_type = var.machine-type\n  image       = var.os-image\n  location    = var.location\n\n  public_net {\n    ipv4_enabled = true\n    ipv6_enabled = false\n  }\n\n  network {\n    network_id = hcloud_network.pcpc.id\n  }\n  ssh_keys  = [hcloud_ssh_key.default.id]\n  user_data = data.cloudinit_config.conf.rendered\n\n  lifecycle {\n    ignore_changes = [network]\n  }\n\n  # **Note**: the depends_on is important when directly attaching the\n  # server to a network. Otherwise Terraform will attempt to create\n  # server and sub-network in parallel. This may result in the server\n  # creation failing randomly.\n  depends_on = [\n    hcloud_network_subnet.vm,\n  ]\n}\n\n# Firewall attach to servers\nresource \"hcloud_firewall_attachment\" \"fw_att_ssh\" {\n  count = var.firewall-ssh ? 1 : 0\n\n  firewall_id = hcloud_firewall.ssh[0].id\n  server_ids  = hcloud_server.vm[*].id\n}\n\nresource \"hcloud_firewall_attachment\" \"fw_att_internal\" {\n  count = var.firewall-internal ? 1 : 0\n\n  firewall_id = hcloud_firewall.internal[0].id\n  server_ids  = hcloud_server.vm[*].id\n}\n\nresource \"hcloud_firewall_attachment\" \"fw_att_external\" {\n  count = length(var.firewall-external) == 0 ? 0 : 1\n\n  firewall_id = hcloud_firewall.external[0].id\n  server_ids  = hcloud_server.vm[*].id\n}\n\n#File: output.tf\noutput \"ssh-user\" {\n  value = \"root\"\n}\n\noutput \"private-ips\" {\n  value = flatten(hcloud_server.vm[*].network[*].ip)\n}\n\noutput \"public-ips\" {\n  value = hcloud_server.vm[*].ipv4_address\n}\n\n#File: variables.tf\nvariable \"hcloud_token\" {\n  type      = string\n  sensitive = true\n}\n\nvariable \"location\" {\n  default = \"fsn1\"\n}\n\nvariable \"network-zone\" {\n  default = \"eu-central\"\n}\n\nvariable \"name\" {\n  default = \"pcpc\"\n}\n\nvariable \"machines-count\" {\n  type = number\n}\n\nvariable \"machine-type\" {\n  default = \"cx11\"\n}\n\nvariable \"os-image\" {\n  default = \"ubuntu-22.04\"\n}\n\nvariable \"firewall-ssh\" {\n  default = true\n}\n\nvariable \"firewall-internal\" {\n  default     = true\n  description = \"Allow the machines to communicate between them in the LAN\"\n}\n\nvariable \"firewall-external\" {\n  type = list(object({\n    port     = string\n    protocol = string\n  }))\n\n  default = []\n\n  description = \"Add additional ports to be opened on the WAN\"\n}\n\nvariable \"ssh-pk-save-path\" {\n  default = \"hetzner.pem\"\n}\n\nvariable \"cloud-init-file\" {\n  type = string\n}\n"}]}
{"messages": [{"role": "user", "content": "Create a Google Cloud Storage bucket using the provided variables for project ID, name, location, and labels. Implement a lifecycle rule that deletes objects older than a specified age. Set the bucket's location to the defined region. Output the bucket's name and self-link upon creation. Ensure that the required Google provider version is configured in your Terraform setup."}, {"role": "assistant", "content": "\n#File: main.tf\nprovider \"google\" {\n  project = var.project_id\n  region  = var.region\n}\n\nresource \"google_storage_bucket\" \"default\" {\n  name     = var.name\n  location = var.location\n\n  labels = var.labels\n\n  lifecycle_rule {\n    action {\n      type = \"Delete\"\n    }\n    condition {\n      age = var.lifecycle_age\n    }\n  }\n}\n\n#File: variables.tf\nvariable \"project_id\" {\n  description = \"The ID of the GCP project\"\n  type        = string\n}\n\nvariable \"region\" {\n  description = \"The region to deploy resources\"\n  type        = string\n  default     = \"us-central1\"\n}\n\nvariable \"name\" {\n  description = \"Name of the storage bucket\"\n  type        = string\n}\n\nvariable \"location\" {\n  description = \"Location of the bucket\"\n  type        = string\n}\n\nvariable \"labels\" {\n  description = \"Labels for the bucket\"\n  type        = map(string)\n}\n\nvariable \"lifecycle_age\" {\n  description = \"Lifecycle rule age\"\n  type        = number\n  default     = 30\n}\n\n#File: versions.tf\nterraform {\n  required_providers {\n    google = {\n      source = \"hashicorp/google\"\n      version = \"~> 4.0\"\n    }\n  }\n}\n#File: outputs.tf\noutput \"bucket_name\" {\n  description = \"The name of the storage bucket\"\n  value       = google_storage_bucket.default.name\n}\n\noutput \"bucket_self_link\" {\n  description = \"The self-link of the storage bucket\"\n  value       = google_storage_bucket.default.self_link\n}\n"}]}
{"messages": [{"role": "user", "content": "Create a Terraform configuration with version constraints that requires Azurerm provider version 2.46.0 or higher. Set up an Azure provider block using specific subscription, client ID, client secret, and tenant ID variables. Define variables for resource group names, resource name prefixes, deployment environments, geographic regions, and tags. Ensure input variables have appropriate descriptions and defaults where needed. Organize your code into main.tf, outputs.tf, providers.tf, and variables.tf files."}, {"role": "assistant", "content": "\n#File: main.tf\n###\n# resource composition\n###\n\n\n#File: outputs.tf\n###\n# resource outputs\n###\n#File: providers.tf\n###\n# environment providers\n###\n\nterraform {\n  required_version = \">= 0.14\"\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \">=2.46.0\"\n    }\n  }\n}\n\nprovider \"azurerm\" {\n  features {}\n  subscription_id = \"0fd6b65c-0ee2-4bb4-957d-1b92fff9d1b4\"\n  client_id       = var.client_id\n  client_secret   = var.client_secret\n  tenant_id       = var.tenant_id\n}\n#File: variables.tf\n###\n# resource variables\n###\n\n#common\n\nvariable \"resource_group\" {\n  description = \"The name of the target resource group\"\n  type        = string\n}\n\nvariable \"name_prefix\" {\n  description = \"A short pre-defined text to identify the resource type\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"environment\" {\n  description = \"Development environment for resource; prod, non-prod, shared-services\"\n  type        = string\n}\n\nvariable \"region\" {\n  description = \"Geographic Region resource will be deployed into\"\n  type        = string\n}\n\n#tags\n\nvariable \"tags\" {\n  description = \"A map of tags to add to all resources\"\n  type        = map(any)\n  default     = {}\n}\n\n"}]}
{"messages": [{"role":"user","content":"Provide an AWS VPC with a public subnet, an internet gateway, and associated routing to enable public internet access. It creates multiple EC2 instances for different Kafka components (such as brokers, zookeeper, schema registry, connect, and control center), each tagged with a prefix and indexed count. The security group allows inbound traffic on relevant Kafka ports and SSH, ensuring connectivity for Kafka services and management."},{"role":"assistant","content":"provider \"aws\" {\r\n    region = var.aws_region\r\n}\r\n\r\nresource \"aws_instance\" \"rest\" {\r\n    count = var.instance_count[\"rest\"]\r\n    ami = var.aws_ami\r\n    instance_type = var.aws_instance_type\r\n    key_name = var.key_name\r\n    vpc_security_group_ids = [\"${aws_security_group.kafka_sg.id}\"] \r\n    subnet_id = aws_subnet.default.id\r\n    associate_public_ip_address = true\r\n    source_dest_check = false\r\n    tags = {\r\n        Name = \"kafka-rest-${var.instance_prefix}-${format(\"%02d\", count.index+1)}\"\r\n    }\r\n}\r\n\r\nresource \"aws_instance\" \"connect\" {\r\n    count = var.instance_count[\"connect\"]\r\n    ami = var.aws_ami\r\n    instance_type = var.aws_instance_type\r\n    key_name = var.key_name\r\n    vpc_security_group_ids = [\"${aws_security_group.kafka_sg.id}\"] \r\n    subnet_id = aws_subnet.default.id\r\n    associate_public_ip_address = true\r\n    source_dest_check = false\r\n    tags = {\r\n        Name = \"kafka-connect-${var.instance_prefix}-${format(\"%02d\", count.index+1)}\"\r\n    }\r\n}\r\n\r\nresource \"aws_instance\" \"ksql\" {\r\n    count = var.instance_count[\"ksql\"]\r\n    ami = var.aws_ami\r\n    instance_type = var.aws_instance_type \r\n    key_name = var.key_name\r\n    vpc_security_group_ids = [\"${aws_security_group.kafka_sg.id}\"] \r\n    subnet_id = aws_subnet.default.id\r\n    associate_public_ip_address = true\r\n    source_dest_check = false\r\n    tags = {\r\n        Name = \"kafka-ksql-${var.instance_prefix}-${format(\"%02d\", count.index+1)}\"\r\n    }\r\n}\r\nresource \"aws_instance\" \"control_center\" {\r\n    count = var.instance_count[\"control_center\"]\r\n    ami = var.aws_ami\r\n    instance_type = var.aws_instance_type\r\n    key_name = var.key_name\r\n    vpc_security_group_ids = [\"${aws_security_group.kafka_sg.id}\"] \r\n    subnet_id = aws_subnet.default.id\r\n    associate_public_ip_address = true\r\n    source_dest_check = false\r\n    tags = {\r\n        Name = \"kafka-control-center-${var.instance_prefix}-${format(\"%02d\", count.index+1)}\"\r\n    }\r\n}\r\n\r\nresource \"aws_instance\" \"schema\" {\r\n    count = var.instance_count[\"schema\"]\r\n    ami = var.aws_ami\r\n    instance_type = var.aws_instance_type \r\n    key_name = var.key_name\r\n    vpc_security_group_ids = [\"${aws_security_group.kafka_sg.id}\"] \r\n    subnet_id = aws_subnet.default.id\r\n    associate_public_ip_address = true\r\n    source_dest_check = false\r\n    tags = {\r\n        Name = \"kafka-schema-${var.instance_prefix}-${format(\"%02d\", count.index+1)}\"\r\n    }\r\n}\r\n\r\nresource \"aws_instance\" \"broker\" {\r\n    count = var.instance_count[\"broker\"]\r\n    ami = var.aws_ami\r\n    instance_type = var.aws_instance_type\r\n    key_name = var.key_name\r\n    vpc_security_group_ids = [\"${aws_security_group.kafka_sg.id}\"] \r\n    subnet_id = aws_subnet.default.id\r\n    associate_public_ip_address = true\r\n    source_dest_check = false\r\n    tags = {\r\n        Name = \"kafka-broker-${var.instance_prefix}-${format(\"%02d\", count.index+1)}\"\r\n    }\r\n}\r\n\r\nresource \"aws_instance\" \"zookeeper\" {\r\n    count = var.instance_count[\"zookeeper\"]\r\n    ami = var.aws_ami\r\n    instance_type = var.aws_instance_type\r\n    key_name = var.key_name\r\n    vpc_security_group_ids = [\"${aws_security_group.kafka_sg.id}\"] \r\n    subnet_id = aws_subnet.default.id\r\n    associate_public_ip_address = true\r\n    source_dest_check = false\r\n    tags = {\r\n        Name = \"kafka-zookeeper-${var.instance_prefix}-${format(\"%02d\", count.index+1)}\"\r\n    }\r\n}\r\nvariable \"aws_region\" {\r\n  description = \"The AWS region to create things in.\"\r\n  default     = \"eu-west-1\"\r\n}\r\n\r\nvariable \"instance_count\" {\r\n  type = map(string)\r\n\r\n  default = {\r\n    \"rest\"            = 1\r\n    \"connect\"         = 1\r\n    \"ksql\"            = 1\r\n    \"schema\"          = 1\r\n    \"control_center\"  = 1\r\n    \"broker\"          = 1\r\n    \"zookeeper\"       = 1\r\n  }\r\n}\r\n\r\nvariable \"instance_prefix\" {\r\n  default     = \"staging\"\r\n}\r\n\r\nvariable \"aws_ami\" {\r\n  description = \"The AWS AMI.\"\r\n  default     = \"ami-040ba9174949f6de4\"\r\n}\r\n\r\nvariable \"aws_instance_type\" {\r\n  description = \"The AWS Instance Type.\"\r\n  default     = \"t2.small\"\r\n}\r\n\r\nvariable \"vpc_cidr\" {\r\n  description = \"CIDR for VPC\"\r\n  default     = \"10.0.0.0/16\"\r\n}\r\n\r\nvariable \"public_subnet_cidr\" {\r\n  description = \"CIDR for public subnet\"\r\n  default     = \"10.0.1.0/24\"\r\n}\r\n\r\nvariable \"key_name\" {\r\n  description = \"Key Pair\"\r\n  default     = \"terraform-ansible-pair\"\r\n}\r\n\r\nresource \"aws_internet_gateway\" \"default\" {\r\n    vpc_id = aws_vpc.default.id\r\n    tags = {\r\n        Name = \"kafka_gw\"\r\n    }\r\n}\r\n\r\nresource \"aws_route\" \"default\" {\r\n  route_table_id         = aws_vpc.default.main_route_table_id\r\n  destination_cidr_block = \"0.0.0.0/0\"\r\n  gateway_id             = aws_internet_gateway.default.id\r\n}\r\n\r\nresource \"aws_route_table\" \"default\" {\r\n    vpc_id = aws_vpc.default.id\r\n\r\n    route {\r\n       cidr_block = \"0.0.0.0/0\"\r\n        gateway_id = aws_internet_gateway.default.id\r\n    }\r\n\r\n    tags = {\r\n        Name = \"Kafka Public Subnet\"\r\n    }\r\n}\r\n\r\nresource \"aws_route_table_association\" \"default\" {\r\n    subnet_id = aws_subnet.default.id\r\n    route_table_id = aws_route_table.default.id\r\n}\r\n\r\n\r\nresource \"aws_subnet\" \"default\" {\r\n    vpc_id = aws_vpc.default.id\r\n\r\n    cidr_block = var.public_subnet_cidr\r\n\r\n    map_public_ip_on_launch = true\r\n\r\n    tags = {\r\n        Name = \"Kafka Public Subnet\"\r\n    }\r\n}\r\n\r\nresource \"aws_security_group\" \"kafka_sg\" {\r\n    name = \"vpc_kafka_sg\"\r\n    description = \"Accept incoming connections.\"\r\n\r\n    ingress {\r\n        from_port = 22\r\n        to_port = 22\r\n        protocol = \"tcp\"\r\n        cidr_blocks = [\"0.0.0.0/0\"]\r\n        description = \"SSH\"\r\n    }\r\n    ingress {\r\n        from_port = 8083\r\n        to_port = 8083\r\n        protocol = \"tcp\"\r\n        cidr_blocks = [\"0.0.0.0/0\"]\r\n        description = \"Kafka Connect REST API\" \r\n    }\r\n    ingress {\r\n        from_port = 8088\r\n        to_port = 8088\r\n        protocol = \"tcp\"\r\n        cidr_blocks = [\"0.0.0.0/0\"]\r\n        description = \"KSQL Server REST API\" \r\n    }\r\n    ingress {\r\n        from_port = 8082\r\n        to_port = 8082\r\n        protocol = \"tcp\"\r\n        cidr_blocks = [\"0.0.0.0/0\"]\r\n        description = \"REST Proxy\" \r\n    }\r\n    ingress {\r\n        from_port = 8081\r\n        to_port = 8081\r\n        protocol = \"tcp\"\r\n        cidr_blocks = [\"0.0.0.0/0\"]\r\n        description = \"Schema Registry REST API\" \r\n    }\r\n    ingress {\r\n        from_port = 1099\r\n        to_port = 1099\r\n        protocol = \"tcp\"\r\n        cidr_blocks = [\"0.0.0.0/0\"]\r\n        description = \"JMX\" \r\n    }\r\n    ingress {\r\n        from_port = 2181\r\n        to_port = 2181\r\n        protocol = \"tcp\"\r\n        cidr_blocks = [\"0.0.0.0/0\"]\r\n        description = \"ZooKeeper\" \r\n    }\r\n    ingress {\r\n        from_port = 2888\r\n        to_port = 2888\r\n        protocol = \"tcp\"\r\n        cidr_blocks = [\"0.0.0.0/0\"]\r\n        description = \"ZooKeeper\" \r\n    }\r\n    ingress {\r\n        from_port = 3888\r\n        to_port = 3888\r\n        protocol = \"tcp\"\r\n        cidr_blocks = [\"0.0.0.0/0\"]\r\n        description = \"ZooKeeper\" \r\n    }\r\n    ingress {\r\n        from_port = 9092\r\n        to_port = 9092\r\n        protocol = \"tcp\"\r\n        cidr_blocks = [\"0.0.0.0/0\"]\r\n        description = \"Kafka Brokers\"\r\n    }\r\n    ingress {\r\n        from_port = 9021\r\n        to_port = 9021\r\n        protocol = \"tcp\"\r\n        cidr_blocks = [\"0.0.0.0/0\"]\r\n        description = \"Control Center\"\r\n    }\r\n    ingress {\r\n        from_port = -1\r\n        to_port = -1\r\n        protocol = \"icmp\"\r\n        cidr_blocks = [\"0.0.0.0/0\"] \r\n    }\r\n    egress {\r\n        from_port   = 0\r\n        to_port     = 0\r\n        protocol    = \"-1\"\r\n        cidr_blocks = [\"0.0.0.0/0\"]\r\n    }\r\n\r\n    vpc_id = aws_vpc.default.id\r\n\r\n    tags = {\r\n        Name = \"kafka_cluster_sg\"\r\n    }\r\n}\r\n\r\n\r\nresource \"aws_vpc\" \"default\" {\r\n    cidr_block = var.vpc_cidr\r\n    enable_dns_hostnames = true\r\n    tags = {\r\n        Name = \"Kafka VPC\"\r\n    }\r\n}\r\n"}]}
{"messages": [{"role":"user","content":"Set up a complete OpenVPN server on AWS, including VPC, subnet, routing, security groups, and an EC2 instance running Amazon Linux 2. Provide the instance with SSH access, installs OpenVPN automatically using a script, adds VPN users, and downloads their configuration files locally. Security is enforced by restricting SSH access to the local machines IP, and all resources are tagged and modularized using variables."},{"role":"assistant","content":"provider \"aws\" {\r\n  region                  = var.aws_region\r\n  shared_credentials_files = var.shared_credentials_file\r\n  profile                 = var.profile\r\n}\r\n\r\nvariable \"aws_region\" {\r\n  description = \"The AWS region to use\"\r\n  default     = \"eu-west-2\"\r\n}\r\n\r\nvariable \"shared_credentials_file\" {\r\n  description = \"The location of the AWS shared credentials file (e.g. ~dominic/.aws/credentials)\"\r\n}\r\n\r\nvariable \"profile\" {\r\n  description = \"The profile to use\"\r\n}\r\n\r\nvariable \"tag_name\" {\r\n  description = \"The name to tag AWS resources with\"\r\n  default     = \"OpenVPN\"\r\n}\r\n\r\nvariable \"cidr_block\" {\r\n  description = \"The CIDR block range to use for the OpenVPN VPC\"\r\n  default     = \"10.0.0.0/16\"\r\n}\r\n\r\nvariable \"instance_type\" {\r\n  description = \"The instance type to use\"\r\n  default     = \"t2.micro\"\r\n}\r\n\r\nvariable \"instance_root_block_device_volume_size\" {\r\n  description = \"The size of the root block device volume of the EC2 instance in GiB\"\r\n  default     = 8\r\n}\r\n\r\nvariable \"ec2_username\" {\r\n  description = \"The user to connect to the EC2 as\"\r\n  default     = \"ec2-user\"\r\n}\r\n\r\nvariable \"openvpn_install_script_location\" {\r\n  description = \"The location of an OpenVPN installation script compatible with https://raw.githubusercontent.com/angristan/openvpn-install/master/openvpn-install.sh\"\r\n  default     = \"https://raw.githubusercontent.com/dumrauf/openvpn-install/master/openvpn-install.sh\"\r\n}\r\n\r\nvariable \"ssh_public_key_file\" {\r\n  # Generate via 'ssh-keygen -f openvpn -t rsa'\r\n  description = \"The public SSH key to store in the EC2 instance\"\r\n  default     = \"settings/openvpn.pub\"\r\n}\r\n\r\nvariable \"ssh_private_key_file\" {\r\n  # Generate via 'ssh-keygen -f openvpn -t rsa'\r\n  description = \"The private SSH key used to connect to the EC2 instance\"\r\n  default     = \"settings/openvpn\"\r\n}\r\n\r\nvariable \"ovpn_users\" {\r\n  type        = list(string)\r\n  description = \"The list of users to automatically provision with OpenVPN access\"\r\n}\r\n\r\nvariable \"ovpn_config_directory\" {\r\n  description = \"The name of the directory to eventually download the OVPN configuration files to\"\r\n  default     = \"generated/ovpn-config\"\r\n}\r\n\r\ndata \"aws_ami\" \"amazon_linux_2\" {\r\n  most_recent = true\r\n\r\n  filter {\r\n    name   = \"name\"\r\n    values = [\"amzn2-ami-hvm*\"]\r\n  }\r\n\r\n  filter {\r\n    name   = \"architecture\"\r\n    values = [\"x86_64\"]\r\n  }\r\n\r\n  filter {\r\n    name   = \"block-device-mapping.volume-type\"\r\n    values = [\"gp2\"]\r\n  }\r\n\r\n  filter {\r\n    name   = \"virtualization-type\"\r\n    values = [\"hvm\"]\r\n  }\r\n\r\n  owners = [\"amazon\"]\r\n}\r\n\r\nresource \"aws_key_pair\" \"openvpn\" {\r\n  key_name   = var.ssh_private_key_file\r\n  public_key = file(\"${path.module}/${var.ssh_public_key_file}\")\r\n}\r\n\r\nresource \"aws_instance\" \"openvpn\" {\r\n  ami                         = data.aws_ami.amazon_linux_2.id\r\n  associate_public_ip_address = true\r\n  instance_type               = var.instance_type\r\n  key_name                    = aws_key_pair.openvpn.key_name\r\n  subnet_id                   = aws_subnet.openvpn.id\r\n\r\n  vpc_security_group_ids = [\r\n    aws_security_group.openvpn.id,\r\n    aws_security_group.ssh_from_local.id,\r\n  ]\r\n\r\n  root_block_device {\r\n    volume_type           = \"gp2\"\r\n    volume_size           = var.instance_root_block_device_volume_size\r\n    delete_on_termination = true\r\n  }\r\n\r\n  tags = {\r\n    Name        = var.tag_name\r\n    Provisioner = \"Terraform\"\r\n  }\r\n}\r\n\r\nresource \"aws_eip\" \"openvpn_eip\" {\r\n  instance = aws_instance.openvpn.id\r\n  vpc      = true\r\n}\r\n\r\nresource \"null_resource\" \"openvpn_bootstrap\" {\r\n  connection {\r\n    type        = \"ssh\"\r\n    host        = aws_eip.openvpn_eip.public_ip\r\n    user        = var.ec2_username\r\n    port        = \"22\"\r\n    private_key = file(\"${path.module}/${var.ssh_private_key_file}\")\r\n    agent       = false\r\n  }\r\n\r\n  provisioner \"remote-exec\" {\r\n    inline = [\r\n      \"sudo yum update -y\",\r\n      \"curl -O ${var.openvpn_install_script_location}\",\r\n      \"chmod +x openvpn-install.sh\",\r\n      <<EOT\r\n      sudo AUTO_INSTALL=y \\\r\n           APPROVE_IP=${aws_eip.openvpn_eip.public_ip} \\\r\n           ENDPOINT=${aws_eip.openvpn_eip.public_dns} \\\r\n           ./openvpn-install.sh\r\n      \r\nEOT\r\n      ,\r\n    ]\r\n  }\r\n}\r\n\r\nresource \"null_resource\" \"openvpn_update_users_script\" {\r\n  depends_on = [null_resource.openvpn_bootstrap]\r\n\r\n  triggers = {\r\n    ovpn_users = join(\" \", var.ovpn_users)\r\n  }\r\n\r\n  connection {\r\n    type        = \"ssh\"\r\n    host        = aws_eip.openvpn_eip.public_ip\r\n    user        = var.ec2_username\r\n    port        = \"22\"\r\n    private_key = file(\"${path.module}/${var.ssh_private_key_file}\")\r\n    agent       = false\r\n  }\r\n\r\n  provisioner \"file\" {\r\n    source      = \"${path.module}/scripts/update_users.sh\"\r\n    destination = \"/home/${var.ec2_username}/update_users.sh\"\r\n  }\r\n\r\n  provisioner \"remote-exec\" {\r\n    inline = [\r\n      \"chmod +x ~${var.ec2_username}/update_users.sh\",\r\n      \"sudo ~${var.ec2_username}/update_users.sh ${join(\" \", var.ovpn_users)}\",\r\n    ]\r\n  }\r\n}\r\n\r\nresource \"null_resource\" \"openvpn_download_configurations\" {\r\n  depends_on = [null_resource.openvpn_update_users_script]\r\n\r\n  triggers = {\r\n    ovpn_users = join(\" \", var.ovpn_users)\r\n  }\r\n\r\n  provisioner \"local-exec\" {\r\n    command = <<EOT\r\n    mkdir -p ${var.ovpn_config_directory};\r\n    scp -o StrictHostKeyChecking=no \\\r\n        -o UserKnownHostsFile=/dev/null \\\r\n        -i ${var.ssh_private_key_file} ${var.ec2_username}@${aws_eip.openvpn_eip.public_ip}:/home/${var.ec2_username}/*.ovpn ${var.ovpn_config_directory}/\r\n    \r\nEOT\r\n\r\n  }\r\n}\r\n\r\nresource \"aws_vpc\" \"openvpn\" {\r\n  cidr_block           = var.cidr_block\r\n  enable_dns_hostnames = true\r\n  enable_dns_support   = true\r\n\r\n  tags = {\r\n    Name        = var.tag_name\r\n    Provisioner = \"Terraform\"\r\n  }\r\n}\r\n\r\nresource \"aws_subnet\" \"openvpn\" {\r\n  vpc_id     = aws_vpc.openvpn.id\r\n  cidr_block = cidrsubnet(var.cidr_block, 8, 0)\r\n\r\n  tags = {\r\n    Name        = var.tag_name\r\n    Provisioner = \"Terraform\"\r\n  }\r\n}\r\n\r\nresource \"aws_internet_gateway\" \"openvpn\" {\r\n  vpc_id = aws_vpc.openvpn.id\r\n\r\n  tags = {\r\n    Name        = var.tag_name\r\n    Provisioner = \"Terraform\"\r\n  }\r\n}\r\n\r\nresource \"aws_route_table\" \"openvpn\" {\r\n  vpc_id = aws_vpc.openvpn.id\r\n\r\n  route {\r\n    cidr_block = \"0.0.0.0/0\"\r\n    gateway_id = aws_internet_gateway.openvpn.id\r\n  }\r\n}\r\n\r\nresource \"aws_route_table_association\" \"openvpn\" {\r\n  subnet_id      = aws_subnet.openvpn.id\r\n  route_table_id = aws_route_table.openvpn.id\r\n}\r\n\r\nresource \"aws_security_group\" \"openvpn\" {\r\n  name        = \"openvpn\"\r\n  description = \"Allow inbound UDP access to OpenVPN and unrestricted egress\"\r\n\r\n  vpc_id = aws_vpc.openvpn.id\r\n\r\n  tags = {\r\n    Name        = var.tag_name\r\n    Provisioner = \"Terraform\"\r\n  }\r\n\r\n  ingress {\r\n    from_port   = 1194\r\n    to_port     = 1194\r\n    protocol    = \"udp\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n\r\n  egress {\r\n    from_port   = 0\r\n    to_port     = 0\r\n    protocol    = -1\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n}\r\n\r\nresource \"aws_security_group\" \"ssh_from_local\" {\r\n  name        = \"ssh-from-local\"\r\n  description = \"Allow SSH access only from local machine\"\r\n\r\n  vpc_id = aws_vpc.openvpn.id\r\n\r\n  tags = {\r\n    Name        = var.tag_name\r\n    Provisioner = \"Terraform\"\r\n  }\r\n\r\n  ingress {\r\n    from_port   = 22\r\n    to_port     = 22\r\n    protocol    = \"tcp\"\r\n    cidr_blocks = [local.local_ip_address]\r\n  }\r\n}\r\n\r\ndata \"http\" \"local_ip_address\" {\r\n  url = \"http://ipv4.icanhazip.com\"\r\n}\r\n\r\nlocals {\r\n  local_ip_address = \"${chomp(data.http.local_ip_address.body)}/32\"\r\n}\r\n\r\n"}]}
{"messages": [{"role": "user", "content": "Create a VPC in AWS with the CIDR block 10.2.0.0/23, and assign it the tag \"aws-vpc-001\". Create a subnet within the VPC using the CIDR block 10.2.0.0/24 and tag it as \"AWSWorkloadSubnet\". Set up a VPN gateway for the VPC and tag it \"aws-gateway-001\". Create customer gateways for two Azure public IP addresses and configure VPN connections for each within the AWS environment. Establish corresponding Azure resources including a virtual network, subnets, public IPs, and local network gateways to facilitate the VPN connections."}, {"role": "assistant", "content": "\n#File: aws.tf\n#################################################################################\n#\n# AWS EU West 1\n# Address Space : 10.2.0.0/23\n# ASN : 64512\n#\n#################################################################################\n\n#################################################################################\n#\n# AWS EU West 1 VPC\n#\n#################################################################################\nresource \"aws_vpc\" \"vpc\" {\n  cidr_block = \"10.2.0.0/23\"\n\n  tags = {\n    Name = \"aws-vpc-001\"\n  }\n}\n\nresource \"aws_subnet\" \"subnet\" {\n  vpc_id     = aws_vpc.vpc.id\n  cidr_block = \"10.2.0.0/24\"\n\n  tags = {\n    Name = \"AWSWorkloadSubnet\"\n  }\n}\n\n#################################################################################\n#\n# AWS EU West 1 Gateway\n#\n#################################################################################\nresource \"aws_vpn_gateway\" \"vpn_gateway\" {\n  vpc_id = aws_vpc.vpc.id\n\n  tags = {\n    Name = \"aws-gateway-001\"\n  }\n}\n\nresource \"aws_vpn_gateway_route_propagation\" \"gateway_route_propagation\" {\n  vpn_gateway_id = aws_vpn_gateway.vpn_gateway.id\n  route_table_id = aws_vpc.vpc.main_route_table_id\n}\n\n#################################################################################\n#\n# Azure Local Network Gateway\n#\n#################################################################################\nresource \"aws_customer_gateway\" \"customer_gateway_primary\" {\n  bgp_asn    = 65515\n  ip_address = azurerm_public_ip.public_ip_gateway_primary.ip_address\n  type       = \"ipsec.1\"\n\n  tags = {\n    Name = \"azure-gateway-001-primary\"\n  }\n}\n\nresource \"aws_customer_gateway\" \"customer_gateway_secondary\" {\n  bgp_asn    = 65515\n  ip_address = azurerm_public_ip.public_ip_gateway_secondary.ip_address\n  type       = \"ipsec.1\"\n\n  tags = {\n    Name = \"azure-gateway-001-secondary\"\n  }\n}\n\n#################################################################################\n#\n# AWS EU West 1 Connections\n#\n#################################################################################\nresource \"aws_vpn_connection\" \"vpn_connection_primary\" {\n  vpn_gateway_id      = aws_vpn_gateway.vpn_gateway.id\n  customer_gateway_id = aws_customer_gateway.customer_gateway_primary.id\n  type                = \"ipsec.1\"\n\n  tunnel1_inside_cidr = \"169.254.21.0/30\"\n  tunnel2_inside_cidr = \"169.254.21.4/30\"\n\n  tags = {\n    Name = \"azure-vpn-001-primary\"\n  }\n}\n\nresource \"aws_vpn_connection\" \"vpn_connection_secondary\" {\n  vpn_gateway_id      = aws_vpn_gateway.vpn_gateway.id\n  customer_gateway_id = aws_customer_gateway.customer_gateway_secondary.id\n  type                = \"ipsec.1\"\n\n  tunnel1_inside_cidr = \"169.254.22.0/30\"\n  tunnel2_inside_cidr = \"169.254.22.4/30\"\n\n  tags = {\n    Name = \"azure-vpn-001-secondary\"\n  }\n}\n#File: azure-varaibles.tf\n\n#File: azure.tf\n#################################################################################\n#\n# Azure North Europe\n# Address Space : 10.1.0.0/23\n# ASN : 65515\n#\n#################################################################################\nresource \"azurerm_resource_group\" \"resource_group\" {\n  name     = \"Azure-DC-NorthEurope\"\n  location = \"North Europe\"\n}\n\n#################################################################################\n#\n# Azure North Europe VNet\n#\n#################################################################################\nresource \"azurerm_virtual_network\" \"virtual_network\" {\n  name                = \"azure-vnet-001\"\n  location            = azurerm_resource_group.resource_group.location\n  resource_group_name = azurerm_resource_group.resource_group.name\n  address_space       = [\"10.1.0.0/23\"]\n}\n\nresource \"azurerm_subnet\" \"subet_gateway\" {\n  name                 = \"GatewaySubnet\"\n  resource_group_name  = azurerm_resource_group.resource_group.name\n  virtual_network_name = azurerm_virtual_network.virtual_network.name\n  address_prefixes     = [\"10.1.0.0/26\"]\n}\n\nresource \"azurerm_subnet\" \"subnet_workload\" {\n  name                 = \"AzureWorkloadSubnet\"\n  resource_group_name  = azurerm_resource_group.resource_group.name\n  virtual_network_name = azurerm_virtual_network.virtual_network.name\n  address_prefixes     = [\"10.1.1.0/24\"]\n}\n\n#################################################################################\n#\n# Azure North Europe Gateway\n#\n#################################################################################\nresource \"azurerm_public_ip\" \"public_ip_gateway_primary\" {\n  name                = \"azure-pip-001\"\n  location            = azurerm_resource_group.resource_group.location\n  resource_group_name = azurerm_resource_group.resource_group.name\n  sku                 = \"Standard\"\n  allocation_method   = \"Static\"\n}\n\nresource \"azurerm_public_ip\" \"public_ip_gateway_secondary\" {\n  name                = \"azure-pip-002\"\n  location            = azurerm_resource_group.resource_group.location\n  resource_group_name = azurerm_resource_group.resource_group.name\n  sku                 = \"Standard\"\n  allocation_method   = \"Static\"\n}\n\nresource \"azurerm_virtual_network_gateway\" \"virtual_network_gateway\" {\n  name                = \"azure-gateway-001\"\n  location            = azurerm_resource_group.resource_group.location\n  resource_group_name = azurerm_resource_group.resource_group.name\n\n  type     = \"Vpn\"\n  vpn_type = \"RouteBased\"\n\n  active_active = true\n  enable_bgp    = true\n  sku           = \"VpnGw1\"\n\n  bgp_settings {\n    asn = 65515\n\n    peering_addresses {\n      ip_configuration_name = \"gw-ip1\"\n      apipa_addresses       = [cidrhost(\"169.254.21.0/30\", 2), cidrhost(\"169.254.21.4/30\", 2)]\n    }\n\n    peering_addresses {\n      ip_configuration_name = \"gw-ip2\"\n      apipa_addresses       = [cidrhost(\"169.254.22.0/30\", 2), cidrhost(\"169.254.22.4/30\", 2)]\n    }\n  }\n\n  ip_configuration {\n    name                          = \"gw-ip1\"\n    public_ip_address_id          = azurerm_public_ip.public_ip_gateway_primary.id\n    private_ip_address_allocation = \"Dynamic\"\n    subnet_id                     = azurerm_subnet.subet_gateway.id\n  }\n\n  ip_configuration {\n    name                          = \"gw-ip2\"\n    public_ip_address_id          = azurerm_public_ip.public_ip_gateway_secondary.id\n    private_ip_address_allocation = \"Dynamic\"\n    subnet_id                     = azurerm_subnet.subet_gateway.id\n  }\n}\n\n#################################################################################\n#\n# AWS Local Network Gateway\n#\n#################################################################################\nresource \"azurerm_local_network_gateway\" \"local_network_gateway_primary_tunnel1\" {\n  depends_on = [\n    azurerm_virtual_network_gateway.virtual_network_gateway\n  ]\n  name                = \"aws-gateway-vpn-001-tunnel1\"\n  location            = azurerm_resource_group.resource_group.location\n  resource_group_name = azurerm_resource_group.resource_group.name\n  gateway_address     = aws_vpn_connection.vpn_connection_primary.tunnel1_address\n\n  bgp_settings {\n    asn                 = 64512\n    bgp_peering_address = cidrhost(\"169.254.21.0/30\", 1)\n  }\n}\n\nresource \"azurerm_local_network_gateway\" \"local_network_gateway_primary_tunnel2\" {\n  depends_on = [\n    azurerm_virtual_network_gateway.virtual_network_gateway\n  ]\n  name                = \"aws-gateway-vpn-001-tunnel2\"\n  location            = azurerm_resource_group.resource_group.location\n  resource_group_name = azurerm_resource_group.resource_group.name\n  gateway_address     = aws_vpn_connection.vpn_connection_primary.tunnel2_address\n\n  bgp_settings {\n    asn                 = 64512\n    bgp_peering_address = cidrhost(\"169.254.21.4/30\", 1)\n  }\n}\n\nresource \"azurerm_local_network_gateway\" \"local_network_gateway_secondary_tunnel1\" {\n  depends_on = [\n    azurerm_virtual_network_gateway.virtual_network_gateway\n  ]\n  name                = \"aws-gateway-vpn-002-tunnel1\"\n  location            = azurerm_resource_group.resource_group.location\n  resource_group_name = azurerm_resource_group.resource_group.name\n  gateway_address     = aws_vpn_connection.vpn_connection_secondary.tunnel1_address\n\n  bgp_settings {\n    asn                 = 64512\n    bgp_peering_address = cidrhost(\"169.254.22.0/30\", 1)\n  }\n}\n\nresource \"azurerm_local_network_gateway\" \"local_network_gateway_secondary_tunnel2\" {\n  depends_on = [\n    azurerm_virtual_network_gateway.virtual_network_gateway\n  ]\n  name                = \"aws-gateway-vpn-002-tunnel2\"\n  location            = azurerm_resource_group.resource_group.location\n  resource_group_name = azurerm_resource_group.resource_group.name\n  gateway_address     = aws_vpn_connection.vpn_connection_secondary.tunnel2_address\n\n  bgp_settings {\n    asn                 = 64512\n    bgp_peering_address = cidrhost(\"169.254.22.4/30\", 1)\n  }\n}\n\n#################################################################################\n#\n# Azure North Europe Connections\n#\n#################################################################################\nresource \"azurerm_virtual_network_gateway_connection\" \"aws-primary-tunnel1\" {\n  name                = \"aws-primary-tunnel1\"\n  location            = azurerm_resource_group.resource_group.location\n  resource_group_name = azurerm_resource_group.resource_group.name\n\n  type                       = \"IPsec\"\n  enable_bgp                 = true\n  virtual_network_gateway_id = azurerm_virtual_network_gateway.virtual_network_gateway.id\n  local_network_gateway_id   = azurerm_local_network_gateway.local_network_gateway_primary_tunnel1.id\n\n  shared_key = aws_vpn_connection.vpn_connection_primary.tunnel1_preshared_key\n}\n\nresource \"azurerm_virtual_network_gateway_connection\" \"aws-primary-tunnel2\" {\n  name                = \"aws-primary-tunnel2\"\n  location            = azurerm_resource_group.resource_group.location\n  resource_group_name = azurerm_resource_group.resource_group.name\n\n  type                       = \"IPsec\"\n  enable_bgp                 = true\n  virtual_network_gateway_id = azurerm_virtual_network_gateway.virtual_network_gateway.id\n  local_network_gateway_id   = azurerm_local_network_gateway.local_network_gateway_primary_tunnel2.id\n\n  shared_key = aws_vpn_connection.vpn_connection_primary.tunnel2_preshared_key\n}\n\nresource \"azurerm_virtual_network_gateway_connection\" \"aws-secondary-tunnel1\" {\n  name                = \"aws-secondary-tunnel1\"\n  location            = azurerm_resource_group.resource_group.location\n  resource_group_name = azurerm_resource_group.resource_group.name\n\n  type                       = \"IPsec\"\n  enable_bgp                 = true\n  virtual_network_gateway_id = azurerm_virtual_network_gateway.virtual_network_gateway.id\n  local_network_gateway_id   = azurerm_local_network_gateway.local_network_gateway_secondary_tunnel1.id\n\n  shared_key = aws_vpn_connection.vpn_connection_secondary.tunnel1_preshared_key\n}\n\nresource \"azurerm_virtual_network_gateway_connection\" \"aws-secondary-tunnel2\" {\n  name                = \"aws-secondary-tunnel2\"\n  location            = azurerm_resource_group.resource_group.location\n  resource_group_name = azurerm_resource_group.resource_group.name\n\n  type                       = \"IPsec\"\n  enable_bgp                 = true\n  virtual_network_gateway_id = azurerm_virtual_network_gateway.virtual_network_gateway.id\n  local_network_gateway_id   = azurerm_local_network_gateway.local_network_gateway_secondary_tunnel2.id\n\n  shared_key = aws_vpn_connection.vpn_connection_secondary.tunnel2_preshared_key\n}\n\n#File: provider.tf\nterraform {\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"=3.4.0\"\n    }\n\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"=4.9.0\"\n    }\n  }\n}\n\nprovider \"azurerm\" {\n  features {}\n}\n\nprovider \"aws\" {\n  region  = \"eu-west-1\"\n  profile = \"lab\"\n}"}]}
{"messages": [{"role":"user","content":"Set up an AWS Lambda function running a Java application, including the necessary IAM role and policy to allow Lambda execution and logging to CloudWatch. It configures an API Gateway REST API with proxy integration to invoke the Lambda function on any HTTP method and path, enabling serverless HTTP access. The deployment includes permissions allowing API Gateway to trigger the Lambda, and a CloudWatch log group to capture Lambda logs for monitoring."},{"role":"assistant","content":"provider \"aws\" {\r\n  access_key = \"${var.aws_access_key}\"\r\n  secret_key = \"${var.aws_secret_key}\"\r\n  region = \"${var.region}\"\r\n}\r\n\r\nvariable \"aws_access_key\" {\r\n  # set aws access key\r\n  default = \"\"\r\n}\r\n\r\nvariable \"aws_secret_key\" {\r\n  # set aws secret key\r\n  default = \"\"\r\n}\r\n\r\nvariable \"region\" {\r\n  # set aws region\r\n  default = \"\"\r\n}\r\n\r\nvariable \"lambda_payload_filename\" {\r\n  default = \"output/terraform-lambda-java-1.0-SNAPSHOT.jar\"\r\n}\r\n\r\nvariable \"lambda_function_handler\" {\r\n  default = \"handler.LambdaHandler\"\r\n}\r\n\r\nvariable \"lambda_runtime\" {\r\n  default = \"java8\"\r\n}\r\n\r\nvariable \"api_path\" {\r\n  default = \"{proxy+}\"\r\n}\r\n\r\nvariable \"api_env_stage_name\" {\r\n  default = \"terraform-lambda-java-stage\"\r\n}\r\n// Create a log group for the lambda\r\nresource \"aws_cloudwatch_log_group\" \"log_group\" {\r\n  name = \"/aws/lambda/java_lambda_function\"\r\n}\r\n\r\n# allow lambda to log to cloudwatch\r\ndata \"aws_iam_policy_document\" \"cloudwatch_log_group_access_document\" {\r\n  statement {\r\n    actions = [\r\n      \"logs:CreateLogGroup\",\r\n      \"logs:CreateLogStream\",\r\n      \"logs:PutLogEvents\"\r\n    ]\r\n\r\n    resources = [\r\n      \"arn:aws:logs:::*\",\r\n    ]\r\n  }\r\n}\r\nresource \"aws_lambda_function\" \"java_lambda_function\" {\r\n  runtime          = \"${var.lambda_runtime}\"\r\n  filename      = \"${var.lambda_payload_filename}\"\r\n  source_code_hash = \"${base64sha256(file(var.lambda_payload_filename))}\"\r\n  function_name = \"java_lambda_function\"\r\n\r\n  handler          = \"${var.lambda_function_handler}\"\r\n  timeout = 60\r\n  memory_size = 256\r\n  role             = \"${aws_iam_role.iam_role_for_lambda.arn}\"\r\n  depends_on   = [\"aws_cloudwatch_log_group.log_group\"]\r\n\r\n}\r\n\r\nresource \"aws_lambda_permission\" \"java_lambda_function\" {\r\n  statement_id  = \"AllowAPIGatewayInvoke\"\r\n  action        = \"lambda:InvokeFunction\"\r\n  function_name = \"${aws_lambda_function.java_lambda_function.function_name}\"\r\n  principal     = \"apigateway.amazonaws.com\"\r\n  # The /*/* portion grants access from any method on any resource\r\n  # within the API Gateway \"REST API\".\r\n  source_arn = \"${aws_api_gateway_deployment.java_lambda_deploy.execution_arn}/*/*\"\r\n}\r\n# lambda role\r\nresource \"aws_iam_role\" \"iam_role_for_lambda\" {\r\n  name = \"lambda-invoke-role\"\r\n  assume_role_policy = <<EOF\r\n{\r\n    \"Statement\": [\r\n      {\r\n        \"Action\": \"sts:AssumeRole\",\r\n        \"Principal\": {\r\n          \"Service\": \"lambda.amazonaws.com\"\r\n        },\r\n        \"Effect\": \"Allow\",\r\n        \"Sid\": \"\"\r\n      }\r\n    ]\r\n}\r\nEOF\r\n}\r\n\r\n# lambda policy\r\nresource \"aws_iam_policy\" \"iam_policy_for_lambda\" {\r\n  name = \"lambda-invoke-policy\"\r\n  path = \"/\"\r\n\r\n  policy = <<EOF\r\n{\r\n    \"Statement\": [\r\n      {\r\n        \"Sid\": \"LambdaPolicy\",\r\n        \"Effect\": \"Allow\",\r\n        \"Action\": [\r\n          \"cloudwatch:PutMetricData\",\r\n          \"ec2:DescribeNetworkInterfaces\",\r\n          \"ec2:CreateNetworkInterface\",\r\n          \"ec2:DeleteNetworkInterface\",\r\n          \"logs:CreateLogStream\",\r\n          \"logs:PutLogEvents\",\r\n          \"xray:PutTelemetryRecords\",\r\n          \"xray:PutTraceSegments\"\r\n        ],\r\n        \"Resource\": \"*\"\r\n      }\r\n    ]\r\n  }\r\nEOF\r\n}\r\n\r\n# Attach the policy to the role\r\nresource \"aws_iam_role_policy_attachment\" \"aws_iam_role_policy_attachment\" {\r\n  role       = \"${aws_iam_role.iam_role_for_lambda.name}\"\r\n  policy_arn = \"${aws_iam_policy.iam_policy_for_lambda.arn}\"\r\n}\r\nresource \"aws_api_gateway_rest_api\" \"java_lambda_api\" {\r\n  name        = \"java_lambda_api\"\r\n  description = \"Java Lambda on Terrraform\"\r\n}\r\n\r\nresource \"aws_api_gateway_resource\" \"java_lambda_api_gateway\" {\r\n  rest_api_id = \"${aws_api_gateway_rest_api.java_lambda_api.id}\"\r\n  parent_id   = \"${aws_api_gateway_rest_api.java_lambda_api.root_resource_id}\"\r\n  path_part   = \"${var.api_path}\"\r\n}\r\n\r\nresource \"aws_api_gateway_method\" \"java_lambda_method\" {\r\n  rest_api_id   = \"${aws_api_gateway_rest_api.java_lambda_api.id}\"\r\n  resource_id   = \"${aws_api_gateway_resource.java_lambda_api_gateway.id}\"\r\n  http_method   = \"ANY\"\r\n  authorization = \"NONE\"\r\n}\r\n\r\nresource \"aws_api_gateway_integration\" \"java_lambda_integration\" {\r\n  rest_api_id             = \"${aws_api_gateway_rest_api.java_lambda_api.id}\"\r\n  resource_id             = \"${aws_api_gateway_resource.java_lambda_api_gateway.id}\"\r\n  http_method             = \"${aws_api_gateway_method.java_lambda_method.http_method}\"\r\n\r\n  integration_http_method = \"POST\"\r\n  type                    = \"AWS_PROXY\"\r\n  uri                     = \"${aws_lambda_function.java_lambda_function.invoke_arn}\"\r\n}\r\n\r\n# Unfortunately the proxy resource cannot match an empty path at the root of the API.\r\n# To handle that, a similar configuration must be applied to the root resource that is built in to the REST API object:\r\nresource \"aws_api_gateway_method\" \"java_lambda_method_root\" {\r\n  rest_api_id   = \"${aws_api_gateway_rest_api.java_lambda_api.id}\"\r\n  resource_id   = \"${aws_api_gateway_rest_api.java_lambda_api.root_resource_id}\"\r\n  http_method   = \"ANY\"\r\n  authorization = \"NONE\"\r\n}\r\n\r\nresource \"aws_api_gateway_integration\" \"java_lambda_integration_root\" {\r\n  rest_api_id = \"${aws_api_gateway_rest_api.java_lambda_api.id}\"\r\n  resource_id = \"${aws_api_gateway_method.java_lambda_method_root.resource_id}\"\r\n  http_method = \"${aws_api_gateway_method.java_lambda_method_root.http_method}\"\r\n\r\n  integration_http_method = \"POST\"\r\n  type                    = \"AWS_PROXY\"\r\n  uri                     = \"${aws_lambda_function.java_lambda_function.invoke_arn}\"\r\n}\r\n\r\nresource \"aws_api_gateway_deployment\" \"java_lambda_deploy\" {\r\n  depends_on  = [\"aws_api_gateway_integration.java_lambda_integration\"]\r\n  rest_api_id = \"${aws_api_gateway_rest_api.java_lambda_api.id}\"\r\n  stage_name  = \"${var.api_env_stage_name}\"\r\n}\r\n"}]}
{"messages": [{"role":"user","content":"Create a Terraform configuration that deploys an EC2 instance using the most recent AMI matching a given prefix within the default VPC and distributes it randomly across one of three public subnets in different availability zones. Define a security group allowing all traffic from within the VPC, SSH access on port 22, and HTTP access on port 80 from anywhere. The setup uses AWS provider settings based on a specified profile and region, with tags and variables for flexible environment, project, and team naming."},{"role":"assistant","content":"\r\nprovider \"aws\" {\r\n  region  = var.aws_region\r\n  profile = var.aws_profile\r\n  shared_credentials_file = \"~/.aws/credentials\"\r\n}\r\n\r\ndata \"aws_caller_identity\" \"current\" {}\r\n\r\ndata \"aws_ami\" \"packer_node_ami\" {\r\n  owners      = [data.aws_caller_identity.current.account_id]\r\n  most_recent = true\r\n\r\n  filter {\r\n    name   = \"tag:Name\"\r\n    values = [\"${var.ami_prefix}*\"]\r\n  }\r\n}\r\n\r\nresource \"aws_instance\" \"packer_node_instance\" {\r\n  ami             = data.aws_ami.packer_node_ami.id\r\n  instance_type   = var.instance_type\r\n  key_name        = var.ssh_key_name\r\n  subnet_id       = random_shuffle.subnet_id.result[0]\r\n  \r\n  vpc_security_group_ids = [\r\n    aws_security_group.packer_node_sg.id\r\n  ]\r\n\r\n  root_block_device {\r\n    volume_type           = \"gp2\"\r\n    volume_size           = 20\r\n    encrypted             = false\r\n    delete_on_termination = true\r\n  }\r\n\r\n  tags = {\r\n    Name = \"${var.team_name}-${var.project_name}-${var.environment_name}\"\r\n  }\r\n}\r\n\r\nresource \"aws_security_group\" \"packer_node_sg\" {\r\n  name        = \"${var.team_name}-${var.project_name}-${var.environment_name}-ec2-sg\"\r\n  description = \"security group for nginx node\"\r\n  vpc_id      = data.aws_vpc.default.id\r\n\r\n  ingress {\r\n    from_port   = 0\r\n    to_port     = 0\r\n    protocol    = \"-1\"\r\n    cidr_blocks = [data.aws_vpc.default.cidr_block]\r\n  }\r\n\r\n  ingress {\r\n    from_port   = \"22\"\r\n    to_port     = \"22\"\r\n    protocol    = \"tcp\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n\r\n  ingress {\r\n    from_port   = \"80\"\r\n    to_port     = \"80\"\r\n    protocol    = \"tcp\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n  \r\n  egress {\r\n    from_port        = 0\r\n    to_port          = 0\r\n    protocol         = \"-1\"\r\n    cidr_blocks      = [\"0.0.0.0/0\"]\r\n  }\r\n}\r\n\r\nvariable \"aws_profile\" {\r\n  type        = string\r\n  description = \"aws profile\"\r\n}\r\n\r\nvariable \"aws_region\" {\r\n  type        = string\r\n  description = \"aws region\"\r\n}\r\n\r\nvariable \"team_name\" {\r\n  type        = string\r\n  description = \"owner of the resource\"\r\n}\r\n\r\nvariable \"project_name\" {\r\n  type        = string\r\n  description = \"project name, eg. my-website\"\r\n}\r\n\r\nvariable \"environment_name\" {\r\n  type        = string\r\n  description = \"environment, eg. prod, staging, dev\"\r\n}\r\n\r\nvariable \"ami_prefix\" {\r\n  type        = string\r\n  description = \"prefix of the name of the ami that should be launched\"\r\n}\r\n\r\nvariable \"instance_type\" {\r\n  type        = string\r\n  description = \"ec2 instance type\"\r\n}\r\n\r\nvariable \"ssh_key_name\" {\r\n  type        = string\r\n  description = \"ec2 ssh key\"\r\n}\r\n\r\n\r\nvariable \"vpc_name\" {\r\n    type        = string\r\n    default     = \"main\"\r\n    description = \"the vpc name\"\r\n}\r\n\r\nvariable \"network_tier\" {\r\n    type        = string\r\n    default     = \"public\"\r\n    description = \"the tier tag value used to identify public subnets\"\r\n}\r\nlocals {\r\n    default_tags = {\r\n        \"Owner\"       = \"devops\"\r\n        \"ManagedBy\"   = \"terraform\"\r\n        \"Environment\" = var.environment_name\r\n        \"Backup\"      = \"false\"\r\n        \"Status\"      = \"active\"\r\n    }\r\n}\r\ndata \"aws_vpc\" \"default\" {\r\n  default = true\r\n  tags = {\r\n    Name = var.vpc_name\r\n  }\r\n}\r\n\r\ndata \"aws_availability_zones\" \"az\" {\r\n  state = \"available\"\r\n  filter {\r\n    name   = \"region-name\"\r\n    values = [var.aws_region]\r\n  }\r\n}\r\n\r\ndata \"aws_subnet\" \"subnet_1\" {\r\n  availability_zone = data.aws_availability_zones.az.names[0]\r\n  vpc_id = data.aws_vpc.default.id\r\n  tags = {\r\n    Tier = var.network_tier\r\n  }\r\n}\r\n\r\ndata \"aws_subnet\" \"subnet_2\" {\r\n  availability_zone = data.aws_availability_zones.az.names[1]\r\n  vpc_id = data.aws_vpc.default.id\r\n  tags = {\r\n    Tier = var.network_tier\r\n  }\r\n}\r\n\r\ndata \"aws_subnet\" \"subnet_3\" {\r\n  availability_zone = data.aws_availability_zones.az.names[2]\r\n  vpc_id = data.aws_vpc.default.id\r\n  tags = {\r\n    Tier = var.network_tier\r\n  }\r\n}\r\n\r\nresource \"random_shuffle\" \"subnet_id\" {\r\n  input        = [data.aws_subnet.subnet_1.id, data.aws_subnet.subnet_2.id, data.aws_subnet.subnet_3.id]\r\n  result_count = 1\r\n}\r\n"}]}
{"messages": [{"role": "user", "content": "Create a unique name suffix using a random pet name generator. Set up a Google Cloud provider in the 'us-central1' region and 'us-central1-c' zone. Create a Google Compute network with the generated name suffix. Set up a Google Compute subnetwork and a disk for your workstation, ensuring both use the unique name suffix. Finally, configure the workstation cluster and workstation configuration to utilize the created network, subnetwork, and source snapshot."}, {"role": "assistant", "content": "\n#File: backing_file.tf\n# This file has some scaffolding to make sure that names are unique and that\n# a region and zone are selected when you try to create your Terraform resources.\n\nlocals {\n  name_suffix = \"${random_pet.suffix.id}\"\n}\n\nresource \"random_pet\" \"suffix\" {\n  length = 2\n}\n\nprovider \"google\" {\n  region = \"us-central1\"\n  zone   = \"us-central1-c\"\n}\n\n#File: main.tf\nresource \"google_compute_network\" \"default\" {\n  provider                = google-beta\n  name                    = \"workstation-cluster-${local.name_suffix}\"\n  auto_create_subnetworks = false\n}\n\nresource \"google_compute_subnetwork\" \"default\" {\n  provider      = google-beta\n  name          = \"workstation-cluster-${local.name_suffix}\"\n  ip_cidr_range = \"10.0.0.0/24\"\n  region        = \"us-central1\"\n  network       = google_compute_network.default.name\n}\n\nresource \"google_compute_disk\" \"my_source_disk\" {\n  provider = google-beta\n  name     = \"workstation-config-${local.name_suffix}\"\n  size     = 10\n  type     = \"pd-ssd\"\n  zone     = \"us-central1-a\"\n}\n\nresource \"google_compute_snapshot\" \"my_source_snapshot\" {\n  provider    = google-beta\n  name        = \"workstation-config-${local.name_suffix}\"\n  source_disk = google_compute_disk.my_source_disk.name\n  zone        = \"us-central1-a\"\n}\n\nresource \"google_workstations_workstation_cluster\" \"default\" {\n  provider               = google-beta\n  workstation_cluster_id = \"workstation-cluster-${local.name_suffix}\"\n  network                = google_compute_network.default.id\n  subnetwork             = google_compute_subnetwork.default.id\n  location               = \"us-central1\"\n}\n\nresource \"google_workstations_workstation_config\" \"default\" {\n  provider               = google-beta\n  workstation_config_id  = \"workstation-config-${local.name_suffix}\"\n  workstation_cluster_id = google_workstations_workstation_cluster.default.workstation_cluster_id\n  location               = google_workstations_workstation_cluster.default.location\n\n  persistent_directories {\n    mount_path = \"/home\"\n\n    gce_pd {\n      source_snapshot = google_compute_snapshot.my_source_snapshot.id\n      reclaim_policy  = \"DELETE\"\n    }\n  }\n}\n"}]}
{"messages": [{"role": "user", "content": "Create a new Terraform configuration for Azure infrastructure. Set up two resource groups named \"us\" and \"europe\" in East US and West Europe. Create virtual networks and subnets within each resource group, ensuring each has a GatewaySubnet. Establish public IPs and virtual network gateways for both regions, and configure VPN connections between the US and Europe gateways. Define security rules to restrict inbound traffic in your network security groups."}, {"role": "assistant", "content": "\n#File: s2s.tf\nterraform {\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"~> 3.0.2\"\n    }\n  }\n\n  required_version = \">= 1.1.0\"\n}\n\nprovider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_resource_group\" \"us\" {\n  name     = \"us\"\n  location = \"East US\"\n}\n\nresource \"azurerm_network_security_group\" \"example\" {\n  name                = \"acceptanceTestSecurityGroup1\"\n  location            = azurerm_resource_group.us.location\n  resource_group_name = azurerm_resource_group.us.name\n\n  security_rule {\n    name                       = \"test123\"\n    priority                   = 100\n    direction                  = \"Inbound\"\n    access                     = \"Deny\"\n    protocol                   = \"*\"\n    source_port_range          = \"*\"\n    destination_port_range     = \"*\"\n    source_address_prefix      = \"*\"\n    destination_address_prefix = \"*\"\n  }\n}\n\nresource \"azurerm_virtual_network\" \"us\" {\n  name                = \"us\"\n  location            = azurerm_resource_group.us.location\n  resource_group_name = azurerm_resource_group.us.name\n  address_space       = [\"10.1.0.0/16\"]\n}\n\nresource \"azurerm_subnet\" \"us_gateway\" {\n  name                 = \"GatewaySubnet\"\n  resource_group_name  = azurerm_resource_group.us.name\n  virtual_network_name = azurerm_virtual_network.us.name\n  address_prefixes     = [\"10.1.1.0/24\"]\n}\n\nresource \"azurerm_public_ip\" \"us\" {\n  name                = \"us\"\n  location            = azurerm_resource_group.us.location\n  resource_group_name = azurerm_resource_group.us.name\n  allocation_method   = \"Dynamic\"\n}\n\nresource \"azurerm_virtual_network_gateway\" \"us\" {\n  name                = \"us-gateway\"\n  location            = azurerm_resource_group.us.location\n  resource_group_name = azurerm_resource_group.us.name\n\n  type     = \"Vpn\"\n  vpn_type = \"RouteBased\"\n  sku      = \"Basic\"\n\n  ip_configuration {\n    public_ip_address_id          = azurerm_public_ip.us.id\n    private_ip_address_allocation = \"Dynamic\"\n    subnet_id                     = azurerm_subnet.us_gateway.id\n  }\n}\n\nresource \"azurerm_resource_group\" \"europe\" {\n  name     = \"europe\"\n  location = \"West Europe\"\n}\n\nresource \"azurerm_virtual_network\" \"europe\" {\n  name                = \"europe\"\n  location            = azurerm_resource_group.europe.location\n  resource_group_name = azurerm_resource_group.europe.name\n  address_space       = [\"10.1.0.0/16\"]\n}\n\nresource \"azurerm_subnet\" \"europe_gateway\" {\n  name                 = \"GatewaySubnet\"\n  resource_group_name  = azurerm_resource_group.europe.name\n  virtual_network_name = azurerm_virtual_network.europe.name\n  address_prefixes     = [\"10.1.1.0/24\"]\n}\n\nresource \"azurerm_public_ip\" \"europe\" {\n  name                = \"europe\"\n  location            = azurerm_resource_group.europe.location\n  resource_group_name = azurerm_resource_group.europe.name\n  allocation_method   = \"Dynamic\"\n}\n\nresource \"azurerm_virtual_network_gateway\" \"europe\" {\n  name                = \"europe-gateway\"\n  location            = azurerm_resource_group.europe.location\n  resource_group_name = azurerm_resource_group.europe.name\n\n  type     = \"Vpn\"\n  vpn_type = \"RouteBased\"\n  sku      = \"Basic\"\n\n  ip_configuration {\n    public_ip_address_id          = azurerm_public_ip.europe.id\n    private_ip_address_allocation = \"Dynamic\"\n    subnet_id                     = azurerm_subnet.europe_gateway.id\n  }\n}\n\nresource \"azurerm_virtual_network_gateway_connection\" \"us_to_europe\" {\n  name                = \"us-to-europe\"\n  location            = azurerm_resource_group.us.location\n  resource_group_name = azurerm_resource_group.us.name\n\n  type                            = \"Vnet2Vnet\"\n  virtual_network_gateway_id      = azurerm_virtual_network_gateway.us.id\n  peer_virtual_network_gateway_id = azurerm_virtual_network_gateway.europe.id\n\n  shared_key = \"SuperSecurePassword\"\n}\n\nresource \"azurerm_virtual_network_gateway_connection\" \"europe_to_us\" {\n  name                = \"europe-to-us\"\n  location            = azurerm_resource_group.europe.location\n  resource_group_name = azurerm_resource_group.europe.name\n\n  type                            = \"Vnet2Vnet\"\n  virtual_network_gateway_id      = azurerm_virtual_network_gateway.europe.id\n  peer_virtual_network_gateway_id = azurerm_virtual_network_gateway.us.id\n\n  shared_key = \"SuperSecurePass\"\n}"}]}
{"messages": [{"role": "user", "content": "Create a Terraform configuration for a Google Cloud environment that includes necessary APIs, IAM roles, and a Cloud Run service. Enable monitoring and logging for the Cloud Run services and configure alert policies for errors and performance metrics. Set up a load balancer with an SSL certificate and associated backend services. Schedule a Cloud Function to check and update the Cloud Run services daily. Define variables for modularity and facilitate customization within the deployment."}, {"role": "assistant", "content": "\n#File: main.tf\nterraform {\n  required_providers {\n    google = {\n      source = \"hashicorp/google\"\n    }\n  }\n}\n\nlocals {\n  cloudrun_neg = one(google_compute_region_network_endpoint_group.cloudrun_neg[*].id)\n  ip_address = one(google_compute_global_address.default[*].address)\n  backend_default_service = one(google_compute_backend_service.default[*].id)\n  url_map  = one(google_compute_url_map.default[*].id)\n  ssl_certificate = one(google_compute_managed_ssl_certificate.default[*].id)\n  load_balancer_target = one(google_compute_target_https_proxy.default[*].id)\n}\n\nprovider \"google\" {\n  project = var.project_id\n  region  = var.region\n}\n\n# Enable required Google Cloud APIs\nresource \"google_project_service\" \"compute_engine_api\" {\n  count = var.use_load_balancer ? 1 : 0\n  service = \"compute.googleapis.com\"\n  disable_on_destroy = false\n}\n\nresource \"google_project_service\" \"dns\" {\n  count = var.use_load_balancer ? 1 : 0\n  project = var.project_id\n  service = \"dns.googleapis.com\"\n}\n\n#Enable logging\nresource \"google_project_service\" \"logging\" {\n  service = \"logging.googleapis.com\"\n  disable_on_destroy = false\n}\n\n#Enable IAM\nresource \"google_project_service\" \"iam_api\" {\n  service = \"iam.googleapis.com\"\n  disable_on_destroy = false\n}\n\n#SET NETWORKING TIER\nresource \"google_compute_project_default_network_tier\" \"default\" {\n  count = var.use_load_balancer ? 1 : 0\n  network_tier = \"PREMIUM\"\n  depends_on = [\n      google_project_service.compute_engine_api\n  ]\n}\n\n#Cloud Run\nresource \"google_project_service\" \"run_api\" {\n  service = \"run.googleapis.com\"\n  disable_on_destroy = false\n}\n\n#Health Check\nresource \"google_compute_health_check\" \"cloud_run_health_check\" {\n  count = var.use_load_balancer ? 1 : 0\n  name = \"cloud-run-health-check\"\n  check_interval_sec = 5\n  timeout_sec        = 5\n  healthy_threshold  = 2\n  unhealthy_threshold = 2\n\n  http_health_check {\n    request_path = \"/healthy\"\n    port         = \"443\"\n  }\n}\n\n#SSL Create\nresource \"google_compute_managed_ssl_certificate\" \"default\" {\n  count = var.use_load_balancer ? 1 : 0\n  name = \"${var.name}-cert\"\n  managed {\n    domains = [\"${var.domain_name}\"]\n  }\n}\n\n#Network Endpoint Group\nresource \"google_compute_region_network_endpoint_group\" \"cloudrun_neg\" {\n  count = var.use_load_balancer ? 1 : 0\n  provider              = google-beta\n  name                  = \"cloud-run-prod-backend\"\n  network_endpoint_type = \"SERVERLESS\"\n  region                = var.region\n  cloud_run {\n    service = google_cloud_run_v2_service.gtm_production.name\n  }\n}\n\n#Empty URL Map\nresource \"google_compute_url_map\" \"default\" {\n  count = var.use_load_balancer ? 1 : 0\n  name            = \"${var.name}-urlmap\"\n  default_service = local.backend_default_service\n  \n  host_rule {\n    hosts = [\"${var.domain_name}\"]\n    path_matcher = \"scripts\"\n  }\n\n  path_matcher {\n    name            = \"scripts\"\n    default_service = local.backend_default_service\n\n    path_rule {\n      paths = [\"/gtm.js\", \"/gtag/*\"]\n      service = google_compute_backend_service.scripts[count.index].id\n    }\n  }\n}\n\n#Backend for script serving\nresource \"google_compute_backend_service\" \"scripts\" {\n  count = var.use_load_balancer ? 1 : 0\n  name      = \"${var.name}-script-serving-backend\"\n\n  protocol  = \"HTTPS\"\n  port_name = \"http\"\n  timeout_sec = 30\n  custom_request_headers  = [\n    \"X-Gclb-Country:{client_region}\",\n    \"X-Gclb-Region:{client_region_subdivision}\",\n    \"X-Gclb-City:{client_city}\",\n    \"X-Gclb-Citylatlong:{client_city_lat_long}\"\n  ]\n  backend {\n    group = local.cloudrun_neg\n  }\n}\n\n#Backend default\nresource \"google_compute_backend_service\" \"default\" {\n  count = var.use_load_balancer ? 1 : 0\n  name      = \"${var.name}-backend\"\n\n  protocol  = \"HTTP\"\n  port_name = \"http\"\n  timeout_sec = 30\n  backend {\n    group = local.cloudrun_neg\n  }\n}\n\nresource \"google_compute_target_https_proxy\" \"default\" {\n  count = var.use_load_balancer ? 1 : 0\n  name   = \"${var.name}-https-proxy\"\n\n  url_map          = local.url_map\n  ssl_certificates = [\n    local.ssl_certificate\n  ]\n}\n\n#Load Balancer Configuration\nresource \"google_compute_global_address\" \"default\" {\n  count = var.use_load_balancer ? 1 : 0\n  name = \"${var.name}-address\"\n}\n\n#Load Balancer Rule\nresource \"google_compute_global_forwarding_rule\" \"default\" {\n  count = var.use_load_balancer ? 1 : 0\n  name   = \"${var.name}-lb\"\n\n  target = local.load_balancer_target\n  port_range = \"443\"\n  ip_address = local.ip_address\n}\n\n#Cloud Scheduler\nresource \"google_project_service\" \"cloud_scheduler\" {\n  service = \"cloudscheduler.googleapis.com\"\n  disable_on_destroy = false\n}\n\nresource \"google_project_service\" \"cloud_build\" {\n  service = \"cloudbuild.googleapis.com\"\n  disable_on_destroy = false\n}\n\nresource \"google_project_service\" \"cloud_functions\" {\n  service = \"cloudfunctions.googleapis.com\"\n  disable_on_destroy = false\n}\n\n#Alerts\nresource \"google_project_service\" \"monitoring_api\" {\n  service = \"monitoring.googleapis.com\"\n  disable_on_destroy = false\n}\n\nresource \"google_service_account\" \"sgtm_service_account\" {\n  account_id   = \"server-side-gtm\"\n  display_name = \"Serverside Google Tagmanager\"\n  depends_on = [ google_project_service.iam_api ]\n}\n\nresource \"google_project_iam_member\" \"sgtm_add_roles\" {\n  for_each = toset([\n    \"roles/run.invoker\",\n    \"roles/cloudfunctions.invoker\",\n    \"roles/cloudfunctions.serviceAgent\",\n    \"roles/artifactregistry.reader\"\n    ])\n  project = var.project_id\n  role = each.value\n  member = \"serviceAccount:${google_service_account.sgtm_service_account.email}\"\n  depends_on = [ google_service_account.sgtm_service_account ]\n}\n\nresource \"google_cloud_run_v2_service\" \"gtm_preview\" {\n    name     = var.service_name_preview\n    location = var.region\n    ingress = \"INGRESS_TRAFFIC_ALL\"\n    labels = {\n        stack = \"sgtm\",\n        provider = \"mohrstade\"\n    }\n    deletion_protection = var.deletion_protection\n    template {\n        annotations = {\n          \"run.googleapis.com/startup-cpu-boost\" = var.cpu_boost\n        }\n        service_account = google_service_account.sgtm_service_account.email\n        scaling {\n            min_instance_count = 0\n            max_instance_count = 1\n        }\n        containers {\n          image = \"gcr.io/cloud-tagging-10302018/gtm-cloud-image:stable\"\n          env {\n              name = \"CONTAINER_CONFIG\"\n              value = var.container_config\n          }\n          env {\n              name = \"GOOGLE_CLOUD_PROJECT\"\n              value = var.project_id\n          }\n          env {\n              name = \"RUN_AS_PREVIEW_SERVER\"\n              value = true\n          }\n          startup_probe {\n              http_get {\n                  path = \"/healthy\"\n              }\n              initial_delay_seconds = 0\n              period_seconds = 10\n              failure_threshold = 3\n              timeout_seconds = 4\n          }\n          liveness_probe {\n              http_get {\n                  path = \"/healthy\"\n              }\n              initial_delay_seconds = 240\n              period_seconds = 10\n              failure_threshold = 10\n              timeout_seconds = 4\n          }\n        }\n    }\n    depends_on = [ google_project_iam_member.sgtm_add_roles, google_project_service.run_api ]\n}\n\nresource \"google_cloud_run_v2_service\" \"gtm_production\" {\n  name     = var.service_name_production\n  location = var.region\n  ingress = \"INGRESS_TRAFFIC_ALL\"\n  labels = {\n        stack = \"sgtm\",\n        provider = \"mohrstade\"\n    }\n  deletion_protection = var.deletion_protection\n  template {\n    annotations = {\n      \"run.googleapis.com/startup-cpu-boost\" = var.cpu_boost\n    }\n    service_account = google_service_account.sgtm_service_account.email\n    scaling {\n        min_instance_count = var.min_instance_count\n        max_instance_count = var.max_instance_count\n    }\n    containers {\n        image = \"gcr.io/cloud-tagging-10302018/gtm-cloud-image:stable\"\n        env {\n            name = \"CONTAINER_CONFIG\"\n            value = var.container_config\n        }\n        env {\n            name = \"GOOGLE_CLOUD_PROJECT\"\n            value = var.project_id\n        }\n        env {\n            name = \"PREVIEW_SERVER_URL\"\n            value = google_cloud_run_v2_service.gtm_preview.uri\n        }\n       startup_probe {\n        http_get {\n          path = \"/healthy\"\n        }\n        initial_delay_seconds = 0\n        period_seconds = 10\n        failure_threshold = 3\n        timeout_seconds = 4\n      }\n      liveness_probe {\n        http_get {\n          path = \"/healthy\"\n        }\n        initial_delay_seconds = 240\n        period_seconds = 10\n        failure_threshold = 10\n        timeout_seconds = 4\n      }\n    }\n  }\n  depends_on = [ google_cloud_run_v2_service.gtm_preview ]\n}\n\nresource \"google_logging_project_exclusion\" \"cloud-run-log-exclusion\" {\n  name = \"cloud-run-log-exclusion\"\n  description = \"Exclude Cloud Run logs which are not severe.\"\n  filter = var.cloud_run_exclusion_filter\n  depends_on = [ google_cloud_run_v2_service.gtm_production ]\n}\n\nresource \"google_cloud_run_service_iam_member\" \"prod_run_all_users\" {\n  service  = google_cloud_run_v2_service.gtm_production.name\n  location = google_cloud_run_v2_service.gtm_production.location\n  role     = \"roles/run.invoker\"\n  member   = \"allUsers\"\n  depends_on = [ google_cloud_run_v2_service.gtm_production ]\n}\n\nresource \"google_cloud_run_service_iam_member\" \"debug_run_all_users\" {\n  service  = google_cloud_run_v2_service.gtm_preview.name\n  location = google_cloud_run_v2_service.gtm_preview.location\n  role     = \"roles/run.invoker\"\n  member   = \"allUsers\"\n  depends_on = [ google_cloud_run_v2_service.gtm_preview ]\n}\n\nresource \"google_monitoring_notification_channel\" \"sgtm_notification_channels\" {\n  count = length(var.notification_users)\n  display_name = var.notification_users[count.index].name\n  type         = \"email\"\n  labels = {\n    email_address = var.notification_users[count.index].email\n  }\n  force_delete = false\n  depends_on = [ google_project_service.monitoring_api ]\n}\n\nresource \"google_monitoring_uptime_check_config\" \"sgtm_uptime_check\" {\n  display_name = \"sgtm_uptime_check\"\n  timeout = \"10s\"\n  period = \"60s\"\n\n  http_check {\n    path     = \"/healthy\"\n    port     = 443\n    use_ssl  = true\n  }\n\n  monitored_resource {\n    type = \"cloud_run_revision\"\n    labels = {\n      project_id = var.project_id\n      service_name = google_cloud_run_v2_service.gtm_production.name\n      location = var.region\n    }\n  }\n  depends_on = [ google_cloud_run_v2_service.gtm_production ]\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"google_monitoring_alert_policy\" \"sgtm_alert_policy\" {\n  display_name = \"SGTM Alert Policy\"\n  combiner     = \"OR\"\n  documentation {\n    content = <<EOT\n    Uptime Alert - Serverside Google Tag Manager\n    There was an error for the Cloud Run services running the serverside Google Tag Manager backend in project: \"${var.project_id}\".\n\n    Check the Uptime Checks in Monitoring on GCP for more information.\n    EOT\n    mime_type = \"text/markdown\"\n  }\n  conditions {\n    display_name = \"Failure of uptime check : ${google_monitoring_uptime_check_config.sgtm_uptime_check.uptime_check_id}\"\n    condition_threshold {\n    filter = <<EOT\nmetric.type=\"monitoring.googleapis.com/uptime_check/check_passed\" AND metric.label.check_id=\"${google_monitoring_uptime_check_config.sgtm_uptime_check.uptime_check_id}\" AND resource.type=\"cloud_run_revision\"\n    EOT\n    duration        = \"60s\"\n    comparison      = \"COMPARISON_GT\"\n    threshold_value = \"1\"\n    trigger {\n      count = \"1\"\n    }\n\n    aggregations {\n      alignment_period     = \"1200s\"\n      cross_series_reducer = \"REDUCE_COUNT_FALSE\"\n      group_by_fields = [\n        \"resource.label.project_id\",\n        \"resource.label.service_name\",\n        \"resource.label.revision_name\",\n        \"resource.label.location\",\n        \"resource.label.configuration_name\"\n      ]\n      per_series_aligner   = \"ALIGN_NEXT_OLDER\"\n    }\n  }\n  }\n\n  notification_channels = [ for channel in google_monitoring_notification_channel.sgtm_notification_channels : channel.id ]\n  depends_on = [ google_monitoring_notification_channel.sgtm_notification_channels, google_monitoring_uptime_check_config.sgtm_uptime_check ]\n}\n\nresource \"google_monitoring_alert_policy\" \"sgtm_update_alert_policy\" {\n  display_name = \"SGTM Update Notice\"\n  combiner     = \"OR\"\n  documentation {\n    content = <<EOT\n    SGTM Update Notice\n    The Cloud Run SGTM in \"${var.project_id}\" was updated to the latest version.\n    Check Cloud Function logs for details.\n\n    EOT\n    mime_type = \"text/markdown\"\n  }\n  conditions {\n    display_name = \"SGTM\"\n    condition_matched_log {\n      filter =  var.cloud_function_update_filter\n    }\n  }\n  alert_strategy {\n    notification_rate_limit {\n      period = \"300s\"\n    }\n  }\n  notification_channels = [ for channel in google_monitoring_notification_channel.sgtm_notification_channels : channel.id ]\n  depends_on = [ google_monitoring_notification_channel.sgtm_notification_channels ]\n}\n\nresource \"google_monitoring_alert_policy\" \"sgtm_cpu_utilization_alert_policy\" {\n  display_name = \"SGTM High CPU Utilization Alert\"\n  combiner     = \"OR\"\n  conditions {\n    display_name = \"SGTM CPU Utilization > 60% for Production\"\n    condition_threshold {\n      filter = <<-EOT\n        metric.type=\"run.googleapis.com/container/cpu/utilizations\" AND\n        resource.type=\"cloud_run_revision\" AND\n        resource.label.service_name=\"${var.service_name_production}\"\n      EOT\n      comparison = \"COMPARISON_GT\"\n      threshold_value = 0.6\n      duration = \"300s\"\n      aggregations {\n        alignment_period   = \"300s\"\n        per_series_aligner = \"ALIGN_PERCENTILE_99\"\n      }\n    }\n  }\n  notification_channels = [ for channel in google_monitoring_notification_channel.sgtm_notification_channels : channel.id ]\n  depends_on = [ google_monitoring_notification_channel.sgtm_notification_channels ]\n}\n\nresource \"google_monitoring_alert_policy\" \"sgtm_instance_count_alert_policy\" {\n  display_name = \"SGTM High Instance Count Alert\"\n  combiner     = \"OR\"\n  conditions {\n    display_name = \"SGTM Instance Count Exceeds 80% of Maximum\"\n    condition_threshold {\n      filter = <<-EOT\n        metric.type=\"run.googleapis.com/container/instance_count\" AND\n        resource.type=\"cloud_run_revision\" AND\n        resource.label.service_name=\"${var.service_name_production}\"\n      EOT\n      aggregations {\n        alignment_period   = \"300s\"\n        per_series_aligner = \"ALIGN_MEAN\"\n      }\n      comparison      = \"COMPARISON_GT\"\n      threshold_value = var.alert_instance_count\n      duration        = \"300s\"\n    }\n  }\n  notification_channels = [ for channel in google_monitoring_notification_channel.sgtm_notification_channels : channel.id ]\n  depends_on = [ google_monitoring_notification_channel.sgtm_notification_channels ]\n}\n\nresource \"google_monitoring_alert_policy\" \"sgtm_request_latency_alert\" {\n  display_name = \"SGTM High Request Latency Alert\"\n  combiner     = \"OR\"\n  conditions {\n    display_name = \"SGTM Request Latency Exceeds 2 Seconds\"\n    condition_threshold {\n      filter = <<-EOT\n        metric.type=\"run.googleapis.com/request_latencies\" AND\n        resource.type=\"cloud_run_revision\" AND\n        resource.label.service_name=\"${var.service_name_production}\"\n      EOT\n      aggregations {\n        alignment_period   = \"300s\"\n        per_series_aligner = \"ALIGN_PERCENTILE_99\"\n      }\n      comparison      = \"COMPARISON_GT\"\n      threshold_value = 2000\n      duration        = \"300s\"\n    }\n  }\n  notification_channels = [ for channel in google_monitoring_notification_channel.sgtm_notification_channels : channel.id ]\n  depends_on = [ google_monitoring_notification_channel.sgtm_notification_channels ]\n}\n\nresource \"google_logging_metric\" \"sgtm_http_error_responses_metric\" {\n  name        = \"http_error_responses\"\n  description = \"Count of HTTP error responses for Cloud Run requests\"\n  filter      = <<EOT\n    resource.type=\"cloud_run_revision\"\n    httpRequest.status>=400\n  EOT\n  metric_descriptor {\n    metric_kind = \"DELTA\"\n    value_type  = \"INT64\"\n    labels {\n      key         = \"status_code\"\n      value_type  = \"INT64\"\n      description = \"The HTTP status code of the response.\"\n    }\n  }\n  label_extractors = {\n    \"status_code\" = \"EXTRACT(httpRequest.status)\"\n  }\n}\n\nresource \"google_monitoring_alert_policy\" \"sgtm_error_logs_alert\" {\n  display_name = \"SGTM High HTTP Error Rate Alert\"\n  combiner     = \"OR\"\n  conditions {\n    display_name = \"Error Rate Exceeds Threshold\"\n    condition_threshold {\n      filter = <<-EOT\n        metric.type=\"logging.googleapis.com/user/http_error_responses\" AND\n        resource.type=\"cloud_run_revision\" AND\n        resource.label.service_name=\"${var.service_name_production}\"\n      EOT\n      aggregations {\n        alignment_period   = \"300s\"\n        per_series_aligner = \"ALIGN_RATE\"\n      }\n      comparison      = \"COMPARISON_GT\"\n      threshold_value = 5.0\n      duration        = \"0s\"\n    }\n  }\n  notification_channels = [ for channel in google_monitoring_notification_channel.sgtm_notification_channels : channel.id ]\n  depends_on = [ google_monitoring_notification_channel.sgtm_notification_channels, google_logging_metric.sgtm_http_error_responses_metric ]\n}\n\n# download cloud function files from github\nresource \"null_resource\" \"index_js\" {\n  triggers = {\n    always_run = \"${timestamp()}\"\n  }\n  provisioner \"local-exec\" {\n    command = \"curl -L https://raw.githubusercontent.com/liscor/sgtm_cloud_run_updater/main/index.js --output ${path.module}/cf_function/index.js\"\n  }\n}\n\nresource \"null_resource\" \"package_json\" {\n  triggers = {\n    always_run = \"${timestamp()}\"\n  }\n  provisioner \"local-exec\" {\n    command = \"curl -L https://raw.githubusercontent.com/liscor/sgtm_cloud_run_updater/main/package.json --output ${path.module}/cf_function/package.json\"\n  }\n}\n\ndata \"archive_file\" \"function_zip\" {\n  type        = \"zip\"\n  output_path = \"${path.module}/cf_function/function.zip\"\n  source_dir  = \"${path.module}/cf_function\"\n  excludes    = [\"${path.module}/cf_function/function.zip\"]\n\n  depends_on = [null_resource.index_js,null_resource.package_json]\n}\n\nresource \"google_storage_bucket\" \"bucket\" {\n  name     = var.google_storage_bucket_name\n  location = \"EU\"\n}\n\n# Upload the Cloud Function source file\nresource \"google_storage_bucket_object\" \"source_files\" {\n  name   = \"sgtm_cloud_run_updater\"\n  bucket = google_storage_bucket.bucket.name\n  source = \"cf_function/function.zip\"\n  depends_on = [ google_storage_bucket.bucket, data.archive_file.function_zip ]\n}\n\n# Create Cloud Function for updating\nresource \"google_cloudfunctions_function\" \"sgtm_updater\" {\n  name        = \"sgtm_cloud_run_updater\"\n  description = \"Cloud Function to update the Cloud Run sgtm if necessary.\"\n  service_account_email = google_service_account.sgtm_service_account.email\n  runtime     = \"nodejs20\"\n  region = var.region\n  available_memory_mb   = 256\n  source_archive_bucket = google_storage_bucket.bucket.name\n  source_archive_object = google_storage_bucket_object.source_files.name\n  trigger_http          = true\n  entry_point           = \"check_cloud_run\"\n  depends_on = [ google_storage_bucket_object.source_files ]\n}\n\n# Triggers the sgtm cloud updater for gtm-production once a day\nresource \"google_cloud_scheduler_job\" \"run_sgtm_updater_production\" {\n  name             = \"run_sgtm_updater_production\"\n  description      = \"Execute the SGTM Cloud Function on a daily basis to check for updates and deploy these as well.\"\n  region           = var.region\n  schedule         = var.update_interval\n  time_zone        = \"Europe/Berlin\"\n  attempt_deadline = \"320s\"\n\n  retry_config {\n    retry_count = 1\n  }\n\n  http_target {\n    http_method = \"POST\"\n    uri         = google_cloudfunctions_function.sgtm_updater.https_trigger_url\n    body        = base64encode(\"{\\\"project_id\\\":\\\"${var.project_id}\\\",\\\"region\\\":\\\"${var.region}\\\",\\\"service_name\\\":\\\"${google_cloud_run_v2_service.gtm_production.name}\\\"}\")\n    headers = {\n      \"Content-Type\" = \"application/json\"\n    }\n    oidc_token {\n      service_account_email = google_service_account.sgtm_service_account.email\n    }\n  }\n  depends_on = [ google_cloudfunctions_function.sgtm_updater,google_cloud_run_v2_service.gtm_production ]\n}\n\n# Triggers the sgtm cloud updater for gtm-debug once a day\nresource \"google_cloud_scheduler_job\" \"run_sgtm_updater_debug\" {\n  name             = \"run_sgtm_updater_debug\"\n  description      = \"Execute the SGTM Cloud Function on a daily basis to check for updates and deploy these as well.\"\n  region           = var.region\n  schedule         = var.update_interval\n  time_zone        = \"Europe/Berlin\"\n  attempt_deadline = \"320s\"\n\n  retry_config {\n    retry_count = 1\n  }\n\n  http_target {\n    http_method = \"POST\"\n    uri         = google_cloudfunctions_function.sgtm_updater.https_trigger_url\n    body        = base64encode(\"{\\\"project_id\\\":\\\"${var.project_id}\\\",\\\"region\\\":\\\"${var.region}\\\",\\\"service_name\\\":\\\"${google_cloud_run_v2_service.gtm_preview.name}\\\"}\")\n    headers = {\n      \"Content-Type\" = \"application/json\"\n    }\n    oidc_token {\n      service_account_email = google_service_account.sgtm_service_account.email\n    }\n  }\n  depends_on = [ google_cloudfunctions_function.sgtm_updater,google_cloud_run_v2_service.gtm_preview ]\n}\n\noutput \"load_balancer_ip\" {\n  value = local.ip_address\n}\n\n#File: variables.tf\nvariable \"project_id\" {\n  description = \"The project ID in which the stack is being deployed\"\n  type        = string\n}\n\nvariable \"project_name\" {\n  description = \"The name of the project\"\n  type        = string\n}\n\nvariable \"region\" {\n  description = \"The name of the region to deploy within\"\n  type        = string\n  default     = \"europe-west1\"\n}\n\nvariable \"organization_id\" {\n  description = \"The organization ID for your project\"\n  type        = string\n  default     = null  # Set null if not part of an organization\n}\n\nvariable \"container_config\" {\n    description = \"The container configuration string obtained from the Google Tag Manager Webinterface\"\n    type = string\n}\n\nvariable \"service_name_production\" {\n    description = \"The name of the SGTM production service in Cloud Run.\"\n    type = string\n    default = \"sgtm-production\"\n}\n\nvariable \"service_name_preview\" {\n    description = \"The name of the SGTM preview service in Cloud Run.\"\n    type = string\n    default = \"sgtm-preview\"\n}\n\nvariable \"min_instance_count\" {\n  description = \"The maximum instances the Cloud Run service for production SGTM can create.\"\n  type = number\n  default = 0\n}\n\nvariable \"max_instance_count\" {\n  description = \"The maximum instances the Cloud Run service for production SGTM can create.\"\n  type = number\n  default = 10\n}\n\nvariable \"alert_instance_count\" {\n  description = \"Number of instances after which instance count alert will be triggered.\"\n  type = number\n  default = 8\n}\n\nvariable \"cpu_boost\" {\n  description = \"Activate CPU boost to allocate more CPUs for instances starting up.\"\n  type = bool\n  default = false\n}\n\nvariable \"cloud_function_update_filter\" {\n  description = \"The Cloud function logs when the the Cloud Run SGTM instance gets updated.\"\n  type = string\n  default = \"resource.type=\\\"cloud_function\\\" \\nAND textPayload=~\\\"Versions are different: Deploying a new revision\\\"\"\n}\n\nvariable \"update_interval\" {\n  description = \"Update interval for the Cloud Function updating the SGTM Image in unix-cron job format - Default everyday at 8:00 am UTC\"\n  type = string\n  default = \"0 8 * * *\"\n}\n\nvariable \"cloud_run_exclusion_filter\" {\n  description = \"The Cloud Run logs which will be exclude from the _default bucket.\"\n  type = string\n  default = \"resource.type=\\\"cloud_run_revision\\\" AND severity = \\\"INFO\\\" OR severity =\\\"DEFAULT\\\"\"\n}\n\nvariable \"notification_users\" {\n  description = \"List of users for notification\"\n  type = list(object({\n    name  = string\n    email = string\n  }))\n}\n\nvariable \"google_storage_bucket_name\" {\n    description = \"The unique name of the google storage bucket\"\n    type = string\n}\n\nvariable \"domain_name\" {\n  description = \"Domain name for the load balancer.\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"name\" {\n  description = \"The name of the stack\"\n  type        = string\n}\n\nvariable \"use_load_balancer\" {\n  description = \"Whether to use a load balancer\"\n  type        = bool\n  default     = false\n}\n\n variable \"deletion_protection\" {\n    description = \"Whether to enable deletion protection\"\n    type        = bool\n    default     = true\n}"}]}
{"messages": [{"role":"user","content":"Provisions an AWS EC2 instance with a secure key pair, security group, and an attached EBS volume, then sets up a web server with HTTP and PHP support. Upload a file to an S3 bucket and creates a CloudFront distribution to serve the content securely with caching and geo-restrictions. Finally, it modifies the web server HTML to include an image link, takes an EBS snapshot, and opens the webpage automatically in a local browser"},{"role":"assistant","content":"provider \"aws\" {\r\n  region  = \"ap-south-1\"\r\n  profile = \"harsh\"\r\n}\r\n\r\nvariable \"ami_id\" {\r\n  type    = string\r\n  default = \"ami-0447a12f28fddb066\"\r\n}\r\n\r\nvariable \"ami_type\" {\r\n  type    = string\r\n  default = \"t2.micro\"\r\n}\r\n\r\nvariable \"EC2_Key\" {\r\n  type    = string\r\n  default = \"Task1Key\"\r\n}\r\n\r\nresource \"tls_private_key\" \"tls_key\" {\r\n  algorithm = \"RSA\"\r\n  rsa_bits  = 4096\r\n}\r\n\r\nresource \"aws_key_pair\" \"generated_key\" {\r\n  depends_on = [\r\n    tls_private_key.tls_key\r\n  ]\r\n  key_name   = var.EC2_Key\r\n  public_key = tls_private_key.tls_key.public_key_openssh\r\n}\r\n\r\nresource \"local_file\" \"key_file\" {\r\n  depends_on = [\r\n    tls_private_key.tls_key\r\n  ]\r\n  content  = tls_private_key.tls_key.private_key_pem\r\n  filename = \"${var.EC2_Key}.pem\"\r\n}\r\n\r\nresource \"aws_security_group\" \"firewall\" {\r\n  depends_on = [\r\n    aws_key_pair.generated_key\r\n  ]\r\n  name        = \"firewall\"\r\n  description = \"allows ssh and httpd protocol\"\r\n\r\n  ingress {\r\n    description = \"SSH Port\"\r\n    from_port   = 22\r\n    to_port     = 22\r\n    protocol    = \"tcp\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n\r\n  ingress {\r\n    description = \"HTTPD Port\"\r\n    from_port   = 80\r\n    to_port     = 80\r\n    protocol    = \"tcp\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n\r\n  egress {\r\n    from_port   = 0\r\n    to_port     = 0\r\n    protocol    = \"-1\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n\r\n  tags = {\r\n    Name = \"security-group-1\"\r\n  }\r\n}\r\n\r\nresource \"aws_instance\" \"autos\" {\r\n  depends_on    = [aws_security_group.firewall]\r\n  ami           = var.ami_id\r\n  instance_type = var.ami_type\r\n  key_name      = var.EC2_Key\r\n  security_groups = [aws_security_group.firewall.name]\r\n\r\n  connection {\r\n    type        = \"ssh\"\r\n    user        = \"ec2-user\"\r\n    private_key = tls_private_key.tls_key.private_key_pem\r\n    host        = self.public_ip\r\n  }\r\n\r\n  provisioner \"remote-exec\" {\r\n    inline = [\r\n      \"sudo yum install httpd php git -y\",\r\n      \"sudo systemctl restart httpd\",\r\n      \"sudo systemctl enable httpd\"\r\n    ]\r\n  }\r\n\r\n  tags = {\r\n    Name = \"autos\"\r\n    env  = \"Production\"\r\n  }\r\n}\r\n\r\nresource \"aws_ebs_volume\" \"ebs\" {\r\n  availability_zone = aws_instance.autos.availability_zone\r\n  size              = 1\r\n\r\n  tags = {\r\n    Name = \"autos_ebs\"\r\n  }\r\n}\r\n\r\nresource \"aws_volume_attachment\" \"ebs_att\" {\r\n  device_name  = \"/dev/sdh\"\r\n  volume_id    = aws_ebs_volume.ebs.id\r\n  instance_id  = aws_instance.autos.id\r\n  force_detach = true\r\n}\r\n\r\nresource \"null_resource\" \"mount_ebs_volume\" {\r\n  depends_on = [\r\n    aws_volume_attachment.ebs_att\r\n  ]\r\n\r\n  connection {\r\n    type        = \"ssh\"\r\n    user        = \"ec2-user\"\r\n    private_key = tls_private_key.tls_key.private_key_pem\r\n    host        = aws_instance.autos.public_ip\r\n  }\r\n\r\n  provisioner \"remote-exec\" {\r\n    inline = [\r\n      \"sudo mkfs.ext4 /dev/xvdh || echo 'Filesystem already exists'\",\r\n      \"sudo mount /dev/xvdh /var/www/html\",\r\n      \"sudo rm -rf /var/www/html/*\"\r\n    ]\r\n  }\r\n}\r\n\r\nresource \"aws_s3_bucket\" \"S3\" {\r\n  bucket = \"autos-s3-bucket\"\r\n}\r\n\r\nresource \"aws_s3_object\" \"S3_Object\" {\r\n  depends_on = [\r\n    aws_s3_bucket.S3\r\n  ]\r\n\r\n  bucket = aws_s3_bucket.S3.bucket\r\n  key    = \"Cloud.JPG\"\r\n  source = \"D:/LW/Hybrid-Multi-Cloud/Terraform/tera/task/Cloud.JPG\"\r\n  acl    = \"public-read\"\r\n}\r\n\r\nlocals {\r\n  S3_Origin_Id = aws_s3_bucket.S3.id\r\n}\r\n\r\nresource \"aws_cloudfront_distribution\" \"CloudFront\" {\r\n  depends_on = [\r\n    aws_s3_object.S3_Object\r\n  ]\r\n\r\n  origin {\r\n    domain_name = aws_s3_bucket.S3.bucket_regional_domain_name\r\n    origin_id   = aws_s3_bucket.S3.id\r\n  }\r\n\r\n  enabled         = true\r\n  is_ipv6_enabled = true\r\n  comment         = \"S3 Web Distribution\"\r\n\r\n  default_cache_behavior {\r\n    allowed_methods  = [\"DELETE\", \"GET\", \"HEAD\", \"OPTIONS\", \"PATCH\", \"POST\", \"PUT\"]\r\n    cached_methods   = [\"GET\", \"HEAD\"]\r\n    target_origin_id = aws_s3_bucket.S3.id\r\n\r\n    forwarded_values {\r\n      query_string = false\r\n      cookies {\r\n        forward = \"none\"\r\n      }\r\n    }\r\n\r\n    viewer_protocol_policy = \"allow-all\"\r\n    min_ttl                = 0\r\n    default_ttl            = 3600\r\n    max_ttl                = 86400\r\n  }\r\n\r\n  ordered_cache_behavior {\r\n    path_pattern     = \"/content/immutable/*\"\r\n    allowed_methods  = [\"GET\", \"HEAD\", \"OPTIONS\"]\r\n    cached_methods   = [\"GET\", \"HEAD\", \"OPTIONS\"]\r\n    target_origin_id = aws_s3_bucket.S3.id\r\n\r\n    forwarded_values {\r\n      query_string = false\r\n      headers      = [\"Origin\"]\r\n      cookies {\r\n        forward = \"none\"\r\n      }\r\n    }\r\n\r\n    min_ttl                = 0\r\n    default_ttl            = 86400\r\n    max_ttl                = 31536000\r\n    compress               = true\r\n    viewer_protocol_policy = \"redirect-to-https\"\r\n  }\r\n\r\n  ordered_cache_behavior {\r\n    path_pattern     = \"/content/*\"\r\n    allowed_methods  = [\"GET\", \"HEAD\", \"OPTIONS\"]\r\n    cached_methods   = [\"GET\", \"HEAD\"]\r\n    target_origin_id = aws_s3_bucket.S3.id\r\n\r\n    forwarded_values {\r\n      query_string = false\r\n      cookies {\r\n        forward = \"none\"\r\n      }\r\n    }\r\n\r\n    min_ttl                = 0\r\n    default_ttl            = 3600\r\n    max_ttl                = 86400\r\n    compress               = true\r\n    viewer_protocol_policy = \"redirect-to-https\"\r\n  }\r\n\r\n  price_class = \"PriceClass_200\"\r\n\r\n  restrictions {\r\n    geo_restriction {\r\n      restriction_type = \"whitelist\"\r\n      locations        = [\"IN\"]\r\n    }\r\n  }\r\n\r\n  tags = {\r\n    Name        = \"CF Distribution\"\r\n    Environment = \"Production\"\r\n  }\r\n\r\n  viewer_certificate {\r\n    cloudfront_default_certificate = true\r\n  }\r\n\r\n  retain_on_delete = true\r\n}\r\n\r\nresource \"null_resource\" \"CF_URL\" {\r\n  depends_on = [\r\n    aws_cloudfront_distribution.CloudFront\r\n  ]\r\n\r\n  connection {\r\n    type        = \"ssh\"\r\n    user        = \"ec2-user\"\r\n    private_key = tls_private_key.tls_key.private_key_pem\r\n    host        = aws_instance.autos.public_ip\r\n  }\r\n\r\n  provisioner \"remote-exec\" {\r\n    inline = [\r\n      \"echo '<br>' | sudo tee -a /var/www/html/Slack.html\",\r\n      \"echo '<br>' | sudo tee -a /var/www/html/Slack.html\",\r\n      \"echo '<br>' | sudo tee -a /var/www/html/Slack.html\",\r\n      \"echo '<br>' | sudo tee -a /var/www/html/Slack.html\",\r\n      \"echo '<br>' | sudo tee -a /var/www/html/Slack.html\",\r\n      \"echo '<a href=\\\"https://dev.to/hrshmistry\\\">' | sudo tee -a /var/www/html/Slack.html\",\r\n      \"echo '<img src=\\\"https://d2fltix0v2e0sb.cloudfront.net/dev-badge.svg\\\" alt=\\\"Harsh Mistry DEV Profile\\\" height=\\\"50\\\" width=\\\"50\\\">' | sudo tee -a /var/www/html/Slack.html\",\r\n      \"echo '</a>' | sudo tee -a /var/www/html/Slack.html\"\r\n    ]\r\n  }\r\n}\r\n\r\nresource \"aws_ebs_snapshot\" \"ebs_snapshot\" {\r\n  depends_on = [\r\n    null_resource.CF_URL\r\n  ]\r\n\r\n  volume_id = aws_ebs_volume.ebs.id\r\n\r\n  tags = {\r\n    Name = \"ebs_snap\"\r\n  }\r\n}\r\n\r\nresource \"null_resource\" \"web_server_site_on_browser\" {\r\n  depends_on = [\r\n    null_resource.CF_URL\r\n  ]\r\n\r\n  provisioner \"local-exec\" {\r\n    command = \"brave http://${aws_instance.autos.public_ip}/Slack.html\"\r\n  }\r\n}\r\n\r\noutput \"autos_public_ip\" {\r\n  value = aws_instance.autos.public_ip\r\n}\r\n"}]}
{"messages": [{"role": "user", "content": "Create a DigitalOcean provider configuration with a token variable. Define a variable for the region with a default value of \"fra1\". Retrieve the most recent droplet snapshot named \"cowrie-snapshot\" in the specified region. Deploy an EC2 instance named \"cowrie-honeypot\" using the retrieved snapshot and configure its size to \"s-2vcpu-2gb\" with monitoring enabled. Set up a firewall for the droplet with inbound rules allowing TCP traffic on port 22 and multiple outbound rules for ICMP, TCP, and UDP traffic."}, {"role": "assistant", "content": "\n#File: main.tf\nterraform {\n  required_providers {\n    digitalocean = {\n      source  = \"digitalocean/digitalocean\"\n      version = \"2.53.0\"\n    }\n  }\n}\n\nvariable \"region\" {\n  type        = string\n  default     = \"fra1\"\n  description = \"DigitalOcean region.\"\n}\n\nvariable \"do_token\" {\n  type        = string\n  description = \"DigitalOcean token.\"\n}\n\nprovider \"digitalocean\" {\n  token = var.do_token\n}\n\ndata \"digitalocean_droplet_snapshot\" \"cowrie_snapshot\" {\n  name_regex  = \"^cowrie-snapshot\"\n  region      = var.region\n  most_recent = true\n}\n\nresource \"digitalocean_droplet\" \"cowrie\" {\n  image      = data.digitalocean_droplet_snapshot.cowrie_snapshot.id\n  name       = \"cowrie-honeypot\"\n  region     = var.region\n  size       = \"s-2vcpu-2gb\"\n  monitoring = \"true\"\n  tags       = [\"honeypot\"]\n}\n\nresource \"digitalocean_firewall\" \"cowrie_firewall\" {\n  name        = \"cowrie-honeypot-firewall\"\n  droplet_ids = [digitalocean_droplet.cowrie.id]\n\n  inbound_rule {\n    port_range = \"22\"\n    protocol   = \"tcp\"\n    source_addresses = [\n      \"0.0.0.0/0\",\n      \"::/0\",\n    ]\n    source_droplet_ids        = []\n    source_load_balancer_uids = []\n    source_tags               = []\n  }\n\n  outbound_rule {\n    destination_addresses = [\n      \"0.0.0.0/0\",\n      \"::/0\",\n    ]\n    destination_droplet_ids        = []\n    destination_load_balancer_uids = []\n    destination_tags               = []\n    protocol                       = \"icmp\"\n  }\n  outbound_rule {\n    destination_addresses = [\n      \"0.0.0.0/0\",\n      \"::/0\",\n    ]\n    destination_droplet_ids        = []\n    destination_load_balancer_uids = []\n    destination_tags               = []\n    port_range                     = \"all\"\n    protocol                       = \"tcp\"\n  }\n  outbound_rule {\n    destination_addresses = [\n      \"0.0.0.0/0\",\n      \"::/0\",\n    ]\n    destination_droplet_ids        = []\n    destination_load_balancer_uids = []\n    destination_tags               = []\n    port_range                     = \"all\"\n    protocol                       = \"udp\"\n  }\n}\n"}]}
{"messages": [{"role":"user","content":"Provide an AWS ECS Fargate cluster running a React app container, integrated with an Application Load Balancer across three default subnets in the eu-central-1 region. It includes IAM roles for ECS task execution, security groups for both load balancer and service, and auto-scaling policies triggered by CPU utilization alarms. Additionally, a CloudWatch dashboard monitors key ECS and ALB metrics for performance and health insights."},{"role":"assistant","content":"provider \"aws\" {\r\n  access_key = var.AWS_ACCESS_KEY\r\n  secret_key = var.AWS_SECRET_KEY\r\n  region     = var.AWS_REGION\r\n}\r\n\r\n\r\n# Providing a reference to our default VPC\r\nresource \"aws_default_vpc\" \"default_vpc\" {\r\n}\r\n\r\n# Providing a reference to our default subnets\r\nresource \"aws_default_subnet\" \"default_subnet_a\" {\r\n  availability_zone = \"eu-central-1a\"\r\n}\r\n\r\nresource \"aws_default_subnet\" \"default_subnet_b\" {\r\n  availability_zone = \"eu-central-1b\"\r\n}\r\n\r\nresource \"aws_default_subnet\" \"default_subnet_c\" {\r\n  availability_zone = \"eu-central-1c\"\r\n}\r\n\r\n#resource \"aws_ecr_repository\" \"my_first_ecr_repo\" {name = \"react\"}\r\n#data \"aws_ecr_image\" \"my_first_ecr_repo\" {\r\n#repository_name = \"356079734857.dkr.ecr.eu-central-1.amazonaws.com/react\"\r\n# image_tag       = \"latest\"\r\n#}\r\n\r\nresource \"aws_ecs_cluster\" \"app\" {\r\n  name = \"app-cluster\" # Naming the cluster\r\n}\r\n\r\n\r\nresource \"aws_ecs_task_definition\" \"my_first_task\" {\r\n  family                   = \"app\" # Naming our first task\r\n  container_definitions    = <<DEFINITION\r\n  [\r\n    {\r\n      \"name\": \"app\",\r\n      \"image\": \"356079734857.dkr.ecr.eu-central-1.amazonaws.com/react:latest\",\r\n      \"essential\": true,\r\n      \"portMappings\": [\r\n        {\r\n          \"containerPort\": 3000,\r\n          \"hostPort\": 3000\r\n        }\r\n      ],\r\n      \"memory\": 512,\r\n      \"cpu\": 256\r\n    }\r\n  ]\r\n  DEFINITION\r\n  requires_compatibilities = [\"FARGATE\"] # Stating that we are using ECS Fargate\r\n  network_mode             = \"awsvpc\"    # Using awsvpc as our network mode as this is required for Fargate\r\n  memory                   = 512         # Specifying the memory our container requires\r\n  cpu                      = 256         # Specifying the CPU our container requires\r\n  execution_role_arn       = aws_iam_role.ecsTaskExecutionRole.arn\r\n}\r\n\r\nresource \"aws_iam_role\" \"ecsTaskExecutionRole\" {\r\n  name               = \"ecsTaskExecutionRole\"\r\n  assume_role_policy = data.aws_iam_policy_document.assume_role_policy.json\r\n}\r\n\r\ndata \"aws_iam_policy_document\" \"assume_role_policy\" {\r\n  statement {\r\n    actions = [\"sts:AssumeRole\"]\r\n\r\n    principals {\r\n      type        = \"Service\"\r\n      identifiers = [\"ecs-tasks.amazonaws.com\"]\r\n    }\r\n  }\r\n}\r\n\r\nresource \"aws_iam_role_policy_attachment\" \"ecsTaskExecutionRole_policy\" {\r\n  role       = aws_iam_role.ecsTaskExecutionRole.name\r\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\"\r\n}\r\n\r\nresource \"aws_alb\" \"application_load_balancer\" {\r\n  name               = \"test-lb-tf\" # Naming our load balancer\r\n  load_balancer_type = \"application\"\r\n  subnets = [ # Referencing the default subnets\r\n    \"${aws_default_subnet.default_subnet_a.id}\",\r\n    \"${aws_default_subnet.default_subnet_b.id}\",\r\n    \"${aws_default_subnet.default_subnet_c.id}\"\r\n  ]\r\n  # Referencing the security group\r\n  security_groups = [\"${aws_security_group.load_balancer_security_group.id}\"]\r\n}\r\n\r\n# Creating a security group for the load balancer:\r\nresource \"aws_security_group\" \"load_balancer_security_group\" {\r\n  ingress {\r\n    from_port   = 80\r\n    to_port     = 80\r\n    protocol    = \"tcp\"\r\n    cidr_blocks = [\"0.0.0.0/0\"] # Allowing traffic in from all sources\r\n  }\r\n\r\n  egress {\r\n    from_port   = 0\r\n    to_port     = 0\r\n    protocol    = \"-1\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n}\r\n\r\nresource \"aws_lb_target_group\" \"target_group\" {\r\n  name        = \"target-group\"\r\n  port        = 80\r\n  protocol    = \"HTTP\"\r\n  target_type = \"ip\"\r\n  vpc_id      = aws_default_vpc.default_vpc.id # Referencing the default VPC\r\n}\r\n\r\nresource \"aws_lb_listener\" \"listener\" {\r\n  load_balancer_arn = aws_alb.application_load_balancer.arn # Referencing our load balancer\r\n  port              = \"80\"\r\n  protocol          = \"HTTP\"\r\n  default_action {\r\n    type             = \"forward\"\r\n    target_group_arn = aws_lb_target_group.target_group.arn # Referencing our target group\r\n  }\r\n}\r\n\r\nresource \"aws_ecs_service\" \"my_first_service\" {\r\n  name            = \"app\"                                     # Naming our first service\r\n  cluster         = aws_ecs_cluster.app.id                    # Referencing our created Cluster\r\n  task_definition = aws_ecs_task_definition.my_first_task.arn # Referencing the task our service will spin up\r\n  launch_type     = \"FARGATE\"\r\n  desired_count   = 3 # Setting the number of containers to 3\r\n\r\n  load_balancer {\r\n    target_group_arn = aws_lb_target_group.target_group.arn # Referencing our target group\r\n    container_name   = aws_ecs_task_definition.my_first_task.family\r\n    container_port   = 3000 # Specifying the container port\r\n  }\r\n\r\n  network_configuration {\r\n    subnets          = [\"${aws_default_subnet.default_subnet_a.id}\", \"${aws_default_subnet.default_subnet_b.id}\", \"${aws_default_subnet.default_subnet_c.id}\"]\r\n    assign_public_ip = true                                                # Providing our containers with public IPs\r\n    security_groups  = [\"${aws_security_group.service_security_group.id}\"] # Setting the security group\r\n  }\r\n}\r\n\r\n\r\nresource \"aws_security_group\" \"service_security_group\" {\r\n  ingress {\r\n    from_port = 0\r\n    to_port   = 0\r\n    protocol  = \"-1\"\r\n    # Only allowing traffic in from the load balancer security group\r\n    security_groups = [\"${aws_security_group.load_balancer_security_group.id}\"]\r\n  }\r\n\r\n  egress {\r\n    from_port   = 0\r\n    to_port     = 0\r\n    protocol    = \"-1\"\r\n    cidr_blocks = [\"0.0.0.0/0\"]\r\n  }\r\n}\r\n\r\nvariable \"AWS_ACCESS_KEY\" {\r\n  description = \"AWS Access Key\"\r\n  type        = string\r\n  default     = \"AKIAVF2ABSBEVOVHXDF7\"\r\n}\r\n\r\nvariable \"AWS_SECRET_KEY\" {\r\n  description = \"AWS Secret Key\"\r\n  type        = string\r\n  default     = \"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\"\r\n}\r\n\r\nvariable \"AWS_REGION\" {\r\n  type    = string\r\n  default = \"eu-central-1\"\r\n}\r\n\r\n\r\n# If the average CPU utilization over a minute drops to this threshold,\r\n# the number of containers will be reduced (but not below ecs_autoscale_min_instances).\r\nvariable \"ecs_as_cpu_low_threshold_per\" {\r\n  default = \"20\"\r\n}\r\n\r\n# If the average CPU utilization over a minute rises to this threshold,\r\n# the number of containers will be increased (but not above ecs_autoscale_max_instances).\r\nvariable \"ecs_as_cpu_high_threshold_per\" {\r\n  default = \"50\"\r\n}\r\n\r\nvariable \"ecs_autoscale_min_instances\" {\r\n  default = \"2\"\r\n}\r\n\r\n# The maximum number of containers that should be running.\r\n# used by both autoscale-perf.tf and autoscale.time.tf\r\nvariable \"ecs_autoscale_max_instances\" {\r\n  default = \"9\"\r\n}\r\n\r\nresource \"aws_cloudwatch_metric_alarm\" \"cpu_utilization_high\" {\r\n  alarm_name          = \"my-first-alert-high-CPU-Utilization-High-${var.ecs_as_cpu_high_threshold_per}\"\r\n  comparison_operator = \"GreaterThanOrEqualToThreshold\"\r\n  evaluation_periods  = \"1\"\r\n  metric_name         = \"CPUUtilization\"\r\n  namespace           = \"AWS/ECS\"\r\n  period              = \"60\"\r\n  statistic           = \"Average\"\r\n  threshold           = var.ecs_as_cpu_high_threshold_per\r\n\r\n  dimensions = {\r\n    ClusterName = aws_ecs_cluster.app.name\r\n    ServiceName = aws_ecs_service.my_first_service.name\r\n  }\r\n\r\n  alarm_actions = [aws_appautoscaling_policy.app_up.arn]\r\n}\r\n\r\nresource \"aws_cloudwatch_metric_alarm\" \"cpu_utilization_low\" {\r\n  alarm_name          = \"my-first-alert-low-CPU-Utilization-Low-${var.ecs_as_cpu_low_threshold_per}\"\r\n  comparison_operator = \"LessThanThreshold\"\r\n  evaluation_periods  = \"1\"\r\n  metric_name         = \"CPUUtilization\"\r\n  namespace           = \"AWS/ECS\"\r\n  period              = \"60\"\r\n  statistic           = \"Average\"\r\n  threshold           = var.ecs_as_cpu_low_threshold_per\r\n\r\n  dimensions = {\r\n    ClusterName = aws_ecs_cluster.app.name\r\n    ServiceName = aws_ecs_service.my_first_service.name\r\n  }\r\n\r\n  alarm_actions = [aws_appautoscaling_policy.app_down.arn]\r\n}\r\n\r\nresource \"aws_appautoscaling_policy\" \"app_up\" {\r\n  name               = \"app-scale-up\"\r\n  service_namespace  = aws_appautoscaling_target.app_scale_target.service_namespace\r\n  resource_id        = aws_appautoscaling_target.app_scale_target.resource_id\r\n  scalable_dimension = aws_appautoscaling_target.app_scale_target.scalable_dimension\r\n\r\n\r\n  step_scaling_policy_configuration {\r\n    adjustment_type         = \"ChangeInCapacity\"\r\n    cooldown                = 81\r\n    metric_aggregation_type = \"Average\"\r\n\r\n    step_adjustment {\r\n      metric_interval_lower_bound = 0\r\n      scaling_adjustment          = 1\r\n    }\r\n  }\r\n}\r\n\r\nresource \"aws_appautoscaling_policy\" \"app_down\" {\r\n  name               = \"app-scale-down\"\r\n  service_namespace  = aws_appautoscaling_target.app_scale_target.service_namespace\r\n  resource_id        = aws_appautoscaling_target.app_scale_target.resource_id\r\n  scalable_dimension = aws_appautoscaling_target.app_scale_target.scalable_dimension\r\n\r\n  step_scaling_policy_configuration {\r\n    adjustment_type         = \"ChangeInCapacity\"\r\n    cooldown                = 300\r\n    metric_aggregation_type = \"Average\"\r\n\r\n    step_adjustment {\r\n      metric_interval_upper_bound = 0\r\n      scaling_adjustment          = -1\r\n    }\r\n  }\r\n}\r\n\r\n\r\nresource \"aws_appautoscaling_target\" \"app_scale_target\" {\r\n  service_namespace  = \"ecs\"\r\n  resource_id        = \"service/${aws_ecs_cluster.app.name}/${aws_ecs_service.my_first_service.name}\"\r\n  scalable_dimension = \"ecs:service:DesiredCount\"\r\n  max_capacity       = var.ecs_autoscale_max_instances\r\n  min_capacity       = var.ecs_autoscale_min_instances\r\n}\r\n\r\nresource \"aws_cloudwatch_dashboard\" \"cloudwatch_dashboard\" {\r\n  dashboard_name = \"my-fargate\"\r\n  dashboard_body = <<EOF\r\n{\"widgets\":[{\"type\":\"metric\",\"x\":12,\"y\":6,\"width\":12,\"height\":6,\"properties\"{\"view\":\"timeSeries\",\"stacked\":false,\r\n\r\n\"metrics\":[[\"AWS/ECS\",\"MemoryUtilization\",\"ServiceName\",\"app\",\"ClusterName\",\"app-cluster\",{\"color\":\"#1f77b4\"}],[\".\",\"CPUUtilization\",\".\",\".\",\".\",\".\",{\"color\":\"#9467bd\"}]],\"region\":\"${var.AWS_REGION}\",\"period\":300,\"title\":\"Memory and CPU utilization\",\"yAxis\":{\"left\":{\"min\":0,\"max\":100}}}},\r\n\r\n{\"type\":\"metric\",\"x\":0,\"y\":6,\"width\":12,\"height\":6,\"properties\":{\"view\":\"timeSeries\",\"stacked\":true,\"metrics\":[[\"AWS/ApplicationELB\",\"HTTPCode_Target_5XX_Count\",\"TargetGroup\",\"${aws_lb_target_group.target_group.arn_suffix}\",\"LoadBalancer\",\"${aws_alb.application_load_balancer.arn_suffix}\",{\"period\":60,\"color\":\"#d62728\",\"stat\":\"Sum\"}],[\".\",\"HTTPCode_Target_4XX_Count\",\".\",\".\",\".\",\".\",{\"period\":60,\"stat\":\"Sum\",\"color\":\"#bcbd22\"}],[\".\",\"HTTPCode_Target_3XX_Count\",\".\",\".\",\".\",\".\",{\"period\":60,\"stat\":\"Sum\",\"color\":\"#98df8a\"}],[\".\",\"HTTPCode_Target_2XX_Count\",\".\",\".\",\".\",\".\",{\"period\":60,\"stat\":\"Sum\",\"color\":\"#2ca02c\"}]],\"region\":\"${var.AWS_REGION}\",\"title\":\"Container responses\",\"period\":300,\"yAxis\":{\"left\":{\"min\":0}}}},\r\n\r\n\r\n{\"type\":\"metric\",\"x\":12,\"y\":0,\"width\":12,\"height\":6,\"properties\":{\"view\":\"timeSeries\",\"stacked\":false,\"metrics\":[[\"AWS/ApplicationELB\",\"TargetResponseTime\",\"LoadBalancer\",\"${aws_alb.application_load_balancer.arn_suffix}\",{\"period\":60,\"stat\":\"p50\"}],[\"...\",{\"period\":60,\"stat\":\"p90\",\"color\":\"#c5b0d5\"}],[\"...\",{\"period\":60,\"stat\":\"p99\",\"color\":\"#dbdb8d\"}]],\"region\":\"${var.AWS_REGION}\",\"period\":300,\"yAxis\":{\"left\":{\"min\":0,\"max\":3}},\"title\":\"Container response times\"}},\r\n\r\n\r\n{\"type\":\"metric\",\"x\":12,\"y\":12,\"width\":12,\"height\":2,\"properties\":{\"view\":\"singleValue\",\"metrics\":[[\"AWS/ApplicationELB\",\"HealthyHostCount\",\"TargetGroup\",\"${aws_lb_target_group.target_group.arn_suffix}\",\"LoadBalancer\",\"${aws_alb.application_load_balancer.arn_suffix}\",{\"color\":\"#2ca02c\",\"period\":60}],[\".\",\"UnHealthyHostCount\",\".\",\".\",\".\",\".\",{\"color\":\"#d62728\",\"period\":60}]],\"region\":\"${var.AWS_REGION}\",\"period\":300,\"stacked\":false}},\r\n\r\n\r\n{\"type\":\"metric\",\"x\":0,\"y\":0,\"width\":12,\"height\":6,\"properties\":{\"view\":\"timeSeries\",\"stacked\":true,\"metrics\":[[\"AWS/ApplicationELB\",\"HTTPCode_Target_5XX_Count\",\"LoadBalancer\",\"${aws_alb.application_load_balancer.arn_suffix}\",{\"period\":60,\"stat\":\"Sum\",\"color\":\"#d62728\"}],[\".\",\"HTTPCode_Target_4XX_Count\",\".\",\".\",{\"period\":60,\"stat\":\"Sum\",\"color\":\"#bcbd22\"}],[\".\",\"HTTPCode_Target_3XX_Count\",\".\",\".\",{\"period\":60,\"stat\":\"Sum\",\"color\":\"#98df8a\"}],[\".\",\"HTTPCode_Target_2XX_Count\",\".\",\".\",{\"period\":60,\"stat\":\"Sum\",\"color\":\"#2ca02c\"}]],\"region\":\"${var.AWS_REGION}\",\"title\":\"Load balancer responses\",\"period\":300,\"yAxis\":{\"left\":{\"min\":0}}}}]}\r\nEOF\r\n}\r\n\r\n"}]}
{"messages": [{"role": "user", "content": "Create an Equinix provider configuration using your client ID and secret. Configure the Google Cloud Platform provider with your project ID and region. Retrieve an existing Equinix Metal project by its project ID. Create a new VLAN in Frankfurt with a specific metro code and description. Request a connection service token in Equinix Metal and configure the corresponding Equinix Fabric connection to Google Cloud Platform, incorporating redundancy settings as needed."}, {"role": "assistant", "content": "\n#File: main.tf\n# Configure the Equinix Provider\n# Please refer to provider documentation for details on supported authentication methods and parameters.\n# https://registry.terraform.io/providers/equinix/equinix/latest/docs\nprovider \"equinix\" {\n  client_id     = var.equinix_provider_client_id\n  client_secret = var.equinix_provider_client_secret\n}\n\n# Configure the Google Cloud Platform Provider\n# https://registry.terraform.io/providers/hashicorp/google/latest/docs/guides/getting_started#adding-credentials\nprovider \"google\" {\n  project = var.gcp_project\n  region  = var.gcp_region\n}\n\n## Retrieve an existing equinix metal project\n## If you prefer you can use resource equinix_metal_project instead to create a fresh project\ndata \"equinix_metal_project\" \"this\" {\n  project_id = var.metal_project_id\n}\n\nlocals {\n  connection_name = format(\"conn-metal-gcp-%s\", lower(var.fabric_destination_metro_code))\n}\n\n# Create a new VLAN in Frankfurt\nresource \"equinix_metal_vlan\" \"this\" {\n  description = format(\"VLAN in %s\", var.fabric_destination_metro_code)\n  metro       = var.fabric_destination_metro_code\n  project_id  = data.equinix_metal_project.this.project_id\n}\n\n## Request a connection service token in Equinix Metal\nresource \"equinix_metal_connection\" \"this\" {\n    name               = local.connection_name\n    project_id         = data.equinix_metal_project.this.project_id\n    metro              = var.fabric_destination_metro_code\n    redundancy         = var.redundancy_type == \"SINGLE\" ? \"primary\" : \"redundant\"\n    type               = \"shared\"\n    service_token_type = \"a_side\"\n    description        = format(\"connection to GCP in %s\", var.fabric_destination_metro_code)\n    speed              = format(\"%dMbps\", var.fabric_speed)\n    vlans              = [equinix_metal_vlan.this.vxlan]\n}\n\n## Configure the Equinix Fabric connection from Equinix Metal to GCP using the metal connection service token\nmodule \"equinix-fabric-connection-gcp-primary\" {\n  source = \"equinix-labs/fabric-connection-gcp/equinix\"\n\n  fabric_notification_users     = var.fabric_notification_users\n  fabric_connection_name        = local.connection_name\n  fabric_destination_metro_code = var.fabric_destination_metro_code\n  fabric_speed                  = var.fabric_speed\n  fabric_service_token_id       = equinix_metal_connection.this.service_tokens.0.id\n\n  # gcp_project = var.gcp_project_name // if unspecified, the project configured in the provided block will be used\n  gcp_availability_domain = 1\n\n  gcp_gcloud_skip_download = false\n  platform                 = var.platform\n\n  ## BGP config\n  gcp_configure_bgp             = true\n  # gcp_interconnect_customer_asn = // If unspecified, default value \"65000\" will be used\n}\n\n## If redundancy_type is REDUNDANT, configure a secondary Equinix Fabric connection from Equinix Metal to GCP\n## using the metal connection service token\nmodule \"equinix-fabric-connection-gcp-secondary\" {\n  source = \"equinix-labs/fabric-connection-gcp/equinix\"\n\n  count = var.redundancy_type == \"REDUNDANT\" ? 1 : 0\n\n  fabric_notification_users     = var.fabric_notification_users\n  fabric_connection_name        = local.connection_name\n  fabric_destination_metro_code = var.fabric_destination_metro_code\n  fabric_speed                  = var.fabric_speed\n  fabric_service_token_id       = equinix_metal_connection.this.service_tokens.1.id\n  \n  gcp_availability_domain   = 2\n  gcp_compute_create_router = false // we use the same cloud router of the primary connection\n  gcp_compute_router_name   = module.equinix-fabric-connection-gcp-primary.gcp_cloud_router_name\n\n  gcp_gcloud_skip_download = true\n  platform                 = var.platform\n\n  ## BGP config\n  gcp_configure_bgp             = true\n  # gcp_interconnect_customer_asn = // If unspecified, default value \"65000\" will be used\n}\n\n#File: outputs.tf\noutput \"connection_primary_details\" {\n  value = module.equinix-fabric-connection-gcp-primary\n}\n\noutput \"connection_secondary_details\" {\n  value = var.redundancy_type == \"REDUNDANT\" ? module.equinix-fabric-connection-gcp-secondary : null\n}\n\n#File: variables.tf\nvariable \"equinix_provider_client_id\" {\n  type        = string\n  description = <<EOF\n  API Consumer Key available under 'My Apps' in developer portal. This argument can also be specified with the\n  EQUINIX_API_CLIENTID shell environment variable.\n  EOF\n  default     = null\n}\n\nvariable \"equinix_provider_client_secret\" {\n  type        = string\n  description = <<EOF\n  API Consumer secret available under 'My Apps' in developer portal. This argument can also be specified with the\n  EQUINIX_API_CLIENTSECRET shell environment variable.\n  EOF\n  default     = null\n}\n\nvariable \"gcp_project\" {\n  type        = string\n  description = \"(Required) ID of the GCP project to manage resources in.\"\n}\n\nvariable \"gcp_region\" {\n  type        = string\n  description = <<EOF\n  The region in which the GCP resources and the Equinix port for GCP resides, i.e. 'us-west2'. If unspecified, this\n  defaults to the region configured in the google provider.\n  \n  NOTE: 'var.gcp_region' and 'var.fabric_destination_metro_code' must correspond to same location.\"\n  EOF\n  default     = \"us-west2\" // Corresponds to Silicon Valley (SV) and Los Angeles (LA).\n}\n\nvariable \"metal_project_id\" {\n  type        = string\n  description = \"ID of the project where the connection is scoped to, used to look up the project.\"\n}\n\nvariable \"fabric_notification_users\" {\n  type        = list(string)\n  description = \"A list of email addresses used for sending connection update notifications.\"\n  default = [\"example@equinix.com\"]\n}\n\nvariable \"fabric_destination_metro_code\" {\n  type        = string\n  description = \"Destination Metro code where the connection will be created.\"\n  default     = \"SV\" // Corresponds to Silicon Valley\n}\n\nvariable \"fabric_speed\" {\n  type        = number\n  description = <<EOF\n  Speed/Bandwidth in Mbps to be allocated to the connection. If unspecified, it will be used the minimum\n  bandwidth available for the `Equinix Metal` service profile. Valid values are\n  (50, 100, 200, 500, 1000, 2000, 5000, 10000).\n  EOF\n  default     = 50\n}\n\nvariable \"redundancy_type\" {\n  type        = string\n  description = \"Whether to create a 'SINGLE' connection or 'REDUNDANT'.\"\n  default     = \"REDUNDANT\"\n}\n\nvariable \"platform\" {\n  type        = string\n  description = <<EOF\n  (Required) Platform this terraform module will run on. One of: linux, darwin.\n  \n  NOTE: Configuration of the bgp customer ASN in google side is not directly supported with current google terraform\n  provider (v3.72.0). As a workaround this module take advantage of 'terraform-google-gcloud' module which allows use\n  gcloud. However, it is only available for `linux` and `darwin` based operating systems.\n  EOF\n}\n\n#File: versions.tf\nterraform {  \n  required_version = \">= 0.13\"\n\n  required_providers {\n    equinix = {\n      source  = \"equinix/equinix\"\n      version = \"~> 1.14\"\n    }\n    google = {\n      source  = \"hashicorp/google\"\n      version = \">= 3.72.0\"\n    }\n  }\n}\n"}]}
{"messages": [{"role": "user", "content": "Create a Google Cloud SQL database instance with PostgreSQL 13 and deletion protection. Define a SQL user with a username and password, and create a database linked to the instance. Deploy a Cloud Run service that uses a specified container image and exposes port 4567, while setting environment variables for database connection. Grant the `roles/run.invoker` role to all users on the Cloud Run service. Output the URL of the deployed Cloud Run service."}, {"role": "assistant", "content": "\n#File: main.tf\nterraform {\n  required_providers {\n    google = {\n      source  = \"hashicorp/google\"\n      version = \"4.58.0\"\n    }\n  }\n}\n\nprovider \"google\" {\n  credentials = file(var.google_key_file)\n\n  project = var.project_id\n  region  = \"asia-southeast1\"\n  zone    = \"asia-southeast1-a\"\n}\n\nresource \"google_cloud_run_service\" \"default\" {\n  name     = \"cloud-run-app-h96sfah4j6\"\n  location = \"asia-southeast1\"\n\n  template {\n    spec {\n      containers {\n        image = var.container_image\n        ports {\n          container_port = 4567\n        }\n\n        env {\n          name  = \"DATABASE_URL\"\n          value = \"postgresql:///${var.db_name}?host=/cloudsql/${var.project_id}:asia-southeast1:${var.db_instance_name}&user=${var.db_username}&password=${var.db_password}\"\n        }\n      }\n    }\n\n    metadata {\n      annotations = {\n        \"autoscaling.knative.dev/maxScale\"      = \"2\"\n        \"run.googleapis.com/cloudsql-instances\" = google_sql_database_instance.instance.connection_name\n        \"run.googleapis.com/client-name\"        = \"terraform\"\n      }\n    }\n  }\n  autogenerate_revision_name = true\n}\n\nresource \"google_cloud_run_service_iam_member\" \"allUsers\" {\n  provider = google\n  service  = google_cloud_run_service.default.name\n  location = google_cloud_run_service.default.location\n  role     = \"roles/run.invoker\"\n  member   = \"allUsers\"\n}\n\nresource \"google_sql_database_instance\" \"instance\" {\n  name             = var.db_instance_name\n  region           = \"asia-southeast1\"\n  database_version = \"POSTGRES_13\"\n  settings {\n    tier = \"db-f1-micro\"\n  }\n\n  deletion_protection = \"true\"\n}\n\nresource \"google_sql_database\" \"database\" {\n  name     = var.db_name\n  instance = google_sql_database_instance.instance.name\n}\n\nresource \"google_sql_user\" \"users\" {\n  name     = var.db_username\n  password = var.db_password\n  instance = google_sql_database_instance.instance.name\n}\n\n#File: outputs.tf\noutput \"url\" {\n  value = google_cloud_run_service.default.status[0].url\n}\n\n#File: variables.tf\nvariable \"project_id\" {\n  description = \"Google Cloud Platform Service Project ID\"\n  type        = string\n  sensitive   = true\n}\n\nvariable \"google_key_file\" {\n  description = \"Path to Google Cloud Platform Service Account JSON key file\"\n  type        = string\n  sensitive   = true\n}\n\n# TODO: Re-evaluate if this is considered sensitive\nvariable \"container_image\" {\n  description = \"Container image to deploying into Cloud Run\"\n  type        = string\n  sensitive   = true\n}\n\nvariable \"db_instance_name\" {\n  type    = string\n  default = \"cloudrun-sql\"\n}\n\nvariable \"db_name\" {\n  description = \"Database username\"\n  type        = string\n  default     = \"sinatra_to_sequel_database\"\n}\n\nvariable \"db_username\" {\n  description = \"Database username\"\n  type        = string\n  sensitive   = true\n}\n\nvariable \"db_password\" {\n  description = \"Database password\"\n  type        = string\n  sensitive   = true\n}\n"}]}
{"messages": [{"role": "user", "content": "Create a Google Compute Engine instance with the specified machine type and boot disk image. Set up a backend service that uses this instance with HTTP protocol and configure health checks for it. Establish firewall rules to allow TCP traffic on ports 22, 80, and 443, and restrict access based on defined source ranges. Define a network with multiple subnets and a router for Cloud NAT functionalities. Output the assigned IP address from the global forwarding rule for further use."}, {"role": "assistant", "content": "\n#File: compute.tf\n\n# https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_instance\nresource \"google_compute_instance\" \"vm1\" {\n  name                      = \"vm1-${var.instance_id}\"\n  machine_type              = var.gcp_vms_size\n  zone                      = data.google_compute_zones.available.names[0]\n  allow_stopping_for_update = true\n  boot_disk {\n    initialize_params {\n      image = var.gcp_os_r\n    }\n  }\n\n  metadata = {\n    serial-port-logging-enable = \"TRUE\"\n    serial-port-enable         = true\n    startup-script-url = \"https://raw.githubusercontent.com/ibenrodriguez/iac-demo-gcp/main/init_os_redhat_deps.sh\"\n  }\n\n  network_interface {\n    subnetwork = google_compute_subnetwork.subnet1.name\n/*     access_config {\n     // Include this section to give the VM an external ip address\n   } */\n  }\n}\n\n# Backend service\n# https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_backend_service\nresource \"google_compute_backend_service\" \"website\" {\n  name                  = \"backend-service-${var.instance_id}\"\n  description           = \"backend-service-${var.instance_id}\"\n  protocol              = \"HTTP\"\n  port_name             = \"http\"\n # port_name - Name of backend port. The same name should appear in the instance groups referenced by this service.  \n  load_balancing_scheme = \"EXTERNAL\"\n  enable_cdn            = false\n  timeout_sec           = 10\n  security_policy       = google_compute_security_policy.security-policy-1.id\n # custom_request_headers   = [\"X-Client-Geo-Location: {client_region_subdivision}, {client_city}\"]\n # custom_response_headers  = [\"X-Cache-Hit: {cdn_cache_status}\"]\n  health_checks = [google_compute_health_check.health.id]\n\n  backend {\n    group           = google_compute_instance_group_manager.default.instance_group\n    balancing_mode  = \"UTILIZATION\"\n    capacity_scaler = 1.0\n  }\n\n}\n\n# https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_firewall\nresource \"google_compute_firewall\" \"allow-tcp\" {\n  name    = \"allow-tcp-armor-firewall-${var.instance_id}\"\n  network = google_compute_network.gcp-network.id\n\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"80\", \"443\"]\n  }\n  source_ranges = [\"0.0.0.0/0\"]\n    log_config {\n    metadata = \"INCLUDE_ALL_METADATA\"\n  }\n}\n\n# https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_firewall\nresource \"google_compute_firewall\" \"allow-ssh\" {\n  name      = \"allow-ssh-firewall-${var.instance_id}\"\n  network   = google_compute_network.gcp-network.id\n  direction = \"INGRESS\"\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"22\"]\n  }\n  source_ranges = [\"0.0.0.0/0\"]\n\n    log_config {\n    metadata = \"INCLUDE_ALL_METADATA\"\n  }\n}\nresource \"google_compute_firewall\" \"default-allow-health-check\" {\n  name          = \"default-allow-health-check\"\n  description   = \"default-allow-health-check\"\n  direction     = \"INGRESS\"\n  network       = google_compute_network.gcp-network.id\n  source_ranges = [\"130.211.0.0/22\", \"35.191.0.0/16\"]\n  allow {\n    protocol = \"tcp\"\n#    ports    = [\"22\",\"80\",\"443\"]\n\n  }\n  target_tags = [\"allow-health-check\",\"http-server\"]\n    log_config {\n    metadata = \"INCLUDE_ALL_METADATA\"\n  }\n}\n\n/* resource \"google_compute_firewall\" \"allow-ssh-eg\" {\n  name      = \"allow-ssh-firewall-eg-${var.instance_id}\"\n  description      = \"allow-ssh-firewall-eg-${var.instance_id}\"\n\n  network   = google_compute_network.gcp-network.id\n  direction = \"INGRESS\"\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"22\"]\n  }\n} */\nresource \"google_compute_firewall\" \"default-eg\" {\n  name          = \"allow-tcp-armor-eg-firewall\"\n  description   = \"allow-tcp-armor-eg-firewall\"\n\n  direction     = \"EGRESS\"\n  network       = google_compute_network.gcp-network.id\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"80\", \"443\"]\n  }\n  target_tags = [\"allow-health-check\",\"http-server\"]\n}\n\n\n# https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_http_health_check\n\nresource \"google_compute_health_check\" \"health\" {\n  check_interval_sec = \"5\"\n  healthy_threshold  = \"2\"\n\n  name          = \"tcp-http-health-check-${var.instance_id}\"\n  description   = \"tcp-http-health-check-${var.instance_id}\"\n\n  tcp_health_check {\n    port         = \"80\"\n    proxy_header = \"NONE\"\n }\n\n#http_health_check {\n#   request_path = \"/\"\n#    port         = \"80\"\n#}\n# https://cloud.google.com/load-balancing/docs/https/ext-http-lb-tf-module-examples\n#        log_config = {\n#        enable      = true\n#        sample_rate = 1.0\n#      }\n  timeout_sec         = \"5\"\n  unhealthy_threshold = \"2\"\n}\n\n\n\n# https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_global_forwarding_rule\nresource \"google_compute_global_forwarding_rule\" \"default\" {\n  name       = \"armor-rule-${var.instance_id}\"\n  target     = google_compute_target_http_proxy.default.id\n  ip_protocol           = \"TCP\"\n  load_balancing_scheme = \"EXTERNAL\"\n  port_range            = \"80\"\n}\n\n# https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_target_http_proxy\nresource \"google_compute_target_http_proxy\" \"default\" {\n  name    = \"armor-proxy-${var.instance_id}\"\n  url_map = google_compute_url_map.default.id\n}\n\n# https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_url_map\nresource \"google_compute_url_map\" \"default\" {\n  name            = \"armor-url-map-${var.instance_id}\"\n  default_service = google_compute_backend_service.website.id\n\n  # host_rule {\n  #   hosts        = [\"*\"]\n  #   path_matcher = \"allpaths\"\n  # }\n\n  # path_matcher {\n  #   name            = \"allpaths\"\n  #   default_service = google_compute_backend_service.website.self_link\n\n  #   path_rule {\n  #     paths   = [\"/*\"]\n  #     service = google_compute_backend_service.website.self_link\n  #   }\n  # }\n}\n#File: main.tf\nresource \"random_id\" \"IKEv2\" {\n  byte_length = 4\n}\n\nprovider \"google\" {\n  project = \"${var.gcp_project_id}\"\n  region  = \"${var.gcp_region}\"\n  credentials = \"${var.GCP_SA_IAC_KEY}\"\n}\n\nprovider \"template\" {}\n\n#File: mig.tf\n# Instance template\n# https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_instance_template\nresource \"google_compute_instance_template\" \"vm2\" {\n  name         = \"inst-tmpl-${var.instance_id}\"\n  description  = \"instance template ${var.instance_id}\"\n  machine_type = var.gcp_vms_size\n  tags         = [\"http-server\",\"allow-health-check\",\"http\"]\n\n  network_interface {\n    network    = google_compute_network.gcp-network.id\n    subnetwork = google_compute_subnetwork.subnet3.id\n/*        access_config {\n     // Include this section to give the VM an external ip address\n   } */\n\n  }\n  disk {\n    source_image = var.gcp_os_r\n    auto_delete  = true\n    boot         = true\n  }\n\n  # install apache and serve a simple web page\n  metadata = {\n    serial-port-enable = true\n    serial-port-logging-enable = \"TRUE\"\n    startup-script-url  =  \"https://raw.githubusercontent.com/ibenrodriguez/iac-demo-gcp/main/init_os_redhat_deps_apache.sh\"\n  }\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n# resource \"google_compute_health_check\" \"autohealing\" {\n#   name                = \"autohealing-health-check\"\n#   check_interval_sec  = 5\n#   timeout_sec         = 5\n#   healthy_threshold   = 2\n#   unhealthy_threshold = 10 # 50 seconds\n#  http_health_check {\n#    request_path = \"/\"\n#    port         = \"80\"\n#  }\n#}\n\n# https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_instance_group_manager\nresource \"google_compute_instance_group_manager\" \"default\" {\n  name          = \"mig-${var.instance_id}\"\n  description   = \"mig-${var.instance_id}\"\n\n  zone   = data.google_compute_zones.available.names[0]\n\n  version {\n    instance_template = google_compute_instance_template.vm2.id\n    name              = \"primary\"\n  }\n  named_port {\n    name = \"http\"\n    port = 80\n  }\n  base_instance_name = \"vm\"\n  target_size        = 1\n  \n#    auto_healing_policies {\n#    health_check      = google_compute_health_check.autohealing.id\n#    initial_delay_sec = 300\n#  }\n\n}\n\n#File: network.tf\n# https://registry.terraform.io/providers/hashicorp/google/latest/docs/data-sources/compute_zones\ndata \"google_compute_zones\" \"available\" {}\n\n# https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_network\nresource \"google_compute_network\" \"gcp-network\" {\n  name                    = \"gcp-network-${var.instance_id}\"\n  auto_create_subnetworks = \"false\"\n}\n\n# https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_subnetwork\nresource \"google_compute_subnetwork\" \"subnet1\" {\n  name          = \"subnet1-${var.instance_id}\"\n  ip_cidr_range = var.gcp_subnet1\n  network       = google_compute_network.gcp-network.name\n  region        = var.gcp_region\n}\n\nresource \"google_compute_subnetwork\" \"subnet2\" {\n  name          = \"subnet2-${var.instance_id}\"\n  ip_cidr_range = var.gcp_subnet2\n  network       = google_compute_network.gcp-network.name\n  region        = var.gcp_region\n}\n\nresource \"google_compute_subnetwork\" \"subnet3\" {\n  name                     = \"subnet3-${var.instance_id}\"\n  ip_cidr_range            = var.gcp_subnet3\n  network                  = google_compute_network.gcp-network.name\n  region                   = var.gcp_region\n}\n\nresource \"google_compute_subnetwork\" \"subnet4\" {\n  name                     = \"subnet4-${var.instance_id}\"\n  ip_cidr_range            = var.gcp_subnet4\n  network                  = google_compute_network.gcp-network.name\n  region                   = var.gcp_region\n}\n\n# Router and Cloud NAT are required for installing packages from repos (apache, php etc)\nresource \"google_compute_router\" \"group1\" {\n  name    = \"gw-group1\"\n  network = google_compute_network.gcp-network.self_link\n  region  = var.gcp_region\n}\n\nmodule \"cloud-nat-group1\" {\n  source     = \"terraform-google-modules/cloud-nat/google\"\n  version    = \"1.4.0\"\n  router     = google_compute_router.group1.name\n  project_id = var.gcp_project_id\n  region     = var.gcp_region\n  name       = \"cloud-nat-group1\"\n}\n\n#File: output.tf\noutput \"ip\" {\n  value = google_compute_global_forwarding_rule.default.ip_address\n}\n\n#File: security.tf\n# resource \"google_compute_firewall\" \"debug\" {\n#   name    = \"debug-firewall-${var.instance_id}\"\n#   network = \"${google_compute_network.gcp-network.name}\"\n\n#   allow {\n#     protocol = \"icmp\"\n#   }\n\n#   allow {\n#     protocol = \"tcp\"\n#   }\n\n#   source_tags   = [\"ssh\"]\n#   source_ranges = [\"0.0.0.0/0\"]\n# }\n\n# resource \"google_compute_firewall\" \"gcp-allow-vpn\" {\n#   name    = \"${google_compute_network.gcp-network.name}-gcp-allow-vpn-${var.instance_id}\"\n#   network = \"${google_compute_network.gcp-network.name}\"\n\n#   allow {\n#     protocol = \"tcp\"\n#     ports    = [\"0-65535\"]\n#   }\n\n#   allow {\n#     protocol = \"udp\"\n#     ports    = [\"0-65535\"]\n#   }\n\n#   allow {\n#     protocol = \"all\"\n#   }\n#   source_ranges = [\n#     \"${var.aws_subnet_vpn}\",\n#     \"${var.azure_vpc}\"\n#   ]\n# }\n\n#File: security_policy.tf\n# Cloud Armor Security policies\n# https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_security_policy\nresource \"google_compute_security_policy\" \"security-policy-1\" {\n  name        = \"armor-security-policy-${var.instance_id}\"\n  description = \"example security policy\"\n\n# Reject all traffic that hasn't been whitelisted.\nrule {\n  action   = \"deny(403)\"\n  priority = \"2147483647\"\n  match {\n    versioned_expr = \"SRC_IPS_V1\"\n    config {\n      src_ip_ranges = [\"*\"]\n      }\n#    description = \"Default rule, higher priority overrides it\"\n    }\n}\n\n# Whitelist traffic from certain ip address\n  rule {\n    action   = \"allow\"\n    priority = \"1000\"\n    match {\n      versioned_expr = \"SRC_IPS_V1\"\n      config {\n        src_ip_ranges = var.ip_white_list\n      }\n    }\n#  description = \"allow traffic\"\n  }\n}\n#File: variables.tf\nvariable \"gcp_project_id\" {\n  description = \"GCP Project ID\"\n  type        = string\n}\nvariable \"gcp_region\" {\n  description = \"GCP Region\"\n  type        = string\n}\nvariable \"GCP_SA_IAC_KEY\" {\n  description = \"GCP Service Account\"\n  type        = string\n}\nvariable \"gcp_subnet1\" {\n  default = \"10.0.0.0/24\"\n  type    = string\n}\nvariable \"gcp_subnet2\" {\n  default = \"10.0.10.0/24\"\n  type    = string\n}\nvariable \"gcp_subnet3\" {\n  default = \"10.0.20.0/24\"\n  type    = string\n}\nvariable \"gcp_subnet4\" {\n  default = \"10.0.30.0/24\"\n  type    = string\n}\nvariable \"gcp_vms_size\" {\n  type    = string\n}\nvariable \"gcp_os_r\" {\n  default = \"rhel-8\"\n  type    = string\n}\nvariable \"instance_id\" {\n  default = \"test-vzxy-01\"\n  type    = string\n}\n\nvariable \"ip_white_list\" {\n  description = \"A list of ip addresses that can be white listed through security policies\"\n  default     = [\"192.0.2.0/24\", \"0.0.0.0/0\"]\n}\n"}]}
{"messages": [{"role":"user","content":"Create Terraform configuration that deploys an AWS Lambda function that monitors IAM policy attachments via CloudTrail and deactivates compromised access keys when the AWSCompromisedKeyQuarantineV2 policy is attached. Include resources for packaging the Lambda code, creating IAM roles and policies, configuring CloudWatch event triggers, logging, and permissions for automated event-driven execution."},{"role":"assistant","content":"variable \"aws_region\" {\r\n  default = \"us-east-1\"\r\n}\r\n\r\nvariable \"aws_profile\" {\r\n}\r\n\r\n\r\n\r\n# Provider configuration for AWS\r\nprovider \"aws\" {\r\n  region = var.aws_region # Dynamically set the region from a variable\r\n  profile = var.aws_profile # Uses a specific AWS profile from your configuration\r\n}\r\n\r\n\r\n\r\n# Provider for generating random strings\r\nprovider \"random\" {}\r\n\r\n# Fetch current AWS account details\r\ndata \"aws_caller_identity\" \"current\" {}\r\n\r\n# Generate a random string for creating unique names\r\nresource \"random_string\" \"random\" {\r\n  length  = 8\r\n  special = false\r\n  upper   = false\r\n}\r\n\r\n# Package the Lambda function code into a ZIP file\r\ndata \"archive_file\" \"lambda\" {\r\n  type        = \"zip\"\r\n  source_file = \"${path.module}/lambda_function.py\"\r\n  output_path = \"${path.module}/lambda_function_payload.zip\"\r\n}\r\n\r\n# IAM role for Lambda function with a unique name\r\nresource \"aws_iam_role\" \"lambda_execution_role\" {\r\n  name = \"lambda_execution_role-${random_string.random.result}\"\r\n\r\n  # IAM policy that allows the Lambda function to assume this role\r\n  assume_role_policy = jsonencode({\r\n    Statement = [\r\n      {\r\n        Action = \"sts:AssumeRole\"\r\n        Effect = \"Allow\"\r\n        Principal = {\r\n          Service = \"lambda.amazonaws.com\"\r\n        }\r\n      },\r\n    ]\r\n  })\r\n}\r\n\r\n# IAM policy attached to the Lambda role\r\nresource \"aws_iam_role_policy\" \"lambda_policy\" {\r\n  name = \"lambda_policy-${random_string.random.result}\"\r\n  role = aws_iam_role.lambda_execution_role.id\r\n\r\n  # Policy definitions for logging and IAM access\r\n  policy = jsonencode({\r\n    Statement = [\r\n      {\r\n        Action = [\r\n          \"logs:CreateLogGroup\",\r\n          \"logs:CreateLogStream\",\r\n          \"logs:PutLogEvents\"\r\n        ],\r\n        Effect = \"Allow\",\r\n        Resource = \"arn:aws:logs:${var.aws_region}:${data.aws_caller_identity.current.account_id}:log-group:/aws/lambda/${aws_lambda_function.iam_access_key_deactivator.function_name}:*\"\r\n      },\r\n      {\r\n        Action = [\r\n          \"iam:UpdateAccessKey\",\r\n          \"iam:ListAccessKeys\"\r\n        ],\r\n        Effect = \"Allow\",\r\n        Resource = \"*\"\r\n      }\r\n    ]\r\n  })\r\n}\r\n\r\n# Lambda function resource\r\nresource \"aws_lambda_function\" \"iam_access_key_deactivator\" {\r\n  filename         = \"lambda_function_payload.zip\"\r\n  function_name    = \"iam_access_key_deactivator-${random_string.random.result}\"\r\n  role             = aws_iam_role.lambda_execution_role.arn\r\n  handler          = \"lambda_function.lambda_handler\"\r\n  runtime          = \"python3.8\"\r\n\r\n  source_code_hash = filebase64sha256(data.archive_file.lambda.output_path)\r\n}\r\n\r\n# CloudWatch Event Rule to trigger Lambda on IAM policy attachments\r\nresource \"aws_cloudwatch_event_rule\" \"iam_policy_attachment\" {\r\n  name        = \"iam-policy-attachment-${random_string.random.result}\"\r\n  description = \"Monitors IAM policy attachments.\"\r\n\r\n  event_pattern = jsonencode({\r\n    source      = [\"aws.iam\"]\r\n    \"detail-type\" = [\"AWS API Call via CloudTrail\"]\r\n    detail = {\r\n      eventName = [\"AttachUserPolicy\", \"AttachGroupPolicy\"]\r\n      requestParameters = {\r\n        policyArn = [\"arn:aws:iam::aws:policy/AWSCompromisedKeyQuarantineV2\"]\r\n      }\r\n    }\r\n  })\r\n}\r\n\r\n# Event target that invokes the Lambda function when the event rule triggers\r\nresource \"aws_cloudwatch_event_target\" \"invoke_lambda\" {\r\n  rule      = aws_cloudwatch_event_rule.iam_policy_attachment.name\r\n  target_id = \"invokeLambdaFunction\"\r\n  arn       = aws_lambda_function.iam_access_key_deactivator.arn\r\n}\r\n\r\n# Permission for EventBridge (CloudWatch Events) to invoke the Lambda function\r\nresource \"aws_lambda_permission\" \"allow_eventbridge\" {\r\n  statement_id  = \"AllowExecutionFromEventBridge\"\r\n  action        = \"lambda:InvokeFunction\"\r\n  function_name = aws_lambda_function.iam_access_key_deactivator.function_name\r\n  principal     = \"events.amazonaws.com\"\r\n  source_arn    = aws_cloudwatch_event_rule.iam_policy_attachment.arn\r\n}\r\n\r\n# CloudWatch Log Group for the Lambda function logs\r\nresource \"aws_cloudwatch_log_group\" \"lambda_log_group\" {\r\n  name = \"/aws/lambda/${aws_lambda_function.iam_access_key_deactivator.function_name}\"\r\n\r\n  retention_in_days = 7\r\n\r\n  lifecycle {\r\n    prevent_destroy = false\r\n  }\r\n}\r\n"}]}
